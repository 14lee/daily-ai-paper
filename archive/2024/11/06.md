

## Papers for 2024-11-06

| Title | Authors | Summary |
|-------|---------|---------|
| HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems (Read more on [arXiv](https://arxiv.org/abs/2411.02959) or [HuggingFace](https://huggingface.co/papers/2411.02959))| Weipeng Chen, Mang Wang, Wen Wang, Zhicheng Dou, Jiejun Tan | HtmlRAG uses HTML instead of plain text to represent retrieved knowledge in Retrieval-Augmented Generation (RAG) systems.  The research investigates whether HTML is superior to plain text for modeling retrieved knowledge and mitigating LLM hallucinations in RAG systems utilizing web data.  The methodology involves HTML cleaning, compression, and a two-step pruning method (embedding-based and generative) to reduce HTML size and noise while preserving relevant information.  On the ASQA dataset, HtmlRAG achieved a 33.31% Exact Match score with Llama-3.1-8B-Instruct-4k, outperforming all plain-text baselines.  AI practitioners developing RAG systems can leverage HTML structure and semantics to improve the accuracy and factuality of LLM-generated responses, especially when utilizing web-based knowledge sources.  |
| LLaMo: Large Language Model-based Molecular Graph Assistant (Read more on [arXiv](https://arxiv.org/abs/2411.00871) or [HuggingFace](https://huggingface.co/papers/2411.00871))| Hyunwoo J. Kim, Dohwan Ko, Minseong Bae, Jinyoung Park | LLaMo is a large molecular graph-language model for instruction-following response generation in the molecular domain.  The research aimed to develop an end-to-end trained large molecular graph-language model capable of general-purpose molecule and language understanding.  The key methodology involves a multi-level graph projector that transforms graph representations into tokens, bridging the gap between graph and language modalities, coupled with instruction tuning using machine-generated molecular graph instruction data. LLaMo achieved a BLEU-4 score of 38.9 for molecular description generation, outperforming GPT-4 with in-context learning (27.0). This implies that AI practitioners can leverage LLaMo for improved performance in molecular tasks involving text and graph modalities, including description generation, property prediction, and IUPAC name prediction.  |
| DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for Efficient Robot Execution (Read more on [arXiv](https://arxiv.org/abs/2411.02359) or [HuggingFace](https://huggingface.co/papers/2411.02359))| Shenzhi Wang, Yizeng Han, Bingyi Kang, Yulin Wang, Yang Yue | DeeR-VLA dynamically adjusts the size of activated Multimodal Large Language Models (MLLMs) for efficient robot execution.  The research aims to reduce the computational demands of MLLMs for robotics, given limited hardware resources on robotic platforms.  The key methodology is a dynamic early-exit framework that leverages a multi-exit MLLM architecture and algorithms to determine termination criteria based on resource constraints and action consistency.  Experiments on the CALVIN benchmark showed a 5.2-6.5x reduction in LLM computational cost and a 2-6x reduction in LLM GPU memory without performance loss. This allows AI practitioners to deploy more complex MLLMs on robots with limited computational resources while maintaining performance.  |
| Sample-Efficient Alignment for LLMs (Read more on [arXiv](https://arxiv.org/abs/2411.01493) or [HuggingFace](https://huggingface.co/papers/2411.01493))| Min Lin, Wee Sun Lee, Chao Du, Changyu Chen, Zichen Liu | This paper introduces SEA, a sample-efficient algorithm for aligning Large Language Models (LLMs) with human preferences.  The research aims to address the challenge of aligning LLMs effectively with limited human feedback.  The key methodology involves a Thompson sampling-based algorithm incorporating an epistemic reward model, policy-guided search, and mixed preference learning.  Experiments demonstrate SEA achieves higher win rates and 2-5x better sample efficiency compared to baseline approaches across multiple model scales and direct preference optimization methods. This implies AI practitioners can achieve more effective LLM alignment with significantly less human feedback using SEA.  |
| DreamPolish: Domain Score Distillation With Progressive Geometry Generation (Read more on [arXiv](https://arxiv.org/abs/2411.01602) or [HuggingFace](https://huggingface.co/papers/2411.01602))| Shiyu Huang, Wendi Zheng, Ming Ding, Yean Cheng, GhostCai | DreamPolish is a text-to-3D generation model that produces refined geometry and photorealistic textures.  The objective is to generate high-quality 3D assets from text prompts, addressing limitations in existing methods regarding geometric detail and texture realism. The method uses progressive geometry construction with multiple neural representations, surface polishing with a normal estimator, and a novel domain score distillation (DSD) objective for texture enhancement.  DreamPolish achieves a CLIP Score of 0.759, outperforming baseline models.  This provides AI practitioners with a new method for generating high-fidelity 3D assets from text, potentially improving applications in areas like virtual reality, gaming, and 3D printing.  |
| Zebra-Llama: A Context-Aware Large Language Model for Democratizing Rare Disease Knowledge (Read more on [arXiv](https://arxiv.org/abs/2411.02657) or [HuggingFace](https://huggingface.co/papers/2411.02657))| Lashaw Salta, Chinmay Agrawal, Catalina Villouta, Andrew Langdon, ksoman | Zebra-Llama is a context-aware large language model specialized for Ehlers-Danlos Syndrome (EDS) information retrieval.  The objective was to develop a model capable of providing accurate and comprehensive responses to EDS-related queries, including proper citations.  The researchers fine-tuned a Llama 3.1-8B-Instruct model using a dataset of question-context-answer triplets derived from medical literature, patient forums, and social media discussions, with a focus on context-aware training using a specialized RAG implementation.  Zebra-Llama achieved 77.5% thoroughness compared to 70.1% for the base model on a test set of real-world questions from EDS patients and clinicians. This improved performance suggests that context-aware, domain-specific fine-tuning can significantly enhance LLMs for specialized information retrieval tasks, offering a promising avenue for developing AI solutions for rare diseases and other specialized domains.  |
| Controlling Language and Diffusion Models by Transporting Activations (Read more on [arXiv](https://arxiv.org/abs/2410.23054) or [HuggingFace](https://huggingface.co/papers/2410.23054))| Nicholas Apostoloff, Luca Zappella, Michal Klein, Arno Blaas, Pau Rodriguez | Activation Transport (ACT) offers fine-grained control over Large Language Models (LLMs) and text-to-image diffusion models (T2Is) by steering activations.  The research aimed to develop a modality-agnostic framework for steering activations to control the generation of LLMs and T2Is.  The key methodology involves using optimal transport theory to learn a transport map between source and target activation distributions and applying this map at inference time.  Linear-ACT achieved up to a 7.5x reduction in toxicity on the Gemma2-2B LLM benchmark with minimal impact on perplexity and MMLU accuracy. AI practitioners can leverage ACT to enhance the controllability and safety of generative models by mitigating unwanted behaviors (like toxicity) and inducing desired concepts or styles during generation, without retraining.  |
| GarVerseLOD: High-Fidelity 3D Garment Reconstruction from a Single In-the-Wild Image using a Dataset with Levels of Details (Read more on [arXiv](https://arxiv.org/abs/2411.03047) or [HuggingFace](https://huggingface.co/papers/2411.03047))| Zirong Jin, Wanghao Du, Chenghong Li, Haolin Liu, Zhongjin Luo | GarVerseLOD introduces a new dataset and framework for reconstructing high-fidelity 3D garment meshes from single in-the-wild images.  The research aimed to address the challenges of generalizing to diverse poses, deformations, and details in single-view 3D garment reconstruction.  The key methodology involves a hierarchical dataset (GarVerseLOD) with levels of detail (LOD) and a coarse-to-fine reconstruction approach that leverages linear blend skinning and implicit garment representations with geometry-aware boundary prediction.  The method achieved a Chamfer Distance of 7.825, outperforming compared methods.  This provides AI practitioners with a new dataset and model for robust 3D garment reconstruction applicable to various fields like virtual try-on and fashion design, enabling the generation of detailed garment models from limited visual input.  |
| Correlation of Object Detection Performance with Visual Saliency and Depth Estimation (Read more on [arXiv](https://arxiv.org/abs/2411.02844) or [HuggingFace](https://huggingface.co/papers/2411.02844))| Dylan Seychell, mbar0075 | This paper investigates the correlation of object detection accuracy with visual saliency and depth prediction.  The research aimed to determine whether visual saliency or depth prediction correlates more strongly with object detection accuracy.  The study used four pre-trained models (DeepGaze IIE, Depth Anything, DPT-Large, and Itti's model) to generate predictions on the COCO and Pascal VOC datasets, comparing them to ground truth annotations using mean Average Pearson Correlation (mAp).  Visual saliency exhibited a stronger correlation (mAp up to 0.459 on Pascal VOC) with object detection accuracy than depth prediction (mAp up to 0.283 on Pascal VOC). This suggests that incorporating visual saliency features into object detection models may improve performance, particularly in complex scenes.  |
