

## Papers for 2024-11-20

| Title | Authors | Summary |
|-------|---------|---------|
| Continuous Speculative Decoding for Autoregressive Image Generation (Read more on [arXiv](https://arxiv.org/abs/2411.11925) or [HuggingFace](https://huggingface.co/papers/2411.11925))| Fei Li, Qi Yang, Kun Ding, Robert Zhang, MarkWang | This paper introduces Continuous Speculative Decoding (CSpD), a novel method for accelerating autoregressive image generation.  The objective is to reduce the computational overhead of continuous-valued autoregressive image generation models while maintaining output quality. CSpD adapts the speculative decoding algorithm from discrete to continuous token space by using denoising trajectory alignment, token pre-filling, and acceptance-rejection sampling to address inconsistencies between draft and target models.  Experiments on MAR models for ImageNet 256x256 generation demonstrated a speedup of up to 2.33x.  This provides AI practitioners with a technique to significantly accelerate inference for continuous autoregressive image generation models without requiring model retraining or architectural changes, enabling faster generation with comparable quality.  |
| Soft Robotic Dynamic In-Hand Pen Spinning (Read more on [arXiv](https://arxiv.org/abs/2411.12734) or [HuggingFace](https://huggingface.co/papers/2411.12734))| Jeffrey Ichnowski, Christopher G. Atkeson, Jean Oh, Uksang Yoo, Yunchao Yao | SWIFT is a system for learning dynamic in-hand manipulation tasks with soft robotic hands, using pen spinning as a case study.  The research aimed to enable a soft robotic hand to autonomously learn to grasp and dynamically spin a pen using only real-world data.  A self-supervised, trial-and-error approach employing Covariance Matrix Adaptation Evolution Strategy (CMA-ES) optimized grasp location and servo parameters for a three-fingered soft hand. After optimization, SWIFT achieved a 100% success rate across three pens with different weight distributions. This demonstrates the potential for soft robots to perform complex dynamic manipulation tasks without precise object models or simulated training, which can inform the development of more robust and adaptable real-world robotic manipulation systems.  |
| RedPajama: an Open Dataset for Training Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2411.12372) or [HuggingFace](https://huggingface.co/papers/2411.12372))| Shane Adams, Yonatan Oren, Quentin Anthony, Daniel Fu, Maurice Weber | RedPajama releases two datasets, V1 and V2, aiming to address transparency and data access challenges in large language model training.  The research aimed to create open and versatile datasets for training and analyzing LLMs, specifically focusing on data composition and filtering strategies.  RedPajama-V1 reproduced the LLaMA training dataset and RedPajama-V2 created a new web-based dataset with quality signals.  Decoder-only transformer models with up to 1.6 billion parameters trained on filtered subsets of RedPajama-V2 showed varying performance on NLP benchmarks, with the Gopher+fuzzy deduplication filter achieving the highest aggregate scores. This allows practitioners to leverage the RedPajama datasets and associated quality signals to curate and experiment with data subsets for training large language models, fostering development of more transparent and potentially higher-performing LLMs.  |
| Building Trust: Foundations of Security, Safety and Transparency in AI (Read more on [arXiv](https://arxiv.org/abs/2411.12275) or [HuggingFace](https://huggingface.co/papers/2411.12275))| Huamin Chen, Mark Bestavros, Emily Fox, Garth Mollett, huzaifas-sidhpurwala | The paper explores security and safety implications of publicly available AI models.  The objective is to propose strategies for enhancing security, safety, and transparency in the development and operation of public AI models. The paper reviews current security and safety scenarios, highlighting challenges like a lack of standardized processes for lifecycle management and vulnerability remediation. A key finding is generative AI's steeper adoption curve compared to other technologies, with a projected 124.7 million US users by year four of its release, compared to 116.9 million smartphone users by year four. A primary implication for AI practitioners is the need to adopt a holistic approach to AI risk management, encompassing both security (protecting systems from threats) and safety (preventing unintended harm from model operation), possibly through the creation of frameworks such as a "Hazards Exposure eXchange (HEX)" format and an "Adjunct panel" mirroring similar concepts used in traditional software security.  The paper lacks precise details about the proposed HEX format and Adjunct panel, hindering full comprehension of their function.  |
| Evaluating Tokenizer Performance of Large Language Models Across Official Indian Languages (Read more on [arXiv](https://arxiv.org/abs/2411.12240) or [HuggingFace](https://huggingface.co/papers/2411.12240))| D. J. Bora, tamang0000 | This paper evaluates the tokenization performance of various large language models (LLMs) across 22 official Indian languages.  The research aimed to compare the efficiency of different tokenizers used by 12 LLMs in processing these languages.  Normalized Sequence Length (NSL) was used as the primary evaluation metric, calculated as the ratio of tokenized sequence lengths between a given tokenizer and a baseline.  The SUTRA tokenizer achieved the lowest average NSL across 14 out of the 22 languages.  This finding indicates that the SUTRA tokenizer is particularly efficient for Indian languages and highlights the importance of tokenizer selection for multilingual LLM performance.  |
