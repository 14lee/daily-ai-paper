

## Papers for 2024-12-26

| Title | Authors | Summary |
|-------|---------|---------|
| Token-Budget-Aware LLM Reasoning (Read more on [arXiv](https://arxiv.org/abs/2412.18547) or [HuggingFace](https://huggingface.co/papers/2412.18547))| Zhenyu Chen, Shiqing Ma, Shiyu Zhao, Chunrong Fang, Tingxu Han | Here is a concise summary of the paper "Token-Budget-Aware LLM Reasoning":  i) **Summary:** This paper introduces TALE, a framework to reduce token redundancy in large language model (LLM) reasoning by dynamically estimating and incorporating token budgets into prompts. ii) **Main research question or objective:** How to effectively reduce token costs in Chain-of-Thought (CoT) reasoning while preserving LLM performance. iii) **Key methodology:** TALE estimates a token budget based on reasoning complexity and uses it to guide the LLM's reasoning process via a token-budget-aware prompt. iv) **Primary results:** TALE reduces token usage by 68.64% on average compared to vanilla CoT, with less than a 5% decrease in accuracy. v) **Principal implication for AI practitioners:** AI practitioners can use TALE to optimize token efficiency in LLM reasoning tasks, significantly reducing computational costs and resource usage while maintaining performance.  |
