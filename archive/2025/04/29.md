

## Papers for 2025-04-29

| Title | Authors | Summary |
|-------|---------|---------|
| RepText: Rendering Visual Text via Replicating (Read more on [arXiv](https://arxiv.org/abs/2504.19724) or [HuggingFace](https://huggingface.co/papers/2504.19724))| Yimeng Li, winhelp, SNOWAI, YujiaX, wanghaofan | RepText introduces a method for rendering multilingual visual text in images by replicating glyphs rather than relying on deep text understanding. The main objective is to empower pre-trained monolingual text-to-image models with accurate, controllable multilingual text rendering capabilities without costly retraining or multilingual encoders. The key methodology involves a ControlNet-like architecture conditioned on language-agnostic glyph canny edges and position masks, enhanced by a text perceptual (OCR) loss, glyph latent replication during initialization, and regional masking at inference. Results show RepText outperforms existing open-source methods and achieves comparable performance to native multilingual closed-source models in rendering quality and accuracy, though specific quantitative metrics are not provided in the initial sections. For AI practitioners, this implies the ability to add precise, user-specified multilingual text to images using existing monolingual generative models through glyph replication, bypassing the need for models with inherent multilingual text understanding. |
| LLM-Powered GUI Agents in Phone Automation: Surveying Progress and
  Prospects (Read more on [arXiv](https://arxiv.org/abs/2504.19838) or [HuggingFace](https://huggingface.co/papers/2504.19838))| Afeng-x, guoyaxuan0106, melpancake, Pengxiangzhao, guangyil | This paper systematically reviews the evolution and capabilities of LLM-powered phone GUI agents, contrasting them with traditional methods. The main objective is to survey the progress, analyze core technologies, identify challenges, and outline future prospects for LLMs in phone automation. The methodology involves a comprehensive literature review, proposing a taxonomy of agent frameworks (single-agent, multi-agent, plan-then-act), modeling approaches (prompting, training-based), datasets, and benchmarks, alongside analyzing how LLMs address prior limitations. Primary results indicate LLMs significantly enhance phone automation through advanced language understanding, multimodal perception, and decision-making, overcoming traditional script limitations; for instance, specific RL approaches like DistRL show up to 20% relative improvement in success rate over state-of-the-art methods on general Android tasks. For AI practitioners, this survey provides a structured taxonomy and methodological framework, serving as a definitive reference for designing, developing, and evaluating scalable, adaptive LLM-powered phone GUI agents. |
| CipherBank: Exploring the Boundary of LLM Reasoning Capabilities through
  Cryptography Challenges (Read more on [arXiv](https://arxiv.org/abs/2504.19093) or [HuggingFace](https://huggingface.co/papers/2504.19093))| JiangWu, mingchenlin2025, LHL3341, blue01223, yu0226 | This paper introduces CipherBank, a comprehensive benchmark evaluating LLM reasoning on cryptographic decryption tasks. The main objective is to rigorously assess the cryptographic reasoning capabilities of modern LLMs, identifying their strengths and weaknesses in this specific domain. Key methodology involves evaluating 18 state-of-the-art LLMs on the CipherBank dataset (comprising 2,358 problems across 5 domains, 14 subdomains, and 9 encryption algorithms) using a 3-shot known-plaintext attack evaluation protocol and accuracy metrics. Primary results reveal significant limitations across all models, even advanced ones; the top-performing model, Claude-3.5, achieved only 45.14% accuracy, demonstrating that current reasoning optimizations inadequately address cryptographic challenges. The principal implication for AI practitioners is that standard LLMs exhibit poor performance in precise cryptographic manipulation, indicating unsuitability for security-critical applications and highlighting the need for targeted development of symbolic reasoning and rule application capabilities beyond general language understanding for robust AI systems. |
| Clinical knowledge in LLMs does not translate to human interactions (Read more on [arXiv](https://arxiv.org/abs/2504.18919) or [HuggingFace](https://huggingface.co/papers/2504.18919))| cynddl, sahimo, Chronoszoldyck11, HannahRoseKirk, ambean | Large language models (LLMs) demonstrate high clinical knowledge on benchmarks but fail to improve lay users' medical assessment accuracy in realistic interactive scenarios compared to controls. The study investigated whether providing laypeople with access to high-performing LLMs (GPT-4o, Llama 3, Command R+) improves their ability to identify appropriate medical dispositions and relevant conditions in simulated health scenarios. A randomized controlled trial (N=1298) assigned participants to receive assistance from one of three LLMs or a control group (using typical resources) to assess ten medical vignettes against physician-defined gold standards. While LLMs alone identified relevant conditions in over 90% of cases, participants using LLMs identified relevant conditions in less than 34.5% of cases, significantly underperforming the control group (47.0%, p<0.001), and showed no significant improvement in disposition accuracy. For AI practitioners, this study critically demonstrates that strong performance on static or simulated benchmarks does not predict real-world interactive utility; robust human-user testing focused on interaction dynamics is essential before deploying LLMs for public health applications. |
| Group Downsampling with Equivariant Anti-aliasing (Read more on [arXiv](https://arxiv.org/abs/2504.17258) or [HuggingFace](https://huggingface.co/papers/2504.17258))| Raymond A. Yeh, ashiq24 | This paper introduces a method for uniform downsampling of signals on finite groups with equivariant anti-aliasing, generalizing classical sampling theory concepts for group equivariant architectures. The objective is to define how to select an appropriate subgroup for a given downsampling rate and how to perform anti-aliasing to preserve equivariance. The methodology involves an algorithm for subgroup selection based on Cayley graphs, a Subgroup Sampling Theorem defining bandlimited-ness for perfect reconstruction, and an equivariant anti-aliasing operator derived via constrained optimization. Experiments demonstrate improved accuracy and equivariance (e.g., near-zero reconstruction error like 1.72e-13 for bandlimited signals on D28 downsampled to D14) and reduced model size when incorporated into G-CNNs for image classification. For AI practitioners, this provides a principled way to incorporate downsampling into group equivariant networks, enabling more computationally efficient models while better preserving theoretical equivariance guarantees compared to naive subsampling. |
| TrustGeoGen: Scalable and Formal-Verified Data Engine for Trustworthy
  Multi-modal Geometric Problem Solving (Read more on [arXiv](https://arxiv.org/abs/2504.15780) or [HuggingFace](https://huggingface.co/papers/2504.15780))| BoZhang, friskit, Rethinker, zhoubb2010, renqiux0302 | TrustGeoGen is a scalable engine generating formally verified multimodal geometric problems, solutions, and diagrams. The objective is to create a reliable benchmark and data generation pipeline for trustworthy geometric problem solving (GPS), addressing the lack of verified, multimodal data. Its methodology integrates multimodal-aligned generation, formal logical verification of reasoning steps, a bootstrapping mechanism for complexity scaling, and algorithms for generating diverse, traceable solutions. Primary results show the generated GeoTrust-test is challenging for SOTA models (OpenAI-o1 achieves 49.17% accuracy), and training on GeoTrust data improves OOD generalization on GeoQA compared to pseudo-labels. For AI practitioners, this provides a formally verified data source and engine (TrustGeoGen/GeoTrust) crucial for developing and evaluating more logically sound multimodal geometric reasoning systems, demonstrating superior training effectiveness over unverified data. |
| SPC: Evolving Self-Play Critic via Adversarial Games for LLM Reasoning (Read more on [arXiv](https://arxiv.org/abs/2504.19162) or [HuggingFace](https://huggingface.co/papers/2504.19162))| Xiaodan Liang, Peisong Wang, Bang Zhang, vvibt, judge | This paper introduces Self-Play Critic (SPC), a method to automatically evolve a critic model for assessing LLM reasoning steps via adversarial self-play, removing the need for manual step-level annotation. The main objective is to improve the evaluation of step-by-step reliability in complex LLM reasoning like Chain-of-Thought. SPC employs two fine-tuned models, a "sneaky generator" creating subtle errors and a "critic" detecting them, which improve iteratively through reinforcement learning based on adversarial game outcomes. Experiments show SPC progressively enhances error detection capabilities (accuracy increasing from 70.8% to 77.7% on ProcessBench) and significantly improves LLM mathematical reasoning on MATH500 and AIME2024 when used to guide test-time search, outperforming existing process reward models. For AI practitioners, SPC provides a scalable technique to develop more accurate step-level critics for verifying and enhancing LLM reasoning processes without requiring expensive human-labeled data. |
| Benchmarking Multimodal Mathematical Reasoning with Explicit Visual
  Dependency (Read more on [arXiv](https://arxiv.org/abs/2504.18589) or [HuggingFace](https://huggingface.co/papers/2504.18589))| Xin Li, Zhiqiang Hu, Wenqi Zhang, Jiashuo Sun, cloudcatcher2 | VCBENCH is a new benchmark evaluating Large Vision-Language Models (LVLMs) on elementary math problems requiring reasoning across multiple images with explicit visual dependencies. The objective is to assess the core ability of LVLMs to discern, integrate, and reason using visual information from multiple images for basic mathematical tasks, moving beyond knowledge-centric evaluations. The methodology involved creating VCBENCH with 1,720 problems (averaging 3.9 images each, total 6,697 images) across six cognitive domains and evaluating 26 state-of-the-art LVLMs. Primary results show significant performance limitations, with even the best-performing models (e.g., Gemini2.0-Flash, Qwen-VL-Max) failing to exceed 50% accuracy, indicating particular weaknesses in pattern recognition and integrating visual cues across multiple images. For AI practitioners, this highlights a critical gap in current LVLMs' fundamental visual-mathematical reasoning and multi-image integration capabilities, suggesting that model architectures and pre-training strategies need substantial improvement for tasks requiring grounded visual reasoning beyond single-image comprehension. |
| MMInference: Accelerating Pre-filling for Long-Context VLMs via
  Modality-Aware Permutation Sparse Attention (Read more on [arXiv](https://arxiv.org/abs/2504.16083) or [HuggingFace](https://huggingface.co/papers/2504.16083))| Xufang Luo, Qianhui Wu, Chengruidong Zhang, Yucheng Li, iofu728 | MMInference introduces a dynamic sparse attention method to accelerate the pre-filling stage for long-context Vision Language Models (VLMs). The primary objective is to mitigate the quadratic complexity bottleneck of attention during the processing of long multi-modal inputs, particularly the pre-fill stage which causes high Time-to-First-Token latency. The key methodology involves identifying unique modality-specific sparse patterns (like the Grid pattern for visual data) and modality boundaries, then applying modality-aware permutations and optimized GPU kernels for efficient sparse computation without model modification. Experiments demonstrate that MMInference accelerates the pre-filling stage by up to 8.3x for 1M tokens compared to dense attention, while maintaining comparable accuracy on various multi-modal benchmarks using models like LongVila and Llava-Video. For AI practitioners, this offers a drop-in method to significantly reduce inference latency for long-context VLMs, enabling faster deployment in real-world applications without requiring model fine-tuning. |
| ICL CIPHERS: Quantifying "Learning'' in In-Context Learning via
  Substitution Ciphers (Read more on [arXiv](https://arxiv.org/abs/2504.19395) or [HuggingFace](https://huggingface.co/papers/2504.19395))| Daniel Khashabi, Anqi Liu, Muhan Gao, Aayush Mishra, FocusV857 | This paper introduces ICL CIPHERS, using substitution ciphers to quantify task learning (TL) in In-Context Learning (ICL) separately from task retrieval (TR). The main objective is to determine if Large Language Models (LLMs) can decipher and solve tasks when input tokens are systematically replaced using a reversible (bijective) mapping, thereby measuring inference-time learning. The methodology involves comparing LLM accuracy on tasks using inputs ciphered with bijective substitution mappings versus non-bijective (irreversible, random) mappings across four datasets and six models. Results consistently show LLMs perform better on bijective ciphers; Llama3.1 (8B) achieved an average of 7.1% higher accuracy on the bijective ciphered Amazon dataset compared to the non-bijective cipher across various demonstration counts. For AI practitioners, the observed accuracy gap between bijective and non-bijective ciphered tasks provides a quantitative proxy to assess an LLM's ability to learn novel, reversible patterns during inference, beyond simple retrieval from pre-training data. |
| ChiseLLM: Unleashing the Power of Reasoning LLMs for Chisel Agile
  Hardware Development (Read more on [arXiv](https://arxiv.org/abs/2504.19144) or [HuggingFace](https://huggingface.co/papers/2504.19144))| Shanshan Li, Renzhi Chen, Jiaran Gao, xiuranli, observerw | This paper introduces ChiseLLM, a series of datasets and fine-tuned reasoning models to enhance Large Language Model (LLM) performance for Chisel hardware construction language generation. The research objective is to address the poor syntax correctness and limited design variability exhibited by existing LLMs when generating Chisel code for Agile Hardware Development Methodology (AHDM). Methodologically, the authors curated high-quality datasets from public RTL sources, synthesized prompt-guided reasoning traces, and performed domain-adapted fine-tuning on Qwen2.5-Coder base models. Results show significant improvements; notably, the ChiseLLM-32B model increased average Pass@5 syntax correctness by 26.32% over the base model and boosted design variability capability by 47.58% compared to baseline reasoning models. The principal implication for AI practitioners is that domain adaptation combined with synthesized reasoning traces is crucial for effectively leveraging reasoning LLMs in specialized, low-resource code generation tasks like HCL, enabling practical application in hardware design. |
