

## Papers for 2025-04-24

| Title | Authors | Summary |
|-------|---------|---------|
| VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal
  Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2504.15279) or [HuggingFace](https://huggingface.co/papers/2504.15279))| Einsiedler, luotto, Weiyun1025, GenuineWWD, wilye | This paper introduces VisuLogic, a benchmark designed to evaluate genuine vision-centric reasoning in multi-modal large language models (MLLMs). The research aims to address the limitation that current MLLM evaluations often rely on textual descriptions, allowing language-based shortcuts instead of measuring true visual reasoning. The methodology involves a new benchmark of 1,000 human-verified visual problems across six categories (quantitative, spatial, positional, attribute, stylistic, other), designed to be difficult to solve via text description alone, on which leading MLLMs and humans were evaluated. Primary results show a significant gap: most evaluated MLLMs achieved below 30% accuracy (e.g., Doubao-1.5-Vision-Pro at 28.1%), far below the human baseline of 51.4% and only slightly above the 25% random baseline. The principal implication for AI practitioners is that current MLLMs possess weak visual reasoning capabilities, necessitating better evaluation benchmarks and development focus on genuine vision-centric understanding, potentially leveraging techniques like reinforcement learning which showed promise (improving a baseline to 31.1%). |
| DreamID: High-Fidelity and Fast diffusion-based Face Swapping via
  Triplet ID Group Learning (Read more on [arXiv](https://arxiv.org/abs/2504.14509) or [HuggingFace](https://huggingface.co/papers/2504.14509))| heqian, giruhc9gj, Crayon-Shinchan, miaohua, Alon77777 | DreamID introduces a high-fidelity, fast diffusion-based face swapping model using explicit supervision. The primary objective is to significantly improve identity (ID) similarity and attribute preservation in face swapping while achieving rapid inference speed. Key methodology involves constructing Triplet ID Group data (source A1, pseudo target B, ground truth A2) for explicit pixel-level supervision, leveraging the accelerated Stable Diffusion Turbo (SD Turbo) model for single-step inference, and utilizing an improved architecture comprising SwapNet, FaceNet, and an ID Adapter. The primary result shows state-of-the-art performance, achieving 0.71 ID similarity and generating 512x512 resolution swaps in just 0.6 seconds. For AI practitioners, this work provides a significantly faster and more accurate face swapping technique by enabling effective end-to-end training with explicit image-space loss functions, overcoming limitations of implicit supervision in prior diffusion-based methods. |
| Trillion 7B Technical Report (Read more on [arXiv](https://arxiv.org/abs/2504.15431) or [HuggingFace](https://huggingface.co/papers/2504.15431))| Suyeong An, hist0613, kyudolski, scottsuk0306, sungjunhan-trl | Trillion-7B is introduced as a highly token-efficient, Korean-centric multilingual Large Language Model. The research aims to address the data imbalance in multilingual LLM training, enabling effective knowledge transfer from English to target languages like Korean despite data scarcity. Key methodologies include the novel Cross-lingual Document Attention (XLDA) mechanism, optimized data mixtures, language-specific filtering, a tailored tokenizer, and a two-stage pre-training approach. Trillion-7B achieves competitive performance across 27 benchmarks using only 10% multilingual data within its 2T token training budget, requiring 59.4K H100 GPU hours ($148K) for full training. For AI practitioners, this demonstrates that architectural innovations like XLDA and strategic training can enable efficient development of high-performing multilingual models for less-resourced languages, reducing reliance on massive language-specific data scaling. |
| Pre-DPO: Improving Data Utilization in Direct Preference Optimization
  Using a Guiding Reference Model (Read more on [arXiv](https://arxiv.org/abs/2504.15843) or [HuggingFace](https://huggingface.co/papers/2504.15843))| Yue Zhang, Qiji Zhou, Shulin Huang, Junshu Pan, Swtheking | Pre-DPO is a training paradigm enhancing DPO and SimPO preference optimization by leveraging a guiding reference model derived from an initial optimization pass for improved data utilization. The research objective was to overcome inefficient data weighting and performance ceilings inherent in standard DPO/SimPO reference model configurations. Methodologically, Pre-DPO involves first optimizing an initial policy, setting this optimized policy as a guiding reference model, and subsequently re-optimizing the initial policy using DPO under the guidance of this new reference. Experimental results show Pre-DPO consistently outperforms standard DPO and SimPO, achieving average improvements of 2.5 points on AlpacaEval 2 LC and boosting Qwen2.5-7B-Instruct Arena-Hard v0.1 WR from 62.9 (DPO) to 68.8. For AI practitioners, this provides a technique to enhance preference optimization outcomes using existing models and data by enabling more effective adaptive data reweighting, potentially raising performance ceilings. |
| I-Con: A Unifying Framework for Representation Learning (Read more on [arXiv](https://arxiv.org/abs/2504.16929) or [HuggingFace](https://huggingface.co/papers/2504.16929))| John Hershey, Shaden Alshammari, mhamilton723, mrpuppt, axelf | I-Con introduces a unified information-theoretic framework generalizing numerous representation learning methods by minimizing an integrated KL divergence between supervisory and learned conditional neighborhood distributions. The primary objective is to demonstrate that diverse techniques like clustering, contrastive learning, dimensionality reduction, and supervised learning are special cases of this single underlying loss function. The methodology involves defining specific conditional probability distributions (p and q) for existing algorithms (e.g., SNE, SimCLR, K-Means, Cross-Entropy) to show their equivalence to minimizing the I-Con objective, proving 15 theorems connecting over 23 methods. Key results include the theoretical unification itself and the creation of a novel debiased clustering method achieving a +8% improvement in Hungarian accuracy on unsupervised ImageNet-1K classification over the previous state-of-the-art. For AI practitioners, I-Con provides a principled foundation for understanding the relationships between disparate loss functions, enabling the transfer of techniques across domains and the development of improved or novel representation learning algorithms, particularly for unsupervised tasks. |
| Decoupled Global-Local Alignment for Improving Compositional
  Understanding (Read more on [arXiv](https://arxiv.org/abs/2504.16801) or [HuggingFace](https://huggingface.co/papers/2504.16801))| Ziyong Feng, Jun Wang, haoranxu, Kaichengalex, xiaoxing2001 | This paper introduces DeGLA, a framework enhancing vision-language models' compositional understanding while maintaining general capabilities by decoupling global self-distillation alignment from local contrastive alignment using LLM-generated hard negatives. The main objective is to overcome the limitation where improving compositional reasoning in models like CLIP often degrades their general performance due to catastrophic forgetting during fine-tuning. DeGLA utilizes self-distillation with an EMA teacher for global alignment and introduces Image-Grounded Contrast (IGC) and Text-Grounded Contrast (TGC) losses with ~2M LLM-generated negative captions for local alignment. Compared to the CE-CLIP baseline, DeGLA shows an average 3.5% improvement across VALSE, SugarCrepe, and ARO compositional benchmarks and a 13.0% average improvement across 11 zero-shot classification datasets. For AI practitioners, DeGLA offers a method to fine-tune vision-language models for improved nuanced understanding (e.g., attribute binding, relations) in multimodal tasks without significantly sacrificing their robust zero-shot transfer abilities. |
| DreamO: A Unified Framework for Image Customization (Read more on [arXiv](https://arxiv.org/abs/2504.16915) or [HuggingFace](https://huggingface.co/papers/2504.16915))| LemonSky1995, Crayon-Shinchan, shiwenzh, Zinan123212, yanze | DreamO provides a unified framework based on a Diffusion Transformer (DiT) for diverse image customization tasks using lightweight adaptation. The objective is to overcome the limitations of task-specific models by enabling flexible integration and interaction of multiple control conditions (identity, subject, style, try-on) within a single model. The methodology involves fine-tuning a pre-trained DiT (Flux-1.0-dev) using LoRA, introducing a feature routing constraint based on cross-attention supervision for fidelity and disentanglement, a placeholder strategy for positional control, and a three-stage progressive training strategy. Qualitative results demonstrate high-fidelity generation across multiple conditions with only 707M additional trainable LoRA parameters, and ablation studies confirm the effectiveness of the routing constraint and progressive training. For AI practitioners, DreamO offers a method to implement versatile, multi-conditional image customization capabilities efficiently using a single, lightweight adapted model, reducing the need for multiple specialized systems. |
| Tina: Tiny Reasoning Models via LoRA (Read more on [arXiv](https://arxiv.org/abs/2504.15777) or [HuggingFace](https://huggingface.co/papers/2504.15777))| Ollie Liu, Enes Burak Bilgin, Ömer Faruk Akgül, Julian Asilis, upup-ashton-wang | This paper introduces Tina, a family of cost-effective 1.5B parameter reasoning models developed by applying LoRA during RL. The research objective is to determine how cost-effectively strong reasoning abilities can be achieved in small language models using minimal computational resources. Key methodology involves applying parameter-efficient low-rank adaptation (LoRA) updates during reinforcement learning (specifically, a GRPO-style algorithm) to a tiny 1.5B parameter base model, using open-source frameworks and minimal hardware. Primary results demonstrate that Tina models achieve reasoning performance competitive with, and sometimes superior to, full-parameter trained SOTA RL models on the same base; the best Tina model attained a 50.60% average score across six reasoning benchmarks, significantly outperforming its 41.60% full-parameter baseline average, at an estimated $9 post-training and evaluation cost. The principal implication for AI practitioners is that LoRA combined with RL provides a highly resource-efficient pathway to substantially enhance reasoning capabilities in smaller LMs, achieving significant performance gains with minimal computational expenditure, potentially by rapidly adapting the model's output format. |
| A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training
  and Deployment (Read more on [arXiv](https://arxiv.org/abs/2504.15585) or [HuggingFace](https://huggingface.co/papers/2504.15585))| Guibin Zhang, Kun Wang, Ningyu, Atarogic, Fred456 | This survey introduces "full-stack" LLM safety, comprehensively analyzing security and safety issues across the entire LLM lifecycle, from data to deployment. The primary objective is to systematically categorize safety considerations throughout all stages of LLM development (data preparation, pre-training, post-training including alignment, editing, unlearning, and agent integration) and deployment, identifying gaps in existing research that focuses on isolated phases. The methodology involves an extensive literature review encompassing over 800 papers, synthesized into a novel "full-stack" taxonomic framework that maps safety risks and defenses across the defined LLM lifecycle stages. Key results include the identification of persistent risks such as data poisoning (e.g., 0.1% poisoned data causing lasting impact even after fine-tuning), privacy leakage from training data memorization, vulnerabilities introduced during fine-tuning/alignment (like RLHF reward model poisoning), and novel attack surfaces in LLM-based agents involving tool use and memory manipulation. The principal implication for AI practitioners is the critical need to integrate safety considerations throughout the entire development and deployment pipeline, recognizing that security is not merely a deployment-stage concern but is deeply intertwined with data sourcing, training methodologies, alignment processes, and the integration of external modules in agentic systems. |
| RePOPE: Impact of Annotation Errors on the POPE Benchmark (Read more on [arXiv](https://arxiv.org/abs/2504.15707) or [HuggingFace](https://huggingface.co/papers/2504.15707))| Matthias Hein, YanNeu | This paper assesses the impact of annotation errors in the MSCOCO dataset on the POPE object hallucination benchmark and introduces a corrected version called RePOPE. The objective is to quantify how these underlying label errors influence the evaluation and ranking of Vision Large Language Models (VLMs) for object hallucination. The methodology involved re-annotating all 500 images used in POPE by consensus, identifying errors and ambiguous cases, creating the corrected RePOPE labels by fixing errors and removing ambiguities, and re-evaluating various VLMs. Primary results show significant label errors, particularly 9.3% errors and 13.8% ambiguous cases in the positive ("Yes") set of POPE, leading to substantial shifts in model F1 score rankings on RePOPE compared to the original benchmark. The principal implication for AI practitioners is that evaluations based on the original POPE benchmark are notably affected by annotation quality, and using RePOPE offers a more reliable assessment, potentially changing conclusions about relative model performance regarding hallucinations. |
| Rethinking the Generation of High-Quality CoT Data from the Perspective
  of LLM-Adaptive Question Difficulty Grading (Read more on [arXiv](https://arxiv.org/abs/2504.11919) or [HuggingFace](https://huggingface.co/papers/2504.11919))| Keyu Wu, Kunlinliu2, MeiManlin, zcs1234, USTCYu | This paper introduces LLM-adaptive difficulty grading to generate high-quality CoT data, enabling smaller LLMs to achieve superior reasoning performance. The objective is to determine if LLM-adaptive question difficulty grading can efficiently produce high-quality Chain-of-Thought (CoT) data tailored to enhance smaller LLM reasoning capabilities. The methodology involves grading questions using a base LLM's performance (correctness check + PRM-Grader), constructing an adaptive question database, sampling based on difficulty distribution, and generating verified CoT using DeepSeek-R1 as a teacher model. Results show that a 32B model fine-tuned on just 2k adaptively generated math CoT examples (ZMath-32B) significantly outperformed the DeepSeek-Distill-32B baseline on math benchmarks (e.g., 73.33% vs 66.67% accuracy on AIME24). For AI practitioners, this indicates that smaller, intelligently curated CoT datasets based on adaptive difficulty grading can be highly resource-efficient for substantially improving the reasoning abilities of smaller LLMs through supervised fine-tuning. |
| CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation (Read more on [arXiv](https://arxiv.org/abs/2504.15254) or [HuggingFace](https://huggingface.co/papers/2504.15254))| Ziteng Wang, Jia Pan, Robert Zhang, gregdurrett, anirudhkhatry | This paper introduces CRUST-Bench, a benchmark for evaluating C-to-safe-Rust transpilation using 100 C repositories with manually defined Rust interfaces and test cases. The research objective is to assess the ability of current transpilation systems, particularly LLMs, to generate functionally correct, memory-safe, and idiomatic Rust code from entire C repositories. The methodology involved creating the CRUST-Bench dataset by sourcing C repositories, manually authoring corresponding safe Rust interfaces and test suites, and using this framework to evaluate various LLMs and agentic systems. Primary results show that current state-of-the-art LLMs find this task challenging; the best performing model, OpenAI o1, solved only 15% of tasks single-shot, improving to 37% with iterative test-based repair, highlighting frequent errors in type handling, borrowing rules, and incomplete implementations. For AI practitioners, this implies that fully automated, reliable C-to-safe-Rust migration for complex projects using current LLMs remains an open challenge, necessitating significant improvements in handling Rust's strict safety and ownership semantics or requiring human oversight. |
| Unchecked and Overlooked: Addressing the Checkbox Blind Spot in Large
  Language Models with CheckboxQA (Read more on [arXiv](https://arxiv.org/abs/2504.10419) or [HuggingFace](https://huggingface.co/papers/2504.10419))| Borchmann, sf-mchilinski, mturski | This paper introduces CheckboxQA, a benchmark dataset to evaluate and improve Large Vision-Language Model (LVLM) performance on interpreting checkboxes in documents. The primary objective is to assess and address the significant challenge LVLMs face with accurately identifying checkbox states and their associated context, a crucial but often overlooked aspect of document understanding. The authors curated the CheckboxQA dataset comprising 88 documents and 579 question-answer pairs focused on checkbox interpretation and evaluated baseline LVLMs using the Average Normalized Levenshtein Similarity (ANLS*) metric. Results show that even top-performing models like Qwen 2.5 VL 72B (83.2 ANLS*) lag significantly behind human performance (97.5 ANLS*), indicating substantial room for improvement. For AI practitioners, this research underscores that robust document processing requires specific attention to fine-grained visual elements like checkboxes, as general LVLM proficiency does not automatically transfer, necessitating targeted datasets and potentially model adaptations for reliable real-world applications. |
| Progressive Language-guided Visual Learning for Multi-Task Visual
  Grounding (Read more on [arXiv](https://arxiv.org/abs/2504.16145) or [HuggingFace](https://huggingface.co/papers/2504.16145))| Dingjiang Huang, Kunhua Ji, Wenlong Zhang, Hong Wang, jcwang0602 | This paper introduces PLVL, a Progressive Language-guided Visual Learning framework for Multi-Task Visual Grounding (MTVG), integrating Referring Expression Comprehension (REC) and Segmentation (RES). The main objective is to address insufficient language injection into visual backbones and ineffective exploitation of the REC-RES task relationship in existing methods. PLVL utilizes a modified ViTDet backbone with local and global blocks, progressively injecting language tokens via cross-attention in global blocks, and employs a novel convolution-based collaborative multi-task head exploiting shared object localization priors. Results demonstrate state-of-the-art performance, achieving 89.80% accuracy on the RefCOCOg test(U) REC task under pre-training settings, outperforming previous methods. For AI practitioners, PLVL offers a more effective architecture for joint REC/RES prediction by deeply integrating language guidance throughout the visual feature extraction process and explicitly modeling task synergy, leading to improved grounding accuracy. |
