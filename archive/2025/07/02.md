

## Papers for 2025-07-02

| Title | Authors | Summary |
|-------|---------|---------|
| GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable
  Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2507.01006) or [HuggingFace](https://huggingface.co/papers/2507.01006))| tanghme0www, bigganbing, xgeric, iyuge2, wenyi | This paper presents GLM-4.1V-Thinking, a vision-language model designed for versatile multimodal reasoning through a novel, reasoning-centric training framework. The primary objective is to enhance a model's general-purpose reasoning capabilities by leveraging scalable reinforcement learning to unlock the full potential of a capable vision foundation model. The key methodology is a three-stage training process: large-scale pre-training on a diverse multimodal corpus, supervised fine-tuning on long chain-of-thought data, and a final stage using Reinforcement Learning with Curriculum Sampling (RLCS) to dynamically select appropriately difficult tasks. The resulting open-source 9B-parameter model outperforms the much larger Qwen2.5-VL-72B on 18 of 28 benchmarks, and the RLCS stage provides substantial performance boosts, including a +7.3% gain on GUI agent tasks. The principal implication for AI practitioners is that a multi-stage pipeline culminating in scalable reinforcement learning with a meticulously designed, multi-domain reward system is a highly effective strategy for creating state-of-the-art, versatile VLMs, with the open-source model providing a strong practical foundation. |
| MoCa: Modality-aware Continual Pre-training Makes Better Bidirectional
  Multimodal Embeddings (Read more on [arXiv](https://arxiv.org/abs/2506.23115) or [HuggingFace](https://huggingface.co/papers/2506.23115))| Nan Yang, Liang Wang, roosephu, hongliu9903, Haon-Chen | The paper introduces MoCa, a two-stage framework for converting pre-trained causal Vision Language Models (VLMs) into more effective bidirectional multimodal embedding models. The research objective is to address the suboptimal performance of causal attention for embedding tasks and the scalability limitations of contrastive learning by developing a method that leverages bidirectional attention and large-scale unlabeled data. The methodology consists of: 1) Modality-aware Continual Pre-training, which uses a joint reconstruction objective (Masked Language Modeling for text and Masked Autoencoding for images) on unlabeled data to enable bidirectional reasoning, and 2) Heterogeneous Contrastive Fine-tuning on diverse data pairs to improve alignment. The resulting MoCa-7B model establishes a new state-of-the-art on the MMEB benchmark with an average score of 71.5, outperforming the prior best model. The principal implication for AI practitioners is that this framework offers a scalable pathway to adapt powerful, existing causal VLMs into superior bidirectional embedding models without requiring training from scratch, effectively leveraging vast amounts of unlabeled multimodal data. |
| SciArena: An Open Evaluation Platform for Foundation Models in
  Scientific Literature Tasks (Read more on [arXiv](https://arxiv.org/abs/2507.01001) or [HuggingFace](https://huggingface.co/papers/2507.01001))| Sihong Wu, zihang93, HughieHu, maxzky, yilunzhao | The paper introduces SciArena, an open, community-driven platform for evaluating foundation models on literature-grounded scientific tasks using pairwise human preference voting. The primary objective is to create a reliable and dynamic evaluation platform for foundation models performing open-ended scientific literature synthesis and to use the collected data to build a meta-evaluation benchmark, `SciArena-Eval`, for assessing automated evaluators. The platform uses a Retrieval-Augmented Generation (RAG) system to provide two anonymous model outputs for a user's scientific query, collecting over 13,000 preference votes from 102 vetted researchers, and then ranks models using a Bradley-Terry model to calculate Elo ratings. The `o3` model achieved the highest Elo score (1172.5) on the SciArena leaderboard; however, when used as an automated judge on the `SciArena-Eval` benchmark, this top model only achieved 65.1% accuracy in aligning with human expert preferences, indicating a significant challenge in automated evaluation for scientific tasks. Current LLM-as-a-judge evaluation methods are insufficient for specialized scientific domains; AI practitioners should use domain-specific, human-validated benchmarks like `SciArena-Eval` to reliably assess model capabilities for scientific literature synthesis, as standard automated metrics fail to capture critical nuances like citation correctness and technical precision. |
| Does Math Reasoning Improve General LLM Capabilities? Understanding
  Transferability of LLM Reasoning (Read more on [arXiv](https://arxiv.org/abs/2507.00432) or [HuggingFace](https://huggingface.co/papers/2507.00432))| Seungone Kim, Xiaoyu Xu, Yuetai Li, Maggie Huan, aaabiao | This paper investigates the transferability of math reasoning gains in LLMs, finding that Reinforcement Learning (RL) preserves general capabilities while Supervised Fine-Tuning (SFT) often leads to catastrophic forgetting. The objective is to determine if improving LLM performance on mathematical reasoning benchmarks translates to enhanced capabilities in other reasoning and non-reasoning domains, and to identify which fine-tuning methods facilitate this transfer. The study performs a large-scale evaluation of over 20 reasoning-tuned models and conducts controlled experiments fine-tuning a Qwen3-14B model with math-only data using both SFT and RL, analyzing changes via latent-space PCA and token-space KL-divergence. Results show that RL-tuned models successfully transfer reasoning gains, whereas SFT-tuned models do not; in a controlled experiment, an RL-tuned model exhibited positive performance gains on non-reasoning tasks (avg. +7.5%), while its SFT-tuned counterpart showed significant performance degradation (avg. -22.4%) compared to the base model. For AI practitioners, this implies that using SFT with specialized, distilled datasets can degrade general model performance, and RL should be preferred for enhancing specific skills without sacrificing broad, general-domain capabilities. |
| Radial Attention: O(nlog n) Sparse Attention with Energy Decay for
  Long Video Generation (Read more on [arXiv](https://arxiv.org/abs/2506.19852) or [HuggingFace](https://huggingface.co/papers/2506.19852))| Shuo Yang, Haocheng Xi, Tianle Cai, Xingyang Li, Lmxyy | This paper introduces Radial Attention, an O(n log n) sparse attention mechanism that models spatiotemporal energy decay to accelerate long video generation. The primary objective is to mitigate the prohibitive O(nÂ²) computational cost of dense attention in video diffusion models, making the generation of long, high-quality videos computationally feasible. The core methodology involves a static sparse attention mask that implements an exponentially decaying compute density: the attention window for a given token shrinks exponentially with increasing temporal distance from other tokens. For extending generation to 4x longer videos on the HunyuanVideo model, Radial Attention achieves a 3.7x inference speedup and a 4.4x reduction in fine-tuning costs compared to dense attention, while maintaining comparable video quality. For AI practitioners, this method provides a direct way to reduce the computational cost of long video generation, enabling existing pre-trained models to be efficiently adapted for longer sequences with minimal fine-tuning overhead. |
| DiffuCoder: Understanding and Improving Masked Diffusion Models for Code
  Generation (Read more on [arXiv](https://arxiv.org/abs/2506.20639) or [HuggingFace](https://huggingface.co/papers/2506.20639))| Navdeep Jaitly, Jiatao Gu, Huangjie Zheng, Ruixiang Zhang, Shansan Gong | This paper introduces DiffuCoder, a 7B diffusion language model for code, and a novel reinforcement learning method, coupled-GRPO, which improves performance by reducing variance in policy gradient estimation. The main objective is to demystify the decoding behavior of masked diffusion language models (dLLMs) for code generation and develop a diffusion-native reinforcement learning (RL) framework to unlock their potential. The methodology involves training a 7B dLLM named DiffuCoder, introducing "autoregressive-ness" (AR-ness) metrics to analyze its decoding patterns, and proposing coupled-GRPO, an RL algorithm that uses a coupled-sampling scheme with complementary masks (an application of antithetic variates) for low-variance policy gradient estimation. The primary result is that training with coupled-GRPO significantly improves DiffuCoder's performance, achieving a +4.4 absolute point increase on the EvalPlus benchmark over the instruction-tuned version. Furthermore, the GRPO-trained model shows a smaller performance drop when decoding steps are halved, indicating increased parallelism. The principal implication for AI practitioners is that coupled-GRPO provides an effective method for applying reinforcement learning directly to dLLMs for tasks like code generation, enhancing performance while respecting their non-autoregressive nature. The finding that sampling temperature affects generation order, not just token choice, offers a new lever for creating diverse rollouts for RL. |
| HumanOmniV2: From Understanding to Omni-Modal Reasoning with Context (Read more on [arXiv](https://arxiv.org/abs/2506.21277) or [HuggingFace](https://huggingface.co/papers/2506.21277))| Weixuan Chen, Shimin Yao, BBBBCHAN, fushh7, PhilipC | This paper introduces HumanOmniV2, an omni-modal model that enhances reasoning by first requiring an explicit summary of multimodal context. The research objective is to mitigate two primary failure modes in existing models: insufficient global context understanding and reasoning shortcuts that ignore multimodal inputs. The methodology utilizes Reinforcement Learning based on Group Relative Policy Optimization (GRPO), uniquely augmented with LLM-judged context and logical rewards, which assess the quality of the model's generated context summary and its subsequent reasoning path. HumanOmniV2 achieves state-of-the-art performance among open-source models, scoring 58.47% on the Daily-Omni benchmark and 69.33% on the authors' new IntentBench. For AI practitioners, this work implies that structuring model outputs to first articulate context and then applying targeted RL rewards to that articulation is a potent technique for improving complex, multimodal reasoning and reducing hallucinatory or incomplete responses. |
| Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive
  Foundations for Artificial General Intelligence and its Societal Impact (Read more on [arXiv](https://arxiv.org/abs/2507.00951) or [HuggingFace](https://huggingface.co/papers/2507.00951))| Abbas Shah, Ranjan Sapkota, Rizwan Qureshi, amanchadha, shainaraza | This paper synthesizes research across AI and cognitive science to argue that AGI requires moving beyond token-level prediction towards integrated, brain-inspired cognitive architectures. The primary objective is to analyze the limitations of current large-scale models and define a roadmap for AGI based on principles like modular reasoning, persistent memory, and grounded agency. The methodology is a cross-disciplinary synthesis and analysis of existing literature from artificial intelligence, cognitive neuroscience, psychology, and agent-based systems. The paper concludes that true intelligence emerges from the integration of cognitive components, not from scaling alone, highlighting that applying Tree-of-Thoughts (ToT) to GPT-4 increased its success rate on a combinatorial puzzle to 74% from 4% using Chain-of-Thought (CoT). The principal implication for AI practitioners is to shift from scaling monolithic models towards architecting modular, agentic systems that integrate structured reasoning, persistent memory, and dynamic tool use to build more capable and grounded AI. |
| Data Efficacy for Language Model Training (Read more on [arXiv](https://arxiv.org/abs/2506.21545) or [HuggingFace](https://huggingface.co/papers/2506.21545))| Chong Li, Wenshan Wu, Xin Zhang, Yangyu Huang, Yalun Dai | This paper introduces "Data Efficacy," a paradigm for improving language model performance by optimizing the organization of training data. The primary research objective is to define and validate a new paradigm, DELT (Data Scoring, Selection, and Ordering), that maximizes model performance by strategically ordering training data, complementing existing data efficiency techniques focused on data selection. The key methodology involves a three-stage process: 1) Data Scoring, using a novel Learnability-Quality Scoring (LQS) method based on gradient consistency to evaluate each sample's learnability and quality; 2) Optional Data Selection; and 3) Data Ordering, using a proposed Folding Ordering (FO) method, which applies multi-pass curriculum learning to mitigate model forgetting and data distribution bias. The primary result demonstrates that the proposed DELT instance (LQS for scoring and FO for ordering) consistently improves model performance; on a 160M parameter model, it achieved a 1.65% absolute improvement in average accuracy across eight benchmarks (38.02% vs. 36.37% for the conventional baseline) without altering the dataset or model size. The principal implication for AI practitioners is that optimizing the sequence of training data is a highly effective, low-cost strategy to enhance model performance. Instead of relying solely on random shuffling, engineers can implement a structured data ordering scheme like LQS+FO to achieve superior results from existing datasets and model architectures, making it a powerful tool for both efficacy and efficiency. |
| FreeLong++: Training-Free Long Video Generation via Multi-band
  SpectralFusion (Read more on [arXiv](https://arxiv.org/abs/2507.00162) or [HuggingFace](https://huggingface.co/papers/2507.00162))| Yi Yang, Yu Lu | FreeLong++ is a training-free framework for extending short-video generation models to produce longer, high-fidelity videos by fusing multi-scale temporal features in the frequency domain. The research objective is to mitigate the high-frequency distortion and temporal inconsistency that arise when applying pre-trained short-video models to longer sequences without additional training. The key methodology is Multi-band SpectralFusion (MSF), which uses multiple attention branches with varying temporal window sizes to capture dynamics at different scales, followed by fusing their outputs in the frequency domain using scale-specific band-pass filters. On the Wan-2.1 model extended to 4x its native length, FreeLong++ achieved an Imaging Quality score of 68.82, outperforming direct sampling (60.52) and the prior FreeNoise method (67.00). For AI practitioners, the principal implication is that FreeLong++ offers a plug-and-play module to adapt existing video diffusion models for high-quality, long-form video generation, bypassing the need for costly retraining by directly addressing signal degradation in the frequency domain. |
| Peccavi: Visual Paraphrase Attack Safe and Distortion Free Image
  Watermarking Technique for AI-Generated Images (Read more on [arXiv](https://arxiv.org/abs/2506.22960) or [HuggingFace](https://huggingface.co/papers/2506.22960))| Vasu Sharma, Shashwat Bajpai, Ashhar Aziz, Shreyas Dixit, amanchadha | This paper introduces PECCAVI, a distortion-free image watermarking technique designed to be resilient against generative visual paraphrase attacks. The primary objective is to develop a watermarking method that can withstand removal by visual paraphrase attacks, where a generative model alters an image's visual style while preserving its core semantic content. The methodology identifies stable semantic regions called Non-Melting Points (NMPs) using saliency detection (XRAI) and intersection analysis across multiple paraphrased image versions, then embeds multi-channel, frequency-domain watermarks into these NMPs, and uses noisy burnishing to prevent reverse-engineering. The primary result shows PECCAVI's superior robustness; against a visual paraphrase attack of strength 0.2, it achieved an Average Watermark Detection Probability (WDP) of 0.87, outperforming the state-of-the-art method ZoDiac which scored 0.70. The principal implication for AI practitioners is that this technique provides a more durable method for watermarking AI-generated content, making it more resilient to removal by other generative models; the most impactful finding is that embedding watermarks in semantically invariant regions (NMPs) is a highly effective strategy against content-aware de-watermarking attacks. |
