

## Papers for 2025-07-24

| Title | Authors | Summary |
|-------|---------|---------|
| Pixels, Patterns, but No Poetry: To See The World like Humans (Read more on [arXiv](https://arxiv.org/abs/2507.16863) or [HuggingFace](https://huggingface.co/papers/2507.16863))| Xinhao Li, Jingyi Tang, Lin Xu, Zihao Huang, Hongcheng Gao | This paper introduces the Turing Eye Test (TET) benchmark to demonstrate that state-of-the-art Multimodal Large Language Models (MLLMs) have fundamental failures in human-like visual perception, distinct from their reasoning abilities. The primary objective is to evaluate whether current MLLMs can perceive the world as humans do by shifting the focus from reasoning-heavy benchmarks to tasks requiring intuitive visual perception. The authors created the Turing Eye Test (TET), a benchmark with four synthetic image tasks (HiddenText, 3DCaptcha, ColorBlind, ChineseLigatures) that are simple for humans but designed to challenge MLLM perception, and analyzed failures using Grad-CAM and selective supervised fine-tuning of model components. The study reveals catastrophic failures, with most of the 15 tested MLLMs achieving near-zero performance; for instance, on the HiddenText and 3DCaptcha tasks, nearly all models scored 0% on the Pass@1 metric, while fine-tuning only the vision encoder boosted accuracy from 0% to over 86% on HiddenText for Qwen2.5-VL-7B. The principal implication for AI practitioners is that overcoming these perceptual deficits requires fundamentally enhancing the vision encoder's generalization capabilities, as current models and fine-tuning strategies focused on the language backbone are ineffective for these tasks. |
| Yume: An Interactive World Generation Model (Read more on [arXiv](https://arxiv.org/abs/2507.17744) or [HuggingFace](https://huggingface.co/papers/2507.17744))| Zhen Li, Shaoheng Lin, Xiaofeng Mao, kpzhang, Jiangmiao | i) A 1-line summary: Yume is an interactive world generation model that synthesizes an infinitely explorable, dynamic world from a single image, controlled by keyboard inputs. ii) Main research question or objective: The primary objective is to develop a high-fidelity, interactive video generation framework that allows users to explore a dynamic world created from a static image by translating discrete keyboard actions into controllable camera motions. iii) Key methodology used: The methodology integrates a Masked Video Diffusion Transformer (MVDT) for autoregressive generation with a Quantized Camera Motion (QCM) module that converts keyboard inputs into textual conditions, and employs advanced samplers like the training-free Anti-Artifact Mechanism (AAM) and Time-Travel SDE (TTS-SDE) to enhance visual quality. iv) Primary results (include at least one specific quantitative finding): In comparative evaluations on the Yume-Bench benchmark, the model demonstrated superior controllability, achieving an instruction-following score of 0.657, significantly outperforming prior models like Wan-2.1 (0.057) and MatrixGame (0.271). v) Principal implication for AI practitioners: AI practitioners can use the Quantized Camera Motion (QCM) technique to implement intuitive, text-based camera control in video diffusion models without architectural changes, providing a practical method for creating interactive generative experiences. The most impactful finding is the high degree of user control achieved by converting discrete keyboard inputs into textual prompts, directly relevant for developing controllable AI-driven simulations and virtual environments. |
| DesignLab: Designing Slides Through Iterative Detection and Correction (Read more on [arXiv](https://arxiv.org/abs/2507.17202) or [HuggingFace](https://huggingface.co/papers/2507.17202))| Shingo Takamatsu, Jaegul Choo, Yotaro Shimose, Heng Wang, YeolJoo | DesignLab is an iterative framework that refines presentation slides by using two specialized LLMs, a reviewer to detect design flaws and a contributor to correct them. The main objective is to create an automated system that models the real-world iterative design process to progressively refine rough presentation drafts into polished slides, overcoming the limitations of single-step generation methods. The methodology involves decomposing the design process into two roles, a "design reviewer" and a "design contributor," implemented by fine-tuning separate Qwen2.5-1.5B models on a JSON representation of slides; training data is generated by applying controlled perturbations to polished slides to simulate rough drafts. In a GPT-4o preference evaluation, DesignLab was chosen over the commercial PowerPoint Designer in 51.9% of cases and over the agent-based AutoPresent in 72.7% of cases. The principal implication for AI practitioners is that decomposing a complex generative task into an iterative cycle of explicit detection and correction, trained on synthetically imperfect data, provides a powerful and generalizable framework for refinement tasks, particularly when paired draft-to-final training data is unavailable. |
| Can One Domain Help Others? A Data-Centric Study on Multi-Domain
  Reasoning via Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2507.17512) or [HuggingFace](https://huggingface.co/papers/2507.17512))| Conghui He, Honglin Lin, Zhuoshi Pan, blue01223, yu0226 | This study systematically investigates multi-domain reasoning in large language models using reinforcement learning, analyzing the effects of data combinations, training strategies, and reward design across math, code, and puzzle domains. The primary objective is to understand the interplay, including synergistic and conflicting effects, among different reasoning skills (math, code, puzzles) when training LLMs with Reinforcement Learning with Verifiable Rewards (RLVR), and to identify factors that optimize multi-domain performance. The study employs the Group Relative Policy Optimization (GRPO) algorithm on Qwen-2.5-7B models, using domain-specific datasets to evaluate single-domain, dual-domain, and triple-domain training configurations against benchmarks like MATH500 and HumanEval. The paper finds that combining data from all three domains (Math, Code, Puzzle) achieves the highest overall average performance and improves task balance, mitigating the catastrophic forgetting observed in dual-domain settings, such as a 22.56 point drop in code performance when combining only Math and Puzzle data. The principal implication for AI practitioners is that training on a diverse, multi-domain dataset is crucial for building robust, generalized models that avoid catastrophic forgetting, even though this may slightly reduce peak performance on a single specialized task. Careful data mixture design and consistent use of training/evaluation templates are critical for reliable outcomes. |
| Re:Form -- Reducing Human Priors in Scalable Formal Software
  Verification with RL in LLMs: A Preliminary Study on Dafny (Read more on [arXiv](https://arxiv.org/abs/2507.16331) or [HuggingFace](https://huggingface.co/papers/2507.16331))| Xin Li, Xu Xu, Xuhan Huang, Fengdi Che, Chuanhao Yan | The Re:Form framework trains LLMs for formal software verification in Dafny by using Reinforcement Learning with automated feedback from the language's verifier, thereby reducing the need for human-annotated data and chain-of-thought reasoning. The primary objective is to create a scalable pipeline for generating provably correct software specifications by enabling models to learn directly from a formal system instead of human priors. The key methodology involves an initial Supervised Fine-Tuning (SFT) stage on automatically curated data, followed by an RL phase that uses a novel "subset reward"—derived from the Dafny verifier—to guide the model toward generating logically stronger specifications. This approach enables a 14B RL-trained model to achieve a 14.0% pass@1 verification rate on the out-of-domain `DafnyComp` benchmark, significantly outperforming the 8.3% rate of its SFT counterpart and discovering novel specifications not seen during training. For AI practitioners, this work implies that a system's internal verifier can provide a powerful and scalable reward signal for RL in formal domains, enabling the autonomous generation of high-quality, provably correct artifacts without extensive human supervision. |
| Ultra3D: Efficient and High-Fidelity 3D Generation with Part Attention (Read more on [arXiv](https://arxiv.org/abs/2507.17745) or [HuggingFace](https://huggingface.co/papers/2507.17745))| Qin Li, Hu Zhang, Yikai Wang, Zhihao Li, Yiwen Chen | ULTRA3D introduces an efficient framework for high-fidelity 3D generation by optimizing sparse voxel modeling. The primary objective is to mitigate the severe computational inefficiency caused by the quadratic complexity of global attention mechanisms in two-stage 3D diffusion pipelines. The methodology involves a two-stage process: first, generating a coarse object layout using the compact VecSet representation, and second, refining per-voxel latent features using "Part Attention," a localized attention mechanism that restricts computation to semantically coherent part regions. This approach achieves a 6.7x speed-up in latent generation and a 3.3x overall pipeline speed-up, with user studies showing a 68.5% preference for ULTRA3D over concurrent methods. The principal implication for AI practitioners is that leveraging geometry-aware localized attention can significantly reduce the computational cost of high-resolution 3D generation, making the production of detailed 3D assets more tractable and scalable. |
| Elevating 3D Models: High-Quality Texture and Geometry Refinement from a
  Low-Quality Model (Read more on [arXiv](https://arxiv.org/abs/2507.11465) or [HuggingFace](https://huggingface.co/papers/2507.11465))| Jiyun Won, chosh1110, joohaeng, gongms, terryryu | The paper introduces Elevate3D, a framework that iteratively refines the texture and geometry of low-quality 3D models using a novel diffusion-based method and monocular geometry prediction. The primary objective is to transform readily accessible but low-quality 3D assets into high-quality, well-aligned models by addressing the limitations of prior refinement techniques. The methodology is a view-by-view iterative process: first, it uses High-Frequency-Swapping SDEdit (HFS-SDEdit) to enhance texture by guiding a diffusion model with high-frequency details from the input; second, it leverages the refined texture to predict a detailed normal map, which is then integrated into the mesh using a regularized normal integration scheme to update the geometry. On the GSO dataset, Elevate3D quantitatively outperforms recent competitors, achieving a MUSIQ score of 66.527 compared to the next-best score of 61.667 from DreamGaussian. For AI practitioners, this framework provides an automated pipeline to significantly upgrade the quality of large-scale 3D asset datasets, making them suitable for high-fidelity graphics applications and for use as improved training data for 3D vision systems. |
| Finding Dori: Memorization in Text-to-Image Diffusion Models Is Less
  Local Than Assumed (Read more on [arXiv](https://arxiv.org/abs/2507.16880) or [HuggingFace](https://huggingface.co/papers/2507.16880))| Adam Dziedzic, Kristian Kersting, Dominik Hintersdorf, lukas-struppek, antoniaaa | This paper demonstrates that memorization in text-to-image diffusion models is a non-local phenomenon, showing that existing weight-pruning mitigations can be circumvented by adversarial inputs, and proposes a robust adversarial fine-tuning solution. The main objective is to assess the robustness of pruning-based memorization mitigation techniques and challenge the assumption that memorization is localized in the model. The authors use an adversarial optimization process to find text embeddings that can re-trigger data replication even after mitigation has been applied, and they analyze the distribution of these embeddings and their internal activation patterns. The primary result shows that while pruning methods like NeMo reduce replication similarity (SSCD score) from 0.90 to 0.33, crafted adversarial embeddings can restore the replication similarity to 0.91, proving the mitigation is not a true erasure of the memorized content. The principal implication for AI practitioners is that weight-pruning techniques are insufficient for robustly removing memorized data, and more comprehensive methods like the proposed adversarial fine-tuning are required to ensure models do not inadvertently replicate sensitive or copyrighted content. |
| RAVine: Reality-Aligned Evaluation for Agentic Search (Read more on [arXiv](https://arxiv.org/abs/2507.16725) or [HuggingFace](https://huggingface.co/papers/2507.16725))| Jinhua Gao, Zhi Zheng, Xiang Long, sapphirex | This paper proposes RAVine, a comprehensive evaluation framework to assess agentic search systems by aligning with realistic user queries, enabling precise fine-grained evaluation, and analyzing the iterative search process. The research objective is to create a more realistic evaluation sandbox for agentic LLMs that addresses the misalignment between existing benchmarks and real-world search tasks, particularly regarding query complexity, evaluation granularity, and process-oriented metrics. The methodology uses a static web environment (MS MARCO V2.1) and real-world queries (TREC 2024 RAG Track), introducing an attributable nugget collection method via dynamic semantic clustering for ground truth construction and a block-level evaluation scheme to jointly measure task completeness and citation faithfulness. Experiments show current agentic LLMs have limited faithfulness; for instance, the Qwen3-32B model achieved a maximum citation recall of only 13.2%, and a significant portion of task performance relies on non-attributable internal model knowledge. The principal implication for AI practitioners is that developing robust agentic search systems requires focusing on improving intermediate process behaviors, such as information gathering and citation accuracy, as final answer quality is not solely dependent on search performance and current models are deficient in these areas. |
