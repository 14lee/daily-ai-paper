

## Papers for 2025-07-25

| Title | Authors | Summary |
|-------|---------|---------|
| Group Sequence Policy Optimization (Read more on [arXiv](https://arxiv.org/abs/2507.18071) or [HuggingFace](https://huggingface.co/papers/2507.18071))| Bowen Yu, Xiong-Hui Chen, Mingze Li, Shixuan Liu, Chujie Zheng | This paper introduces Group Sequence Policy Optimization (GSPO), an RL algorithm that stabilizes large language model training by performing optimization using sequence-level likelihood ratios instead of token-level ones. The primary objective is to develop a stable and efficient RL algorithm that overcomes the model collapse issues observed in methods like Group Relative Policy Optimization (GRPO), especially when training large Mixture-of-Experts (MoE) models. The key methodology is to define the importance sampling ratio based on the likelihood of the entire generated sequence (`s_i(θ) = π_θ(y_i|x) / π_θ_old(y_i|x)`) and apply this single ratio for sequence-level clipping, rewarding, and optimization, thereby aligning the optimization unit with the sequence-level reward. GSPO demonstrates superior training efficiency and stability over GRPO; quantitatively, it clips a token fraction of 0.15, two orders of magnitude higher than GRPO's 0.0013, while achieving better performance, indicating a more reliable learning signal. For AI practitioners, GSPO provides a more robust algorithm for RLHF that fundamentally resolves instability in MoE model training without needing complex workarounds like Routing Replay, and it can potentially simplify RL infrastructure by reducing the need for likelihood recomputation. |
| LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy
  Optimization (Read more on [arXiv](https://arxiv.org/abs/2507.15758) or [HuggingFace](https://huggingface.co/papers/2507.15758))| Linjuan Wu, Shangke Lyu, Xingyu Wu, tricktreat, yanyc | This paper introduces Length-Adaptive Policy Optimization (LAPO), a framework for training large language models to intrinsically control their reasoning length based on problem complexity. The research objective is to address the "overthinking" phenomenon in LLMs by enabling them to autonomously determine an appropriate reasoning depth for a given task, rather than relying on external constraints. LAPO utilizes a two-stage reinforcement learning process where a "Discovery" stage first learns the statistical distribution of successful solution lengths, and a subsequent "Internalization" stage trains the model to generate and adhere to a self-proposed length budget embedded within its reasoning context. Experiments show that LAPO reduces token usage by up to 40.9% while simultaneously improving accuracy by 2.3% on mathematical reasoning benchmarks. For AI practitioners, this framework offers a method to fine-tune models for greater computational efficiency and cost-effectiveness by enabling them to self-regulate reasoning effort based on problem difficulty, thereby making them more practical for deployment. |
| MUR: Momentum Uncertainty guided Reasoning for Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2507.14958) or [HuggingFace](https://huggingface.co/papers/2507.14958))| Jian Zhang, Yifei Li, Rongman Xu, Fangzhi Xu, Hang Yan | This paper introduces Momentum Uncertainty-guided Reasoning (MUR), a training-free algorithm that adaptively applies test-time scaling to LLMs to reduce computational overhead while improving reasoning performance. The main objective is to efficiently and adaptively guide LLM test-time scaling without additional training, thereby mitigating the "overthinking" problem where models waste tokens on redundant computations. The key methodology involves calculating momentum uncertainty, an exponentially weighted average of step-level uncertainties, which acts as a dynamic threshold to trigger compute-intensive scaling only for critical reasoning steps. Results demonstrate that across four benchmarks and three model sizes, MUR reduces computation by over 50% on average while improving accuracy by 0.62-3.37% compared to methods that scale every step. The principal implication for AI practitioners is that MUR can be implemented as an orthogonal, training-free module with existing test-time scaling methods to significantly decrease inference costs and latency in production for reasoning tasks, without degrading and often enhancing accuracy. |
| TTS-VAR: A Test-Time Scaling Framework for Visual Auto-Regressive
  Generation (Read more on [arXiv](https://arxiv.org/abs/2507.18537) or [HuggingFace](https://huggingface.co/papers/2507.18537))| Yujie Wei, Shiwei Zhang, Yukang Chen, Ruihang Chu, Zhekai Chen | TTS-VAR is a test-time scaling framework that improves visual auto-regressive (VAR) generation by applying scale-dependent path-searching strategies. The main objective is to develop a general, training-free, test-time scaling framework for VAR models to enhance generation quality by addressing the unique challenges of their hierarchical, coarse-to-fine process. The key methodology combines three components: an adaptive descending batch size schedule to manage computational cost, clustering-based diversity search using DINOv2 features at coarse scales to preserve structural variety, and resampling-based potential selection using reward models at fine scales to prioritize high-quality candidates. The primary result is a notable 8.7% improvement in the GenEval score for the Infinity VAR model, from 0.69 to 0.75, which surpasses the performance of conventional Best-of-N (BoN) sampling even with fewer samples. The principal implication for AI practitioners is that the performance of hierarchical generative models like VAR can be significantly enhanced at inference time by applying different optimization strategies to different generation scales—specifically, focusing on diversity at early stages and reward-based selection at later stages. |
| Captain Cinema: Towards Short Movie Generation (Read more on [arXiv](https://arxiv.org/abs/2507.18634) or [HuggingFace](https://huggingface.co/papers/2507.18634))| Yang Zhao, Shengqu Cai, Lvmin Zhang, Ceyuan Yang, Junfei Xiao | Captain Cinema is a framework for generating narratively consistent short movies by first planning a sequence of coherent keyframes from a storyline and then synthesizing video between them. Its main objective is to overcome long-range dependency challenges in video generation by employing a two-stage methodology: a top-down keyframe planner uses a novel "GoldenMem" context compression mechanism, which then conditions a bottom-up video synthesis model. The key methodology, GoldenMem, uses golden-ratio-based downsampling of past visual frames to maintain a fixed-cost, long-term visual memory, enabling stable generation over extended sequences. The framework demonstrates strong long-context performance, maintaining over 93% of its initial consistency score when scaled to 48 context pairs and achieving a temporal dynamics score of 65.4, significantly outperforming a baseline of 51.8. For AI practitioners, this work provides a computationally efficient memory strategy (GoldenMem) and a disentangled architecture for scaling video generation from isolated clips to coherent, story-driven content. |
| EarthCrafter: Scalable 3D Earth Generation via Dual-Sparse Latent
  Diffusion (Read more on [arXiv](https://arxiv.org/abs/2507.16535) or [HuggingFace](https://huggingface.co/papers/2507.16535))| Jing Wang, Wen Qian, Chaohui Yu, Chenjie Cao, ShuYaoLiu | This paper introduces EarthCrafter, a scalable framework for geographic-scale 3D Earth generation, and a new large-scale aerial dataset, Aerial-Earth3D, to support it. The primary objective is to scale 3D generative models to geographic extents by developing a novel data infrastructure and a highly efficient model architecture. The methodology employs a dual-sparse latent diffusion approach that separates structural and textural generation, using dual sparse 3D-VAEs to compress geometric voxels and 2D Gaussian Splats into compact latents, which are then modeled by tailored flow matching networks. The proposed StructVAE achieves 97.1% accuracy in structural reconstruction, demonstrating high fidelity while operating on a spatially compressed latent space. For AI practitioners, this research provides a new architectural pattern for efficiently handling large-scale 3D data generation, along with the largest-to-date, richly annotated 3D aerial dataset (Aerial-Earth3D) for training and benchmarking such models. |
| Hierarchical Budget Policy Optimization for Adaptive Reasoning (Read more on [arXiv](https://arxiv.org/abs/2507.15844) or [HuggingFace](https://huggingface.co/papers/2507.15844))| Xingyu Wu, Linjuan Wu, tricktreat, yanyc, paradox122 | This paper introduces Hierarchical Budget Policy Optimization (HBPO), a reinforcement learning framework for training models to adaptively adjust their reasoning depth to match problem complexity. The objective is to develop a training methodology that enables large reasoning models to learn differentiated, problem-specific reasoning depths, thereby improving computational efficiency without sacrificing performance on complex tasks. The HBPO method partitions the RL exploration space into multiple subgroups, each constrained by a distinct token budget, and uses a piecewise, budget-aware reward function with decomposed advantage computation to guide the model in learning to select appropriate computational effort. Experiments show HBPO reduces average token usage by up to 60.6% while simultaneously improving accuracy by 3.14% across four mathematical reasoning benchmarks, demonstrating emergent adaptive behavior where token allocation correlates with problem difficulty. For AI practitioners, this framework offers a method to train reasoning models that are both more computationally efficient and more capable, overcoming the typical trade-off between performance and inference cost by enabling learned, adaptive resource allocation rather than applying uniform constraints. |
| DriftMoE: A Mixture of Experts Approach to Handle Concept Drifts (Read more on [arXiv](https://arxiv.org/abs/2507.18464) or [HuggingFace](https://huggingface.co/papers/2507.18464))| Ricardo Simón Carbajo, Miguel Aspis, suarezcetrulo, sebasmos | The paper introduces DriftMoE, a novel online Mixture-of-Experts framework using a co-trained neural router and incremental tree experts to adapt to concept drift in data streams. The objective is to develop an adaptive model for non-stationary data streams that overcomes the limitations of existing ensembles by enabling more nuanced expert specialization without relying on explicit drift detectors. DriftMoE co-trains a lightweight neural router alongside a pool of incremental Hoeffding Tree experts; the router gates instances to experts and is then updated using a multi-hot "correctness mask" derived from every expert's prediction accuracy on the instance, providing a cooperative training signal. The framework was evaluated on nine benchmarks against established adaptive ensembles, where the MoE-Data variant achieved a prequential accuracy of 70.33% on the Airlines dataset, outperforming baselines like Adaptive Random Forest (64.51%) while using fewer experts. For AI practitioners, DriftMoE presents a resource-efficient and highly adaptive alternative to large-scale ensembles for streaming applications, showing that a small pool of specialized experts managed by a co-trained router can achieve competitive or superior performance. |
| Technical Report of TeleChat2, TeleChat2.5 and T1 (Read more on [arXiv](https://arxiv.org/abs/2507.18013) or [HuggingFace](https://huggingface.co/papers/2507.18013))| Yu Zhao, Chao Wang, Yitong Yao, Xinzhang Liu, Zihan Wang | This paper presents TeleChat2, TeleChat2.5, and T1, a series of open-weight 35B and 115B parameter LLMs developed through an enhanced multi-stage training pipeline.  The main objective is to create and publicly release a new series of high-performance LLMs that improve upon their predecessor by systematically upgrading the pre-training and post-training stages to advance capabilities in general tasks, complex reasoning, and coding.  The methodology consists of pre-training a base model on 10 trillion tokens, followed by a pipeline including continual pre-training on domain-specific data, Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and a final Reinforcement Learning (RL) stage to explicitly enhance mathematical and coding abilities.  The primary results show that the models are competitive with or outperform leading proprietary systems; specifically, the T1-115B model achieves a score of 94.0 on the MATH500 benchmark in thinking mode, surpassing OpenAI's o1-mini model's score of 90.0.  The principal implication for AI practitioners is the public release of these 35B and 115B models, providing open access to state-of-the-art LLMs. This allows engineers to leverage and fine-tune powerful foundation models for complex reasoning, coding, and instruction-following applications without dependency on closed-source APIs. |
| A New Pair of GloVes (Read more on [arXiv](https://arxiv.org/abs/2507.18103) or [HuggingFace](https://huggingface.co/papers/2507.18103))| Christopher D. Manning, John Bauer, Riley Carlson | This paper presents and evaluates new 2024 GloVe word embedding models trained on updated corpora to capture contemporary English. The objective was to create and document updated models using recent data (Wikipedia, Gigaword, and a subset of Dolma) and evaluate whether they better represent modern language and improve downstream task performance compared to the original 2014 models. The methodology involved training new GloVe vectors using the original algorithm on these updated corpora and evaluating them through vocabulary comparison, direct analogy/similarity tests, and performance on four NER datasets, including the recent Worldwide and WNUT-17 datasets. The primary result is that while performance on classic analogy tasks was comparable, the 2024 embeddings showed significant improvement on temporally-dependent NER tasks; for example, the 2024 50d Wiki/Giga model achieved a per-entity F1 score of 84.64 on the Worldwide dataset, compared to 82.1 for the 2014 version. The principal implication for AI practitioners is that these 2024 GloVe embeddings are better suited for modern NLP applications, especially those dealing with recent text or requiring recognition of contemporary entities, as they reduce out-of-vocabulary issues and improve performance on such tasks. |
| DMOSpeech 2: Reinforcement Learning for Duration Prediction in
  Metric-Optimized Speech Synthesis (Read more on [arXiv](https://arxiv.org/abs/2507.14988) or [HuggingFace](https://huggingface.co/papers/2507.14988))| Kaifeng Xu, Cheng Niu, Fei Tao, Xilin Jiang, Yinghao Aaron Li | DMOSpeech 2 introduces a reinforcement learning framework to optimize the previously isolated duration predictor in diffusion-based text-to-speech (TTS) systems, alongside a teacher-guided sampling method to restore output diversity. The primary objective is to enable end-to-end optimization of a zero-shot TTS pipeline for perceptual metrics by integrating the duration prediction component, which was a critical bottleneck in prior metric-optimized systems. The key methodology involves modeling the duration predictor as a stochastic policy and fine-tuning it with Group Relative Policy Optimization (GRPO), using a reward signal composed of speaker similarity and word error rate. A hybrid "teacher-guided sampling" strategy is also employed, leveraging a teacher model for initial denoising steps to establish prosodic structure and an efficient student model for final acoustic refinement. The proposed method significantly improves performance; on the Seed-TTS-en dataset, optimizing the duration predictor with RL reduced the Word Error Rate (WER) from 3.750 to 1.752 compared to the baseline without RL optimization, while maintaining a low Real-Time Factor (RTF) of 0.0316. The principal implication for AI practitioners is that targeted reinforcement learning can be efficiently applied to specific, non-differentiable components within a larger generative model to optimize for system-level metrics, overcoming the high computational overhead typically associated with applying RL to an entire pipeline. |
| GLiNER2: An Efficient Multi-Task Information Extraction System with
  Schema-Driven Interface (Read more on [arXiv](https://arxiv.org/abs/2507.18546) or [HuggingFace](https://huggingface.co/papers/2507.18546))| Ash Lewis, George Hurn-Maloney, Oliver Boyd, Gil Pasternak, Urchade Zaratiana | GLiNER2 is a unified, CPU-efficient framework that performs named entity recognition, text classification, and hierarchical structured data extraction within a single encoder model using a schema-driven interface. The objective is to develop a single, compact model that performs diverse information extraction tasks to overcome the high computational, cost, and privacy barriers associated with deploying large language models or multiple specialized systems. The system extends the GLiNER architecture by using a pretrained transformer encoder (205M parameters) prompted with a unified input format that uses special tokens to define and compose multiple tasks, trained on a 254,334-example dataset of LLM-annotated and synthetic data. In zero-shot evaluations, GLiNER2 achieves an average F1 score of 0.590 on the CrossNER benchmark, closely matching GPT-4o's score of 0.599, while demonstrating an approximate 2.6x speedup over the GPT-4o API on classification tasks when running on a CPU. The principal implication for AI practitioners is the availability of an open-source, pip-installable library for deploying high-performance, multi-task information extraction on standard CPU hardware, enabling complex, privacy-sensitive applications without reliance on GPUs or costly LLM APIs. |
| TeEFusion: Blending Text Embeddings to Distill Classifier-Free Guidance (Read more on [arXiv](https://arxiv.org/abs/2507.18192) or [HuggingFace](https://huggingface.co/papers/2507.18192))| Zhao Xu, Qing-Guo Chen, Xiaohao Chen, Minghao Fu, Flourish | TeEFusion is a distillation method that accelerates text-to-image generation by fusing conditional and unconditional text embeddings to eliminate the multiple forward passes required by Classifier-Free Guidance (CFG). The objective is to distill the behavior of a teacher model using a complex, multi-pass sampling strategy into a student model that requires only a single forward pass per step, without adding extra model parameters. The methodology involves injecting the guidance signal by linearly combining the conditional and unconditional text embeddings, scaling them by the guidance weight `w`, and feeding this fused representation into the model. The primary result shows that on the SD3 model, a TeEFusion-distilled student achieves comparable or higher HPS aesthetic scores than a teacher using the complex W2SD+CFG sampler, while performing inference up to 6x faster. For AI practitioners, this provides a simple and effective technique to significantly reduce the inference cost and latency of state-of-the-art text-to-image models without compromising the output quality derived from sophisticated sampling algorithms. |
| Discovering and using Spelke segments (Read more on [arXiv](https://arxiv.org/abs/2507.16038) or [HuggingFace](https://huggingface.co/papers/2507.16038))| Luca Thomas Wheeler, Seungwoo Kim, Lilian Naing Chen, Klemen Kotar, Rahul Venkatesh | This paper introduces SpelkeNet, a self-supervised visual world model for discovering motion-defined "Spelke segments" in static images, and demonstrates their utility for physical manipulation tasks.  The main objective is to benchmark the concept of Spelke objects—physically coherent groupings that move together—and develop a self-supervised method to extract them from single images without explicit segmentation labels.  The key methodology involves "statistical counterfactual probing" using SpelkeNet, a model based on the Local Random Access Sequence Modeling (LRAS) framework. The model is prompted with sparse "virtual pokes" (localized optical flow tokens), and it predicts a distribution over future motion fields; Spelke segments are then defined as statistical aggregates of correlated motion from multiple such probes.  On the newly introduced SpelkeBench benchmark for point-prompted segmentation, SpelkeNet achieves a mean Intersection over Union (mIoU) of 0.6811, outperforming supervised baselines like SAM2 (0.6225 mIoU) and other self-supervised methods.  The principal implication for AI practitioners is that motion-defined Spelke segments provide a more physically plausible and functional basis for downstream robotics and manipulation tasks compared to conventional semantic or appearance-based segments, leading to superior performance in object editing and manipulation pipelines. |
| SegDT: A Diffusion Transformer-Based Segmentation Model for Medical
  Imaging (Read more on [arXiv](https://arxiv.org/abs/2507.15595) or [HuggingFace](https://huggingface.co/papers/2507.15595))| Abdenour Hadid, Fadi Dornaika, Gaby Maroun, Bekhouche | The paper introduces SegDT, a compact Diffusion Transformer (DiT) model that uses rectified flow for efficient and accurate medical image segmentation. The objective is to develop a segmentation model for skin lesions that achieves state-of-the-art accuracy while maintaining low computational cost and fast inference speeds for deployment on resource-constrained hardware. SegDT's methodology involves using a pretrained Tiny AutoEncoder (TAESD) to map images to a latent space, which is then processed by a DiT-XS (extra-small) model that learns a velocity field via a rectified flow objective to accelerate the reverse diffusion process. On the ISIC 2018 dataset, SegDT achieved a Dice score of 94.51% with only 3.68 GFLOPs and 9.95M parameters, outperforming heavier models like DU-Net+ (92.93% Dice, 54.00 GFLOPs). The principal implication for AI practitioners is that this architecture provides a blueprint for building high-performance segmentation models that are deployable on low-cost GPUs by significantly reducing computational load and inference steps without sacrificing accuracy. |
| Deep Learning-Based Age Estimation and Gender Deep Learning-Based Age
  Estimation and Gender Classification for Targeted Advertisement (Read more on [arXiv](https://arxiv.org/abs/2507.18565) or [HuggingFace](https://huggingface.co/papers/2507.18565))| Nisar Ahmed, ImranzamanML | This paper proposes custom Convolutional Neural Networks (CNNs) to perform age estimation and gender classification from facial images for targeted advertising applications. The stated objective is to create and evaluate a robust system for both tasks, for which the authors trained two separate CNNs from scratch on the UTK Face dataset after performing data balancing and normalization. The paper reports conflicting performance metrics: for gender classification, it claims 95% accuracy and an ROC AUC of 0.95 in the text, but the corresponding results in Table 2 show only 64% accuracy; for age estimation, a Mean Absolute Error (MAE) of 5.77 years is consistently reported in the text, although this metric is absent from its results table. The principal implication for AI practitioners is the critical need for rigorous result validation, as demonstrated by the paper's internal inconsistencies; furthermore, the reported age estimation error (MAE of 5.77 years) highlights that facial attribute regression remains a challenging task requiring targeted data and model refinements to mitigate demographic biases. |
| Agentar-Fin-R1: Enhancing Financial Intelligence through Domain
  Expertise, Training Efficiency, and Advanced Reasoning (Read more on [arXiv](https://arxiv.org/abs/2507.16802) or [HuggingFace](https://huggingface.co/papers/2507.16802))| Zhaowen Zhou, Xiaoke Zhao, Longfei Liao, Xiyang Du, Yanjun Zheng | The paper introduces Agentar-Fin-R1, a series of 8B and 32B parameter financial large language models optimized for domain-specific expertise, training efficiency, and advanced reasoning. The primary objective is to develop a financial LLM that overcomes the limitations of general-purpose models by systematically enhancing domain-specific reasoning, ensuring trustworthiness, and improving training efficiency. The methodology integrates a structured financial task label system with a two-stage training pipeline (SFT followed by GRPO/SFT refinement), guided by a difficulty-aware weighted training framework that dynamically prioritizes tasks based on empirically measured `pass@k` scores. Experimental results show state-of-the-art performance, with the Agentar-Fin-R1-32B model achieving an overall score of 83.13 and specifically scoring 69.93 on the newly introduced Finova agent benchmark, outperforming both general-purpose and other specialized financial models. The principal implication for AI practitioners is the demonstrated data efficiency of the label-guided, difficulty-aware weighted training framework, which can achieve superior performance to full-data vanilla SFT while using only 50% of the training samples, providing an efficient method for domain specialization without catastrophic forgetting. |
