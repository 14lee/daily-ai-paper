

## Papers for 2025-08-12

| Title | Authors | Summary |
|-------|---------|---------|
| ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability (Read more on [arXiv](https://arxiv.org/abs/2508.07050) or [HuggingFace](https://huggingface.co/papers/2508.07050))| Yuchen Li, Yutao Zhu, Weiwei Sun, Xinyu Ma, Wenhan Liu | The paper introduces ReasonRank, a reasoning-intensive passage reranker that achieves superior performance and efficiency by generating its own training data and using a two-stage training process. The primary objective is to empower listwise rerankers with strong reasoning capabilities to handle complex ranking tasks, addressing the scarcity of suitable training data. The key methodology involves an automated framework to synthesize reasoning-intensive training data using DeepSeek-R1, followed by a two-stage training approach combining Supervised Fine-Tuning (SFT) for pattern learning and Reinforcement Learning (RL) with a novel multi-view ranking reward (NDCG@10, Recall@10, RBO). ReasonRank (32B) achieves a state-of-the-art average NDCG@10 of 40.6 on the BRIGHT benchmark, and the 7B model is 2-2.7x faster than the pointwise reasoning reranker Rank1 (7B). The principal implication for AI practitioners is that this framework provides a blueprint for creating highly effective and efficient reasoning-based rerankers; by synthesizing specialized data and using a listwise reasoning approach, they can significantly improve ranking accuracy on complex queries while simultaneously reducing inference latency, making such models more viable for production systems. |
| WideSearch: Benchmarking Agentic Broad Info-Seeking (Read more on [arXiv](https://arxiv.org/abs/2508.07999) or [HuggingFace](https://huggingface.co/papers/2508.07999))| Yan Gao, Li Chen, Junjie Zhao, Jiawei Wang, Ryan Wong | This paper introduces WideSearch, a benchmark for evaluating AI agents on large-scale, broad information-seeking tasks, revealing critical deficiencies in current state-of-the-art systems. The objective is to evaluate the reliability and completeness of LLM-powered agents on "wide-context" information collection tasks, which require gathering, verifying, and structuring a large volume of atomic facts from the web. The authors constructed the WideSearch benchmark with 200 tasks requiring agents to populate predefined tables using web search tools, and developed a hybrid automated evaluation pipeline to score submissions on table-level Success Rate (SR), row-level F1, and item-level F1 metrics. The primary result is that current systems fail at these tasks; across more than 10 tested systems, the best-performing multi-agent framework achieved an average Success Rate of only 5.1%, while a single human achieved 20%. A scaling analysis showed that even with 128 attempts, the item-level F1 score approached 80% while the SR remained below 20%, pinpointing the core difficulty as achieving perfect data completeness and accuracy, not finding individual facts. The principal implication for AI practitioners is that current agentic frameworks are unsuitable for reliable, large-scale data gathering due to fundamental flaws in planning, reflection, and evidence utilization. Development should prioritize more sophisticated architectures, particularly multi-agent systems capable of parallel search and cross-validation, as the benchmark demonstrates that these systemic deficiencies cannot be overcome by simply increasing compute or retries. |
| Omni-Effects: Unified and Spatially-Controllable Visual Effects
  Generation (Read more on [arXiv](https://arxiv.org/abs/2508.07981) or [HuggingFace](https://huggingface.co/papers/2508.07981))| Xiaokun Feng, Dongxia Liu, Jintao Chen, Aiming Hao, Fangyuan Mao | Omni-Effects introduces a unified framework for generating multiple, simultaneous, and spatially-controllable visual effects (VFX) in videos using a diffusion-based model. The objective is to overcome the limitations of single-effect generation by enabling the concurrent synthesis of multiple, spatially-distinct VFX within a single video without cross-effect interference. The core methodology combines two innovations: a LoRA-based Mixture of Experts (LoRA-MoE) to partition diverse effects into specialized, collaboratively trained subspaces, and a Spatial-Aware Prompt (SAP) augmented with an Independent-Information Flow (IIF) attention mask to embed spatial control and isolate information flow between different conditions. In multi-VFX generation experiments, Omni-Effects achieved a 0.50 Effect Controllability Rate (ECR) for a simultaneous "Melt+Explode" task, significantly outperforming the CogV+CN baseline which scored 0.08. The principal implication for AI practitioners is that the LoRA-MoE and SAP-IIF architecture provides a robust method for building unified models for complex, multi-conditional generation tasks, demonstrating how to effectively manage and isolate multiple control signals to prevent interference and concept bleeding without requiring separate models for each condition. |
| Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving
  Clipping Policy Optimization (Read more on [arXiv](https://arxiv.org/abs/2508.07629) or [HuggingFace](https://huggingface.co/papers/2508.07629))| Guanting Dong, Dening Liu, Xue Bai, Leiyu Pan, Zhenpeng Su | Klear-Reasoner is an 8B-parameter model achieving state-of-the-art reasoning capabilities in math and coding via quality-centric SFT and Gradient-Preserving Clipping Policy Optimization (GPPO). The paper aims to advance reasoning capabilities and address limitations of existing RL clipping mechanisms, particularly regarding high-entropy token clipping and delayed convergence from negative samples. Klear-Reasoner employs a long Chain-of-Thought Supervised Fine-Tuning (SFT) strategy prioritizing high-quality data, followed by Reinforcement Learning (RL) with the proposed Gradient-Preserving Clipping Policy Optimization (GPPO) which backpropagates bounded gradients from clipped tokens, and integrates an SFT loss component, along with a soft reward mechanism for coding tasks. Klear-Reasoner-8B achieved 90.5% on AIME 2024 and 66.0% on LiveCodeBench V5, outperforming models like Qwen3-8B and DeepSeek-R1-0528-Distill-8B; ablations showed that for hard tasks, incorporating incorrect examples surprisingly improved performance. AI practitioners should prioritize data quality over surface-level diversity in SFT, consider incorporating mixed-correctness data for difficult tasks, and explore advanced RL clipping methods like GPPO, which preserve critical gradient information, for more stable and effective policy optimization in complex reasoning domains. |
| UserBench: An Interactive Gym Environment for User-Centric Agents (Read more on [arXiv](https://arxiv.org/abs/2507.22034) or [HuggingFace](https://huggingface.co/papers/2507.22034))| Jianguo Zhang, Zhiwei Liu, Akshara Prabhakar, Zuxin Liu, Cheng Qian | This paper introduces UserBench, an interactive gym environment for evaluating an LLM agent's ability to collaborate with users by handling underspecified, incremental, and indirect goals. The core methodology is a Gymnasium-based travel planning simulation where an agent must use tools and proactive dialogue to uncover a simulated user's evolving, implicitly stated preferences. The primary result from evaluating leading LLMs is a severe disconnect between tool proficiency and user alignment; even the most advanced models actively elicited fewer than 30% of all user preferences. For AI practitioners, this demonstrates that proficiency in tool execution does not guarantee user satisfaction, highlighting a critical need to develop agents with communicative intelligence for proactive clarification and dynamic intent modeling. |
| SONAR-LLM: Autoregressive Transformer that Thinks in Sentence Embeddings
  and Speaks in Tokens (Read more on [arXiv](https://arxiv.org/abs/2508.05305) or [HuggingFace](https://huggingface.co/papers/2508.05305))| Anton Razzhigaev, Andrey Kuznetsov, Elizaveta Goncharova, Temurbek Rahmatullaev, Nikita Dragunov | The paper introduces SONAR-LLM, a decoder-only Transformer that generates text by predicting sentence embeddings while being supervised by token-level cross-entropy propagated through a frozen decoder. The main objective is to create a sentence-level generative model that combines the semantic abstraction of concept-based models with the stable, likelihood-based training of traditional token-level LLMs. The key methodology involves autoregressively predicting a continuous SONAR sentence embedding, which is then passed through a fixed SONAR decoder to obtain token logits for a standard cross-entropy loss calculation, a process the authors term a "Token-Aware Embedding Objective." Primary results show that SONAR-LLM outperforms existing sentence-level baselines on summarization, achieving a ROUGE-L score of 19.3 on XSum, which is competitive with or slightly better than a standard token-level LLM (18.7-18.9). The principal implication for AI practitioners is that SONAR-LLM provides a more computationally efficient architecture for long-context generation, as its inference FLOPs surpass the efficiency of standard LLMs for sequences longer than approximately 4096 tokens by operating on a compressed sequence of sentences. |
| A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm
  Bridging Foundation Models and Lifelong Agentic Systems (Read more on [arXiv](https://arxiv.org/abs/2508.07407) or [HuggingFace](https://huggingface.co/papers/2508.07407))| Xinhao Yi, Yingxu Wang, Xi Zhang, Yanwen Peng, Jinyuan Fang | This survey provides a comprehensive review of self-evolving AI agents, introducing a conceptual framework and guiding principles for their development. The paper's primary objective is to systematically review existing techniques for self-evolving agentic systems by introducing a unified conceptual framework that abstracts the feedback loop underlying their design and evolution. The authors use this framework, along with a proposed four-stage paradigm (MOP, MOA, MAO, MASE) and "Three Laws of Self-Evolving AI Agents" (Endure, Excel, Evolve), to systematically categorize and analyze optimisation techniques for agent components like foundation models, prompts, memory, tools, and workflows. The survey finds that research is progressing from single-component optimisation to unified approaches that jointly optimise prompts, topologies, and models; one cited study (OPTIMA) on multi-agent communication efficiency reported a 2.8× performance gain with less than 10% of the token cost. The principal implication for AI practitioners is that the field is moving beyond static, manually configured agents towards dynamic systems; the paper offers a structured roadmap and taxonomies to design, build, and evaluate autonomous agents that can adapt post-deployment by optimising their components based on environmental feedback. |
| BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of
  Deep-Research Agent (Read more on [arXiv](https://arxiv.org/abs/2508.06600) or [HuggingFace](https://huggingface.co/papers/2508.06600))| Kai Zou, Ping Nie, Shengyao Zhuang, Xueguang Ma, Zijian Chen | The paper introduces BrowseComp-Plus, a benchmark with a fixed, human-verified corpus for the fair and transparent evaluation of deep-research agents by disentangling retrieval and reasoning components. The research objective is to create a standardized benchmark to overcome the fairness and reproducibility issues of existing evaluations that rely on dynamic live web search. The methodology involves constructing a 100k-document corpus for 830 questions via LLM-based evidence gathering, followed by rigorous human verification of supporting documents and mining of challenging negative documents. The primary result demonstrates that retrieval quality is critical to agent performance, as upgrading the retriever from BM25 to Qwen3-Embedding-8B increased the GPT-5 agent's accuracy from 55.9% to 70.1% while reducing search calls. The principal implication for AI practitioners is that the retrieval component is a major performance bottleneck, and investing in superior retrieval models is a crucial strategy for enhancing the accuracy and efficiency of agentic systems. |
| OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks (Read more on [arXiv](https://arxiv.org/abs/2508.05614) or [HuggingFace](https://huggingface.co/papers/2508.05614))| Hongxing Li, Dingming Li, tricktreat, yanyc, wangzx1210 | OmniEAR is a comprehensive framework for benchmarking agent reasoning in embodied tasks, evaluating physical interactions, tool usage, and multi-agent coordination. The main objective is to assess how large language models autonomously reason about capability acquisition and coordination needs from task demands and physical constraints, differing from benchmarks with explicit instructions or predefined tools. The methodology employs EAR-Sim, a text-based environment simulation supporting dynamic capability evolution and physics-constrained collaboration across 1,500 scenarios in EAR-Bench. Primary results show severe performance degradation: success rates drop from 85-96% on explicit instructions to 56-85% for tool reasoning and 63-85% for implicit collaboration, with compound tasks exhibiting over 50% failure rates. This implies current language models lack core embodied reasoning capabilities, requiring novel architectural mechanisms and training approaches beyond universal parameter scaling to advance embodied AI. |
| MolmoAct: Action Reasoning Models that can Reason in Space (Read more on [arXiv](https://arxiv.org/abs/2508.07917) or [HuggingFace](https://huggingface.co/papers/2508.07917))| Shuo Liu, Yuquan Deng, Haoquan Fang, Jiafei Duan, Jason Lee | MolmoAct introduces an open-source, vision-language-action model that performs robotic manipulation by explicitly reasoning in space through a structured, multi-stage generation process. The primary objective is to create a robotic foundation model that improves upon standard end-to-end perception-to-control policies by incorporating an explicit, intermediate reasoning pipeline to enhance generalization, explainability, and interactive steerability. The methodology involves an autoregressive Action Reasoning Model (ARM) that, conditioned on visual input and a language instruction, sequentially generates three token types: (1) depth perception tokens representing the scene's 3D geometry, (2) visual reasoning trace tokens forming a 2D polyline of the planned end-effector path, and (3) low-level action tokens. The model achieves an 86.6% average success rate on the LIBERO benchmark, outperforming all baselines, and in real-world fine-tuning, it shows up to a +22.7% task progression improvement over the πο-FAST baseline on bimanual tasks. For AI practitioners, this paper provides a concrete architecture and open-source implementation demonstrating that structuring a VLM's output to include explicit, decodable intermediate representations for spatial planning leads to superior performance and enables novel, precise user interaction modalities like editable trajectory steering. |
| Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts (Read more on [arXiv](https://arxiv.org/abs/2508.07785) or [HuggingFace](https://huggingface.co/papers/2508.07785))| Tieyuan Chen, Zhanchao Zhou, Xiaodong Chen, Haoxing Chen, Haoyuan Wu | The paper introduces Grove MoE, an architecture designed to improve the computational efficiency of Mixture-of-Experts (MoE) LLMs by enabling dynamic parameter activation based on input complexity. Its core methodology partitions experts into groups, each sharing an "adjugate expert" that is computed only once per group for all activated experts within it, thus dynamically allocating computation. The authors demonstrate this by upcycling a Qwen3-30B-A3B model into GroveMoE-Base (33B parameters), which dynamically activates 3.14–3.28B parameters and achieves a MATH benchmark score of 64.82, surpassing the baseline's 59.75. For AI practitioners, Grove MoE offers a method to enhance model capacity and reasoning performance with a sub-linear increase in computational cost, although the paper explicitly states a custom inference kernel is needed to mitigate the 30% latency overhead observed with their generic implementation and achieve theoretical efficiency. |
| Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via
  Past-Future (Read more on [arXiv](https://arxiv.org/abs/2508.06026) or [HuggingFace](https://huggingface.co/papers/2508.06026))| Qiufeng Wang, Junfeng Fang, Cunxiang Wang, Xin Wang, Yidong Wang | Temporal Self-Rewarding Language Models (Temporal SR) address the critical limitation of vanishing DPO gradients in iterative Self-Rewarding LLM training caused by representational convergence of chosen and rejected responses. The primary objective is to sustain effective preference learning signals by strategically decoupling chosen and rejected samples via past and future model generations. This is achieved through a dual-phase methodology: Anchored Rejection, fixing rejected responses to past initial model outputs, and Future-Guided Chosen, curating chosen samples using next-generation model predictions. Empirical results demonstrate that Temporal SR's Llama3.1-8B achieves a 29.44% win rate on AlpacaEval 2.0, outperforming the Self-Rewarding baseline (19.69%) by 9.75%. This approach provides AI practitioners a more stable and effective paradigm for iterative LLM alignment, enabling robust model improvement with fewer optimization iterations. |
| Reinforcement Learning in Vision: A Survey (Read more on [arXiv](https://arxiv.org/abs/2508.08189) or [HuggingFace](https://huggingface.co/papers/2508.08189))| Qingwei Meng, Kevin Qinghong Lin, Joya Chen, Chen Gao, Weijia Wu | This paper surveys over 200 recent works on applying reinforcement learning to visual and multimodal models, tracing the evolution from RLHF to verifiable reward paradigms. The primary objective is to provide a critical and up-to-date synthesis of the visual reinforcement learning field by formalizing its problems, tracing policy optimization strategies, and organizing recent literature into a coherent taxonomy of four pillars: multimodal large language models, visual generation, unified models, and vision-language-action models. The methodology is a comprehensive survey that analyzes trends in algorithmic design (PPO, GRPO), reward engineering (RLHF, DPO, verifiable rewards), and evaluation protocols, structuring the findings into a principled taxonomy based on task domains and reward paradigms. The survey identifies a key trend towards Reinforcement Learning with Verifiable Rewards (RLVR), where deterministic signals replace human feedback; for example, a visual generation task can use a verifiable reward where a generated mask that attains an IoU ≥ 0.9 with the ground truth is awarded a reward of 1. The principal implication for AI practitioners is that this survey serves as a guide for selecting appropriate RL strategies and evaluation metrics, clarifying the design trade-offs between different policy optimization algorithms (e.g., PPO vs. GRPO) and reward supervision types (e.g., human preference vs. verifiable rewards) for developing visually-grounded agents. |
| Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning (Read more on [arXiv](https://arxiv.org/abs/2508.08221) or [HuggingFace](https://huggingface.co/papers/2508.08221))| Jiaheng Liu, Weixun Wang, Yancheng He, Jiashun Liu, Zihe Liu | This paper systematically evaluates common reinforcement learning techniques for LLM reasoning, introducing "Lite PPO," a minimalist PPO variant that outperforms more complex methods. The main objective is to resolve conflicting RL practices by dissecting the mechanisms of techniques like normalization and loss aggregation to provide clear guidelines for practitioners. Using the ROLL framework, the study conducts isolated experiments on Qwen3-4B/8B models across various data difficulties and mathematical benchmarks to assess the impact of each technique. The primary result shows that Lite PPO, which combines only advantage normalization (group-level mean, batch-level std) and token-level loss aggregation, achieves superior and more stable performance on non-aligned base models compared to technique-heavy algorithms like GRPO and DAPO. The principal implication for AI practitioners is that a simple, critic-free PPO with two targeted techniques can be more effective and robust for fine-tuning base models than complex, over-engineered RL algorithms, challenging the trend of adding more components to optimization pipelines. |
| Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided
  Region Control (Read more on [arXiv](https://arxiv.org/abs/2508.08134) or [HuggingFace](https://huggingface.co/papers/2508.08134))| Hongyu Liu, Xinhua Zhang, Kunyu Feng, Mingzhe Zheng, Zeqian Long | This paper presents Follow-Your-Shape, a training-free framework for performing large-scale, shape-aware image editing while preserving background content. The objective is to enable precise structural modifications to objects in an image without requiring external masks or degrading unedited regions, addressing a key limitation in diffusion and flow-based models. Its key methodology is the Trajectory Divergence Map (TDM), which dynamically localizes editable regions by computing the token-wise difference between the denoising velocity fields of the source and target prompts, guiding a scheduled Key-Value (KV) injection mechanism. On the introduced ReShapeBench benchmark, the method achieves state-of-the-art results, including a background preservation PSNR of 35.79, outperforming prior methods. For AI practitioners, this work provides a robust, mask-free technique for fine-grained region control in generative models, enabling complex structural edits by deriving localization information directly from the model's denoising process. |
| Less Is More: Training-Free Sparse Attention with Global Locality for
  Efficient Reasoning (Read more on [arXiv](https://arxiv.org/abs/2508.07101) or [HuggingFace](https://huggingface.co/papers/2508.07101))| Baihong Yuan, Shijie Cao, Arti Jain, Zhihao Zhang, Lijie Yang | The paper introduces LessIsMore, a training-free sparse attention mechanism that enhances inference efficiency for large reasoning models by leveraging global token importance patterns. The primary objective is to develop a sparse attention method that reduces the computational overhead of long-generation reasoning tasks without the significant accuracy degradation or increased generation length seen in existing approaches. LessIsMore employs a unified token selection strategy by aggregating top-k token indices from all attention heads into a single, globally ranked set, and dedicates a fixed ratio of its token budget to a "stable recency window" to preserve immediate context. On the AIME-24 benchmark using a Qwen3-8B model and a 2K token budget, LessIsMore achieved 73.75% accuracy, closely matching the 74.48% of full attention and significantly outperforming a comparable method's 53.33% accuracy, while also achieving a 1.13x end-to-end speedup. The principal implication for AI practitioners is that LessIsMore can be implemented as a drop-in, training-free optimization to significantly reduce latency and computational costs for deploying decode-heavy large reasoning models, maintaining near-lossless accuracy at much higher sparsity levels. |
| VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation
  for Multilingual Long Document Understanding (Read more on [arXiv](https://arxiv.org/abs/2508.07493) or [HuggingFace](https://huggingface.co/papers/2508.07493))| Tong Yu, Chenguang Wang, Jihyung Kil, Ming Li, Jian Chen | This paper introduces VisR-Bench, a new benchmark for evaluating question-driven, multimodal retrieval in long, multilingual documents, addressing the limitations of existing English-only or single-page datasets. The core objective is to systematically assess the retrieval capabilities of various models—including text-based, multimodal encoders, and MLLMs—across diverse content types (text, figures, tables) and 16 different languages. The methodology involves parsing 1.2K documents into page-level text and images, then using GPT-4o to generate over 35K QA pairs that require a specific evidence page for the answer, with a heuristic filter to ensure visual elements are necessary. The primary finding is that while MLLMs outperform other models, the best-performing method (ColQwen2-v0.1) achieves only 75.23% top-1 retrieval accuracy on the English split, with all models showing significant weaknesses in retrieving information from structured tables and in low-resource language contexts. For AI practitioners, this research highlights a critical bottleneck and implies that future development must focus on specialized mechanisms for table-aware perception and improved multilingual generalization to build effective real-world document intelligence systems. |
| Shortcut Learning in Generalist Robot Policies: The Role of Dataset
  Diversity and Fragmentation (Read more on [arXiv](https://arxiv.org/abs/2508.06426) or [HuggingFace](https://huggingface.co/papers/2508.06426))| Hengtao Shen, Lianli Gao, Junlin Xie, Xu Luo, Youguang Xing | This paper identifies limited diversity within individual sub-datasets and significant distributional disparities between them as primary contributors to shortcut learning in generalist robot policies trained on large-scale datasets like OXE. The research aims to uncover why generalist robot policies exhibit limited generalization due to reliance on task-irrelevant features. The authors' methodology includes analyzing visual and textual features of robot datasets using diversity and disparity metrics, developing a theoretical framework based on mutual information, and conducting controlled experiments in both simulation (LIBERO-Spatial) and real-world environments. Primary results demonstrate that introducing a third object in real-world finetuning completely eliminated observed shortcut behavior (from 0.6 to 0.0) and improved $\pi_0$'s OOD success rate from 0.2 to 0.75. The principal implication for AI practitioners is to prioritize dataset collection strategies that ensure diversity and factor independence within sub-datasets while maintaining overlap across them, or to apply targeted robotic data augmentation to existing offline datasets to enhance generalization. |
| MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs (Read more on [arXiv](https://arxiv.org/abs/2508.05257) or [HuggingFace](https://huggingface.co/papers/2508.05257))| Jianguo Li, Jing Zhang, Zhenzhong Lan, Mingming Ha, Xiaodong Chen | The paper introduces Mixture-of-Basis-Experts (MoBE), a compression technique for large Mixture-of-Experts (MoE) models that significantly reduces parameter count while preserving performance. The primary objective is to develop a compression method for massive MoE-based LLMs that avoids the substantial accuracy degradation characteristic of prior pruning and decomposition methods. MoBE's methodology involves factorizing each expert's weight matrix into an expert-specific transformation matrix `A` and a matrix `B`, where `B` is reconstructed as a learnable linear combination of a small set of basis matrices shared across all experts in a given layer. The primary result demonstrates that MoBE can reduce the parameter counts of models like DeepSeek-V3-0324 (671B) and Kimi-K2-Instruct (1T) by 24%-30% with only a 1%-2% drop in accuracy, significantly outperforming baseline methods. For AI practitioners, this implies that massive MoE models can be compressed to a more manageable size for deployment on memory-constrained hardware with minimal performance loss, although the authors note that a custom inference kernel is needed to realize the full computational efficiency of the architecture. |
| GLiClass: Generalist Lightweight Model for Sequence Classification Tasks (Read more on [arXiv](https://arxiv.org/abs/2508.07662) or [HuggingFace](https://huggingface.co/papers/2508.07662))| Alexander Yavorskyi, Oleksandr Lukashov, Dmytro Vodianytskyi, Mykhailo Shtopko, Ihor Stepanov | The paper introduces GLiClass, a uni-encoder transformer architecture for sequence classification that achieves high accuracy and efficiency by jointly processing text and label tokens in a single forward pass. The research objective is to develop a classification model that combines the accuracy of cross-encoders with the computational efficiency of embedding-based methods, while providing robust zero-shot and few-shot learning capabilities for scenarios with large label sets. The key methodology is a uni-encoder architecture (primarily DeBERTa-based) that concatenates input text with all candidate labels and processes the combined sequence simultaneously, enabling inter-label interactions. The model is trained in multiple stages, including supervised learning, refinement with a Proximal Policy Optimization (PPO) framework, and post-training with Low-Rank Adaptation (LoRA) on specialized data streams. The primary result is that the `gliclass-large-v3.0` model achieves an average F1-score of 0.7193 across benchmarks, surpassing a strong `deberta-v3-large` cross-encoder baseline (0.6821 F1). Critically, its inference throughput only degrades by 7.6% when scaling from 1 to 128 labels, while a comparable cross-encoder's throughput slows down by approximately 52x. The principal implication for AI practitioners is that GLiClass provides a production-ready alternative for multi-label classification tasks with large or dynamic label sets, offering accuracy competitive with cross-encoders while maintaining high, stable throughput that does not degrade linearly with the number of classes. |
| Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant
  Safeguards into Open-Weight LLMs (Read more on [arXiv](https://arxiv.org/abs/2508.06601) or [HuggingFace](https://huggingface.co/papers/2508.06601))| Robert Kirk, Tomek Korbak, Quentin Anthony, Stephen Casper, Kyle O'Brien | This paper demonstrates that filtering specific dual-use topics from pretraining data builds inherently tamper-resistant safeguards into large language models. The research investigates whether pretraining data curation can durably prevent a 6.9B-parameter LLM from learning specific unwanted knowledge, such as information related to biothreats. The methodology involves a scalable, multi-stage filtering pipeline combining a keyword blocklist with a fine-tuned ModernBERT classifier to remove targeted documents before pretraining models from scratch. The primary result is that filtered models exhibit substantial resistance to adversarial fine-tuning attacks, withstanding up to 10,000 steps and 300M tokens of biothreat-related text with no degradation to general capabilities. For AI practitioners, this establishes pretraining data curation as a highly effective, computationally tractable defense-in-depth strategy for open-weight models, offering significantly more robustness against fine-tuning attacks than existing post-training techniques. |
| Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System (Read more on [arXiv](https://arxiv.org/abs/2508.06059) or [HuggingFace](https://huggingface.co/papers/2508.06059))| Reynold Cheng, Dacheng Wen, Bin Benjamin Zhu, Yupeng Li, Haorui He | This paper introduces FACT2FICTION, a novel poisoning attack framework designed to compromise modern agentic fact-checking systems. The primary objective is to overcome the robustness of these systems by employing a two-agent LLM architecture that mirrors the victim's claim decomposition strategy and uniquely exploits its justifications to craft tailored malicious evidence for each sub-claim. In extensive experiments, FACT2FICTION achieves an Attack Success Rate (ASR) 8.9%–21.2% higher than state-of-the-art attacks across various poisoning budgets. For instance, at a 1% poison rate on the DEFAME system, it reached a 42.4% ASR, an 8.9 percentage point improvement over the PoisonedRAG baseline. The principal implication for AI practitioners is that system-generated justifications, while enhancing transparency, create an exploitable attack surface, revealing a critical trade-off between explainability and security that must be addressed in agentic system design. |
| Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with
  Patch-level CLIP Latents (Read more on [arXiv](https://arxiv.org/abs/2508.05954) or [HuggingFace](https://huggingface.co/papers/2508.05954))| Mohit Bansal, Chuan Li, Amir Zadeh, Jaemin Cho, Han Lin | Bifrost-1 introduces a unified framework that bridges pretrained Multimodal LLMs (MLLMs) with diffusion models using patch-level CLIP latents as the intermediate representation. The primary objective is to integrate high-fidelity visual synthesis into MLLMs without compromising their reasoning capabilities or requiring costly retraining. The methodology involves adding a lightweight, trainable visual generation branch to a frozen MLLM to predict patch-level CLIP latents, which then guide a pretrained diffusion model via a novel Latent ControlNet. On the ImageNet 256x256 generation task, this approach achieved a Fréchet Inception Distance (FID) of 25.77, significantly outperforming an ablation using cross-attention guidance (FID 76.32) with the same training budget. For AI practitioners, this presents an efficient, modular method to equip existing MLLMs with powerful image generation capabilities by leveraging natively aligned latents, thereby preserving the MLLM's core reasoning abilities and reducing computational costs. |
| When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with
  Benign Inputs (Read more on [arXiv](https://arxiv.org/abs/2508.03365) or [HuggingFace](https://huggingface.co/papers/2508.03365))| Dasol Choi, Taeyoun Kwon, Hiskias Dingeto, Bodam Kim, oneonlee | The paper introduces WHISPERINJECT, a two-stage adversarial audio attack framework designed to jailbreak Audio-Language Models (ALMs) using imperceptible, benign audio inputs. Its objective is to force ALMs to generate harmful content by addressing the challenge of eliciting model-native malicious responses. The methodology involves Stage 1 Native Target Discovery, using Reinforcement Learning with Projected Gradient Descent (RL-PGD) to generate model-native harmful payloads, followed by Stage 2 Adversarial Audio Generation, embedding these payloads into benign audio carriers via PGD. The framework achieved an attack success rate exceeding 86% across Qwen2.5-Omni and Phi-4-Multimodal models, with Stage 1 showing a 91.3% success rate in native payload discovery. This work demonstrates a critical vulnerability in ALMs, underscoring the urgent need for AI practitioners to develop robust, audio-signal level defenses beyond traditional text filtering in multimodal AI systems. |
| Compressing Chain-of-Thought in LLMs via Step Entropy (Read more on [arXiv](https://arxiv.org/abs/2508.03346) or [HuggingFace](https://huggingface.co/papers/2508.03346))| Zhijian Xu, Xiangyu Wen, Ziyang Zheng, Jianyuan Zhong, Zeju Li | This paper introduces a method to compress Chain-of-Thought (CoT) reasoning by identifying and pruning redundant steps using a novel metric called "step entropy." The primary objective is to develop a principled framework for reducing the computational cost and latency of LLM inference by compressing verbose CoT sequences without sacrificing final answer accuracy. The core methodology involves calculating "step entropy" for each reasoning step—defined as the sum of token-level entropies—to quantify its informational contribution, followed by systematically pruning a percentage of the lowest-entropy steps. Empirical validation shows that pruning up to 80% of the lowest-entropy reasoning steps causes minimal degradation in accuracy across multiple mathematical reasoning benchmarks, with one experiment on the Math500 dataset reducing thinking tokens by 29.7% while maintaining identical accuracy. For AI practitioners, this provides a method to significantly enhance the inference efficiency of LLMs using CoT by either statically pruning redundant steps or fine-tuning models to generate compressed thought processes, directly reducing deployment costs. |
| Speech-to-LaTeX: New Models and Datasets for Converting Spoken Equations
  and Sentences (Read more on [arXiv](https://arxiv.org/abs/2508.03542) or [HuggingFace](https://huggingface.co/papers/2508.03542))| Matvey Skripkin, Elvir Karimov, Artyom Iudin, Dmitrii Tarasov, Dmitrii Korzh | This paper introduces new models and datasets for converting spoken mathematical expressions and sentences into LaTeX. The primary objective is to address the challenging task of accurately transcribing spoken mathematical expressions and natural language sentences containing math into LaTeX format. The authors created a novel, large-scale open-source dataset (S2L) comprising 66k human-annotated and 571k TTS-generated audio samples, and evaluated ASR post-correction methods and multimodal end-to-end Audio-LLMs. On the English S2L-equations test subset, the SALMONN model achieved a Character Error Rate (CER) of 17.5%, demonstrating competitive results and outperforming ASR post-correction models. This work highlights the feasibility of Speech-to-LaTeX conversion with high-quality data, providing a strong performance baseline and emphasizing the importance of comprehensive datasets for AI practitioners in advancing spoken mathematical understanding. |
