

## Papers for 2025-08-21

| Title | Authors | Summary |
|-------|---------|---------|
| From Scores to Skills: A Cognitive Diagnosis Framework for Evaluating
  Financial Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2508.13491) or [HuggingFace](https://huggingface.co/papers/2508.13491))| Ziyan Kuang, Effoula, QianqianXie1994, hugai101, 2083L | This paper introduces FinCDM, a cognitive diagnosis framework using non-negative matrix co-factorization and a new expert-annotated dataset, CPA-KQA, to evaluate financial LLMs at a granular skill level rather than by a single aggregate score. The primary objective is to develop a framework that moves beyond "score flattening" in LLM evaluation by diagnosing specific financial knowledge and skill mastery, thereby identifying what a model truly knows and where it fails. The work employs a cognitive diagnosis model based on non-negative matrix co-factorization (MCF) which factorizes an LLM response matrix and a question-concept matrix into latent representations to explicitly estimate each model's mastery of 70 core financial concepts defined in the new CPA-KQA dataset. The FinCDM framework revealed significant discrepancies between aggregate accuracy and concept mastery; while multiple models achieve similar high accuracies (~0.84), they exhibit different specializations (e.g., Gemini in general accounting vs. Doubao in cost management). The underlying MCF method for diagnosis demonstrated superior performance in reconstructing observed model responses, achieving an accuracy of 0.9379 and an AUC of 0.9873. The principal implication for AI practitioners is that relying on aggregate benchmarks for high-stakes domains like finance is insufficient; practitioners should adopt skill-level diagnostic evaluations like FinCDM to gain interpretable insights into model capabilities, identify specific knowledge gaps for targeted fine-tuning, and build more reliable domain-specific LLMs. |
| FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction (Read more on [arXiv](https://arxiv.org/abs/2508.11987) or [HuggingFace](https://huggingface.co/papers/2508.11987))| tianlecai, Nuori, YinLingyue, Tianci-He, liujiashuo77 | FutureX is an advanced, dynamic, and live benchmark for evaluating LLM agents on real-world future prediction tasks. Its main objective is to establish a contamination-free evaluation standard by continuously collecting and assessing agent performance on events with unknown future outcomes. The benchmark utilizes a fully automated pipeline for daily question curation and answer acquisition from 195 high-quality websites, evaluating 25 LLM/agent models across four difficulty tiers. Results indicate a clear performance decline across increasing difficulty, with leading LLMs (Think&Search) outperforming human analysts in 37.5% of revenue and 32.3% of EPS financial prediction tasks. This highlights the critical need for AI practitioners to develop LLM agents with improved advanced search, reasoning, and real-time information processing capabilities for dynamic, high-stakes environments. |
| DuPO: Enabling Reliable LLM Self-Verification via Dual Preference
  Optimization (Read more on [arXiv](https://arxiv.org/abs/2508.14460) or [HuggingFace](https://huggingface.co/papers/2508.14460))| Yu Lu, Yu Bao, Shanbo, ShujianHuang, kevinpro | DuPO is a dual learning-based preference optimization framework that enables reliable LLM self-verification by generating annotation-free feedback through a generalized duality. The paper aims to overcome limitations of Reinforcement Learning with Verifiable Rewards (RLVR)'s reliance on costly labels and traditional dual learning's restriction to strictly dual tasks by providing self-supervised reward signals for LLM optimization. DuPO introduces a generalized duality framework that decomposes a primal task's input into known and unknown components, then constructs a dual task to reconstruct the unknown part using the primal output and known information, with reconstruction quality serving as a self-supervised reward. Empirically, DuPO improved average multilingual translation quality by 2.13 COMET points over 756 directions and boosted mathematical reasoning accuracy by an average of 6.4 percentage points on three challenge benchmarks. This positions DuPO as a scalable, general, and annotation-free paradigm for LLM optimization, also serving as an effective inference-time reranker that enables smaller models to outperform larger counterparts. |
| MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds (Read more on [arXiv](https://arxiv.org/abs/2508.14879) or [HuggingFace](https://huggingface.co/papers/2508.14879))| Jiangmiao, ZhaoyangLyu, asrnline, Qmh, tangqh | MeshCoder is a framework that reconstructs 3D objects from point clouds into editable, part-segmented Blender Python scripts using a multimodal large language model. The primary objective is to translate a 3D point cloud of a complex object into a structured, executable program that represents its geometry and semantic parts, overcoming the limitations of prior domain-specific languages and small-scale datasets. The methodology involves creating a comprehensive set of Blender Python APIs, using them to build a large-scale paired object-code dataset of 1 million objects, and then training a multimodal LLM with a triplane-based tokenizer to perform the final point cloud-to-code translation. The framework significantly outperforms baselines in reconstruction tasks, achieving an average Intersection over Union (IoU) of 86.75% across 41 object categories, compared to 67.62% for the PLAD baseline. For AI practitioners, the principal implication is the conversion of unstructured 3D point cloud data into a structured, human-readable code format, enabling direct programmatic editing of 3D assets and enhancing the capabilities of LLMs for 3D shape reasoning in applications like reverse engineering and procedural content generation. |
| Tinker: Diffusion's Gift to 3D--Multi-View Consistent Editing From
  Sparse Inputs without Per-Scene Optimization (Read more on [arXiv](https://arxiv.org/abs/2508.14811) or [HuggingFace](https://huggingface.co/papers/2508.14811))| Hao Chen, Zhiyue Zhao, Tianjian Feng, Xiaoman Li, Canyu | TINKER is a framework for high-fidelity, multi-view consistent 3D editing from sparse inputs that eliminates the need for per-scene fine-tuning by repurposing pretrained diffusion models. The primary objective is to develop a generalizable 3D editing framework capable of producing multi-view consistent edits from one or a few images without requiring computationally expensive per-scene optimization. The methodology involves two key components: a "Referring multi-view editor," fine-tuned on a self-generated dataset to propagate edits from a reference image, and a depth-conditioned "Any-view-to-video synthesizer" that uses video diffusion priors to perform scene completion and generate a dense set of edited views for 3D Gaussian Splatting optimization. The framework achieves state-of-the-art results, with the few-shot model obtaining an Aesthetic score of 6.338, outperforming prior methods like DGE (5.747) and EditSplat (5.661) while maintaining higher multi-view consistency. The principal implication for AI practitioners is a zero-shot, generalizable pipeline that significantly reduces the computational cost and complexity of 3D editing by replacing per-scene optimization with a pretrained scene completion model, making high-quality editing feasible on consumer-grade GPUs. |
| From AI for Science to Agentic Science: A Survey on Autonomous
  Scientific Discovery (Read more on [arXiv](https://arxiv.org/abs/2508.14111) or [HuggingFace](https://huggingface.co/papers/2508.14111))| zijieqiu, Wanggsh, schrodingers-tiger, ZhangyangGao, VitaCoco | This survey traces the evolution of AI from scientific tools to autonomous "Agentic Science," proposing a unified framework connecting core agent capabilities, scientific processes, and domain-specific applications. The paper's objective is to define and structure this emergent paradigm by synthesizing existing research on autonomous scientific agents across the natural sciences. The methodology is a systematic literature review used to construct a three-level framework comprising five foundational agent capabilities (e.g., planning, tool use), a four-stage discovery workflow, and a review of applications in fields like life sciences and chemistry. The paper establishes a four-level hierarchy for AI in science and collates results from various systems, noting, for example, that the PiFlow framework achieved a 73.55% increase in discovery efficiency by modeling discovery as an uncertainty reduction problem. The principal implication for AI practitioners is the provision of a structured paradigm for designing scientific AI agents, outlining the essential architectural components and dynamic workflow required to achieve full scientific autonomy. |
| Quantization Meets dLLMs: A Systematic Study of Post-training
  Quantization for Diffusion LLMs (Read more on [arXiv](https://arxiv.org/abs/2508.14896) or [HuggingFace](https://huggingface.co/papers/2508.14896))| Haobo Xu, cityug7353, ZiyuG, chriswyc, Felix1023 | This paper presents the first systematic study evaluating the application of post-training quantization (PTQ) on diffusion-based large language models (dLLMs). The primary objective is to analyze the performance of quantized dLLMs across four dimensions: bit-width, quantization method, task category, and model type. The methodology involves implementing state-of-the-art weight-only (GPTQ, AWQ) and weight-activation (SmoothQuant, QuaRot, DuQuant) PTQ methods on dLLMs like LLaDA-8B and evaluating them on general QA, math, and code generation benchmarks. The study finds that dLLMs exhibit activation outliers challenging low-bit quantization, with 4-bit weight-only quantization being the most effective configuration; for instance, 4-bit GPTQ on LLaDA-8B-instruct resulted in only a 0.6% performance drop on math tasks, while 3-bit quantization caused degradation exceeding 10%. For AI practitioners, the principal implication is that 4-bit weight-only PTQ (specifically GPTQ) is a robust and near-lossless method for compressing dLLMs for efficient deployment, although performance on complex tasks like code generation remains a significant challenge. |
| RynnEC: Bringing MLLMs into Embodied World (Read more on [arXiv](https://arxiv.org/abs/2508.14160) or [HuggingFace](https://huggingface.co/papers/2508.14160))| jiangpinliu, CausalLi, maoyunxuan, CircleRadon, RH-Dang | RynnEC is a video Multi-modal Large Language Model (MLLM) designed for fine-grained embodied cognition and interaction. The main objective is to overcome limitations in current MLLMs regarding flexible visual interaction, detailed object understanding, and video-based spatial awareness in ego-centric embodied scenarios for robotics. The methodology involves leveraging VideoLLaMA3, a region-aware encoder, and a mask decoder, trained on a novel mask-centric data generation pipeline from egocentric RGB videos to build the RynnEC-Bench dataset with a four-stage progressive training. RynnEC-7B achieves an overall mean score of 56.2 on the RynnEC-Bench, significantly outperforming state-of-the-art generalist MLLMs. This indicates that RynnEC's robust object and spatial cognitive abilities enable more precise, long-horizon robotic tasks, advancing general embodied intelligence models for real-world applications. |
| NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid
  Mamba-Transformer Reasoning Model (Read more on [arXiv](https://arxiv.org/abs/2508.14444) or [HuggingFace](https://huggingface.co/papers/2508.14444))| abercovich, aditya-malte, adirendu, aklife97, apaithan | NVIDIA's Nemotron-Nano-9B-v2 is a hybrid Mamba-Transformer model created by pre-training a 12B parameter model on 20 trillion tokens and then compressing it to 9B using pruning and knowledge distillation for efficient, long-context reasoning. The primary objective was to increase inference throughput for reasoning workloads while maintaining or exceeding the accuracy of similarly-sized state-of-the-art models, specifically targeting deployment on a single consumer-grade GPU. The methodology involves pre-training a Nemotron-H architecture (Mamba-2 and Transformer layers), aligning it with SFT, DPO, and RLHF, and then compressing it using the Minitron strategy, which combines iterative pruning of layers and neurons with multi-stage knowledge distillation to recover performance. The model achieves comparable or better accuracy than Qwen3-8B on complex reasoning benchmarks while delivering up to 6.3x higher throughput in scenarios with 8k input and 16k output tokens on a single NVIDIA A10G GPU. For AI practitioners, this paper provides a concrete methodology for creating hardware-aware models that balance performance and efficiency, demonstrating that model compression can enable long-context (128k) inference on widely available hardware without significant accuracy degradation. |
| MCP-Universe: Benchmarking Large Language Models with Real-World Model
  Context Protocol Servers (Read more on [arXiv](https://arxiv.org/abs/2508.14704) or [HuggingFace](https://huggingface.co/papers/2508.14704))| Prathyusha Jwalapuram, Zirui Zhao, Wenzhuo Yang, Zhiqi Shen, Ziyang Luo | MCP-Universe is the first benchmark for evaluating LLMs with real-world Model Context Protocol (MCP) servers. Its objective is to assess LLMs in realistic, challenging use cases involving 6 core domains and 11 MCP servers. The methodology employs execution-based evaluators, including format, static, and dynamic types, interacting with authentic MCP servers and data sources. Key results show top-performing models like GPT-5 achieve only a 43.72% success rate, revealing significant performance limitations and challenges with long contexts and unknown tools. This highlights the critical need for targeted advancements in LLM agent design and integration to improve real-world MCP application performance. |
| ViExam: Are Vision Language Models Better than Humans on Vietnamese
  Multimodal Exam Questions? (Read more on [arXiv](https://arxiv.org/abs/2508.13680) or [HuggingFace](https://huggingface.co/papers/2508.13680))| Daeyoung Kim, Duc Dm, Quang Tau, anvo25, tuongvy2603 | This paper introduces ViExam, a new benchmark for evaluating Vision Language Models (VLMs) on Vietnamese multimodal exam questions, revealing significant performance gaps compared to human capabilities. The primary objective is to investigate whether state-of-the-art VLMs, predominantly trained on English data, can perform complex cross-lingual multimodal reasoning on genuine Vietnamese educational assessments. The methodology involves creating the ViExam benchmark, containing 2,548 multimodal questions across 7 academic and practical domains, and evaluating 14 closed-source and open-source VLMs on it. The primary result is that state-of-the-art VLMs achieve a mean accuracy of only 57.74%, underperforming the average human test-taker's score of 66.54%, with failures attributed to reasoning challenges rather than basic text recognition. The principal implication for AI practitioners is that current SOTA VLMs struggle with genuine multimodal, cross-lingual tasks in low-resource languages, highlighting that strong performance on English benchmarks does not reliably transfer to linguistically and culturally distinct contexts. |
| On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised
  Fine-Tuning and Reinforcement Learning via Dynamic Weighting (Read more on [arXiv](https://arxiv.org/abs/2508.11408) or [HuggingFace](https://huggingface.co/papers/2508.11408))| Guoyin Wang, Yanxi Chen, Yuchang Sun, Yuexiang Xie, xiaoniqiu | The paper introduces CHORD, a novel framework that unifies Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) for Large Language Models (LLMs) through dynamic weighting. It aims to overcome issues of disrupting established model patterns and overfitting when integrating off-policy expert data with on-policy RL. CHORD reframes SFT as a dynamically weighted auxiliary objective within the on-policy RL process, utilizing a global coefficient (μ) to adjust overall influence and a token-wise weighting function (φ(·) = pt(1-pt)) for granular stability. On mathematical reasoning benchmarks, CHORD-φ achieved 62.5% accuracy on AMC, significantly outperforming the SFT-best+RL baseline which scored 58.4%. This demonstrates that practitioners can leverage CHORD's dual-control mechanism for more stable and effective integration of expert demonstrations and on-policy exploration in LLM post-training. |
| Leuvenshtein: Efficient FHE-based Edit Distance Computation with Single
  Bootstrap per Cell (Read more on [arXiv](https://arxiv.org/abs/2508.14568) or [HuggingFace](https://huggingface.co/papers/2508.14568))| Ingrid Verbauwhede, Nam-Luc Tran, Bojan Spasic, Jan-Pieter D'Anvers, woutLegiest | This paper introduces Leuvenshtein, a novel fully homomorphic encryption (FHE) based edit distance algorithm that significantly optimizes computation via reduced programmable bootstrap operations. The primary objective is to develop a new, highly efficient edit distance algorithm for third-generation FHE schemes (TFHE) to overcome performance bottlenecks for privacy-preserving string comparisons. The Leuvenshtein algorithm utilizes a compact ternary representation for differential values, reuses programmable bootstrapping results for multiple outputs, and computes the three-input minimum function with a single programmable bootstrap lookup by densely packing inputs into a 16-entry lookup table, while also optimizing equality checks. The proposed algorithm demonstrates a 94x reduction in programmable bootstrap operations per cell for the main algorithm compared to the Wagner-Fischer algorithm and an overall speedup of up to 278x over the best available FHE-based edit distance implementation for 256-character strings. This work significantly enhances the practicality and scalability of encrypted edit distance computations, enabling AI/ML practitioners to develop privacy-preserving applications for sensitive data, such as financial fraud detection or genomic analysis, with substantially reduced computational overhead. |
| Local Scale Equivariance with Latent Deep Equilibrium Canonicalizer (Read more on [arXiv](https://arxiv.org/abs/2508.14187) or [HuggingFace](https://huggingface.co/papers/2508.14187))| Jeremiah Jiang, Lim Jun Hao, Michael N. Cheng, Chiao-An Yang, ashiq24 | This paper proposes the Deep Equilibrium Canonicalizer (DEC) to enhance local scale equivariance and consistency in deep neural networks. The objective is to design deep-nets equivariant to local monotone scaling by modeling canonicalization as finding a fixed point of a learned non-linear transformation, incorporated into the latent space of existing architectures. Evaluations on ImageNet demonstrate that DEC improves both model performance and local scale consistency; for example, on the Swin architecture, it boosted Top-1 accuracy to 78.32% from a baseline of 77.94% and reduced the standard deviation of correctness across local scales from 1.65 to 1.49. This approach allows AI practitioners to adapt pre-trained models to handle local scale variations more effectively, improving robustness and accuracy for vision tasks in real-world settings with diverse object sizes. |
| mSCoRe: a Multilingual and Scalable Benchmark for Skill-based
  Commonsense Reasoning (Read more on [arXiv](https://arxiv.org/abs/2508.10137) or [HuggingFace](https://huggingface.co/papers/2508.10137))| anoperson, Franck-Dernoncourt, ntnghia1811 | This paper introduces mSCoRe, a multilingual and scalable benchmark for evaluating LLM commonsense reasoning by analyzing the use of specific, atomic reasoning skills. The primary objective is to systematically evaluate the multilingual and cultural commonsense reasoning processes of LLMs, addressing the lack of fine-grained, skill-based analysis and dynamic difficulty scaling in existing benchmarks. The methodology involves a four-step pipeline that uses LLMs to filter seed data from mCSQA and CultureBank, generate structured reasoning paths tagged with skills from a novel 10-skill taxonomy, systematically scale question complexity across levels, and create context-implicit questions. Primary results from experiments on eight LLMs show a consistent performance decline with increasing complexity; for instance, LLaMA-3.3-70B's average accuracy on the social commonsense task (mSCoRe-S) dropped from 81.8% at complexity level 0 to 74.8% at level 3. The principal implication for AI practitioners is that current LLMs, including those reinforced for reasoning, struggle with higher-complexity and culturally nuanced commonsense tasks, indicating that deploying these models in such contexts requires careful validation and that future development needs training methods that foster more diverse reasoning strategies. |
| Refining Contrastive Learning and Homography Relations for Multi-Modal
  Recommendation (Read more on [arXiv](https://arxiv.org/abs/2508.13745) or [HuggingFace](https://huggingface.co/papers/2508.13745))| Shiqing Wu, Yawen Zeng, guandongxu, MrShouxingMa | The paper presents REARM, a framework that refines multi-modal recommendation by enhancing contrastive learning to distinguish between shared and unique modal features and by incorporating extended homography relations. The objective is to mitigate issues of noisy shared features and lost unique features in multi-modal recommenders by developing a method that can filter noise, preserve valuable information, and model comprehensive homogeneous relationships. REARM employs a meta-network to denoise modal-shared features derived from contrastive learning and an orthogonal constraint loss to preserve modal-unique information, while also integrating user interest and item co-occurrence graphs into a GNN-based learning process. On the Amazon Sports dataset, REARM achieved a Recall@20 of 0.1231, outperforming the next-best baseline model which scored 0.1130. The principal implication for AI practitioners is that explicitly disentangling and refining shared versus unique modal features using mechanisms like meta-networks and orthogonality constraints can significantly improve recommendation performance by mitigating the noise and information loss inherent in standard multi-modal contrastive learning. |
