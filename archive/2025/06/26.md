

## Papers for 2025-06-26

| Title | Authors | Summary |
|-------|---------|---------|
| ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image
  Generation (Read more on [arXiv](https://arxiv.org/abs/2506.18095) or [HuggingFace](https://huggingface.co/papers/2506.18095))| Ke Ji, Shunian Chen, Zhenyang Cai, Junying Chen, cppppppc | i) This paper introduces ShareGPT-4o-Image, a dataset for distilling GPT-4o's image generation capabilities into open multimodal models. ii) The main objective is to democratize advanced image generation by providing a synthetic dataset to improve open-source models. iii) The methodology involves synthesizing 45K text-to-image and 46K text-and-image-to-image samples using GPT-4o and fine-tuning Janus-Pro on this data to create Janus-4o. iv) Primary results show Janus-4o achieves a 4-point improvement over Janus-Pro on the EvalGen benchmark in text-to-image generation and attains impressive text-and-image-to-image performance with only 91K synthetic samples and 6 hours of training. v) The principal implication for AI practitioners is that high-quality synthetic data distilled from proprietary models can significantly enhance the performance of open-source multimodal models, enabling state-of-the-art image generation capabilities with limited resources.  |
| Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large
  Language Models (Read more on [arXiv](https://arxiv.org/abs/2506.19697) or [HuggingFace](https://huggingface.co/papers/2506.19697))| Jaewoo Kang, Hyeon Hwang, Chanwoong Yoon, Taewhoo Lee, affjljoo3581 | i) The paper introduces Outlier-Safe Pre-Training (OSP), a novel guideline to prevent outlier formation in LLMs to improve 4-bit quantization. ii) The research aims to mitigate activation outliers in Large Language Models (LLMs) to enhance quantization performance for efficient deployment. iii) The methodology combines the Muon optimizer, single-scale RMSNorm (SSNORM), and learnable embedding projection (EMBPROJ). iv) The OSP model achieved a 35.7 average score across 10 benchmarks under aggressive 4-bit quantization, contrasting with 26.5 for an Adam-trained model, and exhibited a 0.04 excess kurtosis value compared to 1818.56. v) AI practitioners can use OSP to train LLMs that are more robust to quantization, potentially reducing deployment overhead in resource-constrained environments by preventing outliers rather than mitigating them post-hoc.  |
| DualTHOR: A Dual-Arm Humanoid Simulation Platform for Contingency-Aware
  Planning (Read more on [arXiv](https://arxiv.org/abs/2506.16012) or [HuggingFace](https://huggingface.co/papers/2506.16012))| Hang Xu, Siyuan He, Boyu Li, WizardTY, tellarin | DualTHOR is a physics-based simulation platform built upon AI2-THOR for developing embodied AI agents with dual-arm humanoid robots. The research objective is to create a simulation environment addressing limitations in current platforms, such as simplified robot morphologies and bypassed low-level execution stochasticity. The key methodology involves integrating real-world robot assets, a dual-arm task suite, humanoid inverse kinematics solvers, and a contingency mechanism simulating potential execution failures. Extensive evaluations reveal that current Vision-Language Models struggle with dual-arm coordination and show limited robustness in realistic environments with contingencies, success rates vary from 9.71% to 36.54% on dual-arm essential tasks. DualTHOR offers AI practitioners a more comprehensive benchmark for evaluating and improving the robustness and generalization capabilities of VLMs in complex household environments.  |
| OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling (Read more on [arXiv](https://arxiv.org/abs/2506.20512) or [HuggingFace](https://huggingface.co/papers/2506.20512))| Pengfei Liu, Xuefeng Li, Fan Zhou, Zengzhi Wang | OctoThinker investigates mid-training strategies to improve reinforcement learning (RL) scaling for language models, specifically Llama and Qwen. The research question is how mid-training strategies influence RL dynamics in language models. The methodology involves controlled mid-training interventions with varying datasets (e.g., MegaMath-Web-Pro, QA-style data) followed by RL training using the verl framework and GRPO algorithm. The primary result shows that a two-stage mid-training strategy (Stable-then-Decay) on 200B tokens with constant learning rate followed by 20B tokens across three CoT-focused branches yields OctoThinker, with RL performance matching Qwen2.5. The principal implication for AI practitioners is that strategic mid-training, particularly using high-quality mathematical corpora and QA-style data, can significantly enhance the RL compatibility of base language models, leading to improved downstream reasoning capabilities.  |
| Use Property-Based Testing to Bridge LLM Code Generation and Validation (Read more on [arXiv](https://arxiv.org/abs/2506.18315) or [HuggingFace](https://huggingface.co/papers/2506.18315))| Jing Shao, Zhe Zhang, Lehan He, lsheng2024, zx55 | i) The paper introduces Property-Generated Solver (PGS), a novel framework utilizing Property-Based Testing (PBT) to enhance the correctness and robustness of code generated by Large Language Models (LLMs). ii) The research aims to improve LLM-based code generation by employing property-based testing for validation, addressing the limitations of traditional test-driven development. iii) PGS uses two collaborative LLM agents: a Generator for code synthesis and iterative refinement, and a Tester for managing the PBT lifecycle and providing semantically rich feedback from property violations. iv) Experiments on multiple code generation benchmarks demonstrate that PGS achieves pass@1 improvements, ranging from 23.1% to 37.3% relative gains over established TDD methods. v) The research implies that AI practitioners can leverage property-based testing frameworks, like PGS, to systematically improve the reliability and correctness of LLM-generated code, particularly in complex programming tasks where traditional test case generation is insufficient.  |
| RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain
  Randomization for Robust Bimanual Robotic Manipulation (Read more on [arXiv](https://arxiv.org/abs/2506.18088) or [HuggingFace](https://huggingface.co/papers/2506.18088))| Yibin Liu, Zijian Cai, Baijun Chen, Zanxin Chen, TianxingChen | i) RoboTwin 2.0 is presented as a scalable framework for bimanual robotic manipulation data generation and benchmarking. ii) The main objective is to enhance the robustness and generalization of bimanual manipulation policies through simulation. iii) The methodology involves an expert data generation pipeline using multimodal large language models with simulation-in-the-loop refinement and structured domain randomization. iv) A vision-language-action model fine-tuned on RoboTwin 2.0 data achieved a 367% relative improvement on unseen scene real-world tasks; 10.9% gain in code generation success rate was demonstrated. v) RoboTwin 2.0 provides AI practitioners with a data generation and benchmarking platform to train and evaluate bimanual manipulation policies exhibiting improved sim-to-real transfer capabilities.  |
| Is There a Case for Conversation Optimized Tokenizers in Large Language
  Models? (Read more on [arXiv](https://arxiv.org/abs/2506.18674) or [HuggingFace](https://huggingface.co/papers/2506.18674))| Pedro Reviriego, Gonzalo Mart√≠nez, Javier Conde, Raquel Ferrando | i) This paper investigates the potential benefits of conversation-optimized tokenizers for Large Language Models (LLMs) to improve energy efficiency. ii) The main research question is whether optimizing tokenizers specifically for chatbot conversations can reduce the number of tokens and improve energy efficiency compared to tokenizers trained on general text corpora. iii) The methodology involves retraining existing tokenizers using a publicly available chatbot conversation dataset (LMSYS Chat 1M) and comparing their performance against the original tokenizers on both conversational and general text corpora (C4). iv) The primary result shows that conversation-optimized tokenizers consistently reduce the number of tokens in chatbot dialogues, achieving savings in the range of 5% to 10% for some tokenizers, while having minimal impact on tokenization efficiency for the original training corpus. v) AI practitioners can potentially reduce computational costs and improve energy efficiency in chatbot applications by adopting conversation-optimized tokenizers; however, trade-offs related to training costs and downstream model performance should be carefully evaluated.  |
| When Life Gives You Samples: The Benefits of Scaling up Inference
  Compute for Multilingual LLMs (Read more on [arXiv](https://arxiv.org/abs/2506.20544) or [HuggingFace](https://huggingface.co/papers/2506.20544))| Sara Hooker, Julia Kreutzer, Ye Shen, Daniel D'souza, ammar-cohere | i) This paper investigates strategies for scaling inference compute in multilingual large language models (LLMs) for open-ended generative tasks. ii) The research question addresses how to efficiently allocate a fixed inference compute budget to improve performance across diverse languages and tasks. iii) The methodology involves evaluating existing sampling and selection methods and proposing novel techniques like hedged sampling, Checklisted One-Pass Selection (CHOPS), and Cross-lingual Minimum Bayes Risk (X-MBR). iv) Results indicate that the proposed methods yield notable gains, specifically showing a +9.0 improvement in win-rates for the Command-A (111B) model on m-ArenaHard-v2.0 with just five samples against single-sample decoding. v) AI practitioners should consider language- and task-aware approaches to inference-time compute allocation, aiming to democratize performance improvements in underrepresented languages.  |
| ReCode: Updating Code API Knowledge with Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2506.20495) or [HuggingFace](https://huggingface.co/papers/2506.20495))| Ningyu Zhang, Huajun Chen, Wenhao Yu, Yunzhi Yao, Haoze Wu | i) ReCode improves LLMs' code generation with updated API knowledge via rule-based reinforcement learning. ii) The paper addresses the research question of how to effectively update LLMs' code generation abilities to accommodate frequent API changes in external libraries. iii) The methodology includes constructing a dataset of approximately 2,000 API migration examples and using a modified string similarity metric as the reward function for reinforcement learning with GRPO and DAPO algorithms. iv) Qwen2.5-Coder-7B trained with ReCode achieved a higher Pass@1 score on the CodeUpdateArena than Qwen2.5-Coder-32B, increasing Pass@1 by 11.3%. v) ReCode provides AI practitioners a framework for enhancing code LLMs' adaptability to evolving APIs, minimizing the impact of outdated training data on code generation tasks in dynamic environments.  |
| HiWave: Training-Free High-Resolution Image Generation via Wavelet-Based
  Diffusion Sampling (Read more on [arXiv](https://arxiv.org/abs/2506.20452) or [HuggingFace](https://huggingface.co/papers/2506.20452))| Farnood Salehi, Tobias Vontobel, RMW, msadat97 | HiWave presents a training-free approach for high-resolution image generation using pre-trained diffusion models. The research aims to enhance visual fidelity and structural coherence in ultra-high-resolution image synthesis from pre-trained diffusion models without retraining. The methodology employs a two-stage pipeline: base image generation from a pre-trained model, followed by patch-wise DDIM inversion and a wavelet-based detail enhancer module preserving low-frequency structure while guiding high-frequency components. User studies showed HiWave was preferred over the state-of-the-art alternative in more than 80% of comparisons, highlighting its effectiveness. The primary implication for AI practitioners is a method to improve the perceptual quality of generated ultra-high-resolution images without architectural modifications or retraining, potentially enabling higher fidelity outputs in creative applications.  |
| Inverse-and-Edit: Effective and Fast Image Editing by Cycle Consistency
  Models (Read more on [arXiv](https://arxiv.org/abs/2506.19103) or [HuggingFace](https://huggingface.co/papers/2506.19103))| Aibek Alanov, Andrey Kuznetsov, Ilia Beletskii | i) This paper introduces a cycle-consistency optimization framework for enhancing image inversion in fast image editing using consistency models. ii) The main objective is to improve image reconstruction quality in distilled diffusion models for higher-fidelity image editing. iii) The methodology involves fine-tuning a forward consistency model (fCM) using a cycle-consistency loss to reduce structural and semantic differences between original images and their reconstructions. iv) The proposed method achieves state-of-the-art performance in image editing tasks, matching or surpassing full-step diffusion models while being substantially more efficient, reducing LPIPS score by at least 0.04 compared to other fast methods for image reconstruction on MS-COCO dataset. v) The cycle-consistency optimization can enable AI practitioners to achieve faster and more effective image editing with distilled diffusion models, while retaining high reconstruction fidelity and controllability.  |
| The Debugging Decay Index: Rethinking Debugging Strategies for Code LLMs (Read more on [arXiv](https://arxiv.org/abs/2506.18403) or [HuggingFace](https://huggingface.co/papers/2506.18403))| Carlos C. N. Kuhn, adnaan525 | i) This paper introduces the Debugging Decay Index (DDI) to quantify and optimize iterative debugging effectiveness in code-generating LLMs. ii) The research investigates how to maximize the effectiveness of LLM-generated code debugging and develops a unified evaluation metric that encompasses reasoning proficiency and instruction-following competency. iii) The methodology involves modeling debugging effectiveness using an exponential decay function, fitting it to empirical data from LLM debugging attempts on the HumanEval dataset, and implementing strategic fresh starts at DDI-calculated intervention points. iv) Results show that LLM debugging effectiveness follows a predictable exponential decay pattern, and strategic fresh starts improve accuracy, as demonstrated by Llama3.1:8b increasing baseline accuracy from 72.56% to 82.82%. v) AI practitioners can utilize DDI to determine optimal debugging windows and improve iterative code generation strategies by implementing fresh starts, mitigating performance degradation.  |
| Biomed-Enriched: A Biomedical Dataset Enriched with LLMs for Pretraining
  and Extracting Rare and Hidden Content (Read more on [arXiv](https://arxiv.org/abs/2506.20331) or [HuggingFace](https://huggingface.co/papers/2506.20331))| Eric de la Clergerie, Nathan Godey, rntc | i) Biomed-Enriched is introduced, a biomedical dataset constructed from PubMed using a two-stage LLM-annotation process for refined subset extraction. ii) The research aims to create a biomedical text dataset that addresses the lack of accessible clinical text and improves biomedical pretraining efficiency. iii) 400K PubMed paragraphs were annotated with scores for type, domain, and educational quality using a large language model, followed by fine-tuning a smaller model to propagate labels across the full PMC-OA corpus. iv) Clinical upsampling boosted performance by 5% on MMLU ProfMed, and combining techniques led to faster convergence, reaching the same performance with a third of the training tokens. v) AI practitioners can leverage this dataset to more efficiently pretrain language models for biomedical applications, particularly when focusing on clinical text or educationally valuable content, thereby reducing computational costs.  |
| MATE: LLM-Powered Multi-Agent Translation Environment for Accessibility
  Applications (Read more on [arXiv](https://arxiv.org/abs/2506.19502) or [HuggingFace](https://huggingface.co/papers/2506.19502))| Paul Laban, Matt Laing, AleksandrAlgazinov | i) The paper introduces MATE, an open-source, lightweight multi-agent system (MAS) for multimodal accessibility, enabling modality conversions based on user needs. ii) The main research objective is to design a flexible MAS architecture to adapt to diverse accessibility requirements in real-time. iii) The methodology involves developing specialized agents utilizing LLM APIs and custom ML classifiers, along with a dataset (ModConTT) for training and evaluation. iv) The ModCon-Task-Identifier, a fine-tuned BERT model, achieves a classification accuracy of 0.917 and F1-score of 0.916 on the ModConTT dataset, outperforming other LLMs and statistical models. v) The principal implication is that MATE offers a customizable and adaptable framework for AI practitioners developing accessibility solutions, leveraging MAS to address modality conversion challenges, although it lacks support for video generation capabilities and relies on external models whose performance can be variable.  |
