

## Papers for 2025-06-05

| Title | Authors | Summary |
|-------|---------|---------|
| MiMo-VL Technical Report (Read more on [arXiv](https://arxiv.org/abs/2506.03569) or [HuggingFace](https://huggingface.co/papers/2506.03569))| Prestonprom, dwzhu, tobiaslee, gsh33, ShuhuaiRen | i) The paper introduces MiMo-VL-7B, a vision-language model achieving state-of-the-art performance in visual understanding and multimodal reasoning. ii) The primary research objective is to develop a compact and powerful vision-language model exceeding existing models in general visual understanding and multimodal reasoning, particularly for GUI grounding applications. iii) The methodology involves a four-stage pre-training process (2.4 trillion tokens) combined with a Mixed On-policy Reinforcement Learning (MORL) framework integrating diverse reward signals. iv) MiMo-VL-7B-RL achieves a score of 59.4 on OlympiadBench and 56.1 on OSWorld-G, outperforming Qwen2.5-VL-7B on 35 of 40 evaluated tasks. v) The principal implication is that incorporating high-quality, broad-coverage reasoning data into pre-training stages significantly enhances model performance and mixed on-policy reinforcement learning further enhances performance.  |
| Advancing Multimodal Reasoning: From Optimized Cold Start to Staged
  Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2506.04207) or [HuggingFace](https://huggingface.co/papers/2506.04207))| Yafu Li, Yue Guo, Shuang Chen, JC-Chen, Warrieryes | i) This paper introduces ReVisual-R1, a 7B open-source Multimodal Large Language Model (MLLM), trained via a staged curriculum. ii) The main objective is to enhance multimodal reasoning capabilities in MLLMs by optimizing the training pipeline. iii) The methodology involves a three-stage curriculum consisting of a text-centric cold start, multimodal reinforcement learning (RL) with Prioritized Advantage Distillation (PAD), and a final text-only RL refinement phase. iv) ReVisual-R1 achieves a new state-of-the-art among open-source 7B MLLMs, with an average score of 53.1% across challenging benchmarks and demonstrates a +44.6% increase on AIME24. v) AI practitioners can leverage the staged curriculum approach to improve the reasoning abilities of open-source MLLMs on challenging multimodal tasks, rivaling proprietary models.  |
| AmbiK: Dataset of Ambiguous Tasks in Kitchen Environment (Read more on [arXiv](https://arxiv.org/abs/2506.04089) or [HuggingFace](https://huggingface.co/papers/2506.04089))| Aleksandr I. Panov, Alexey K. Kovalev, Anastasiia Ivanova, AlexeyKov, tenebrissilvam | i) The paper introduces AmbiK, a new fully textual dataset for ambiguous task detection in kitchen environments. ii) The research aims to provide a benchmark for evaluating and comparing ambiguity detection methods in Large Language Models (LLMs) applied to embodied AI. iii) The methodology involves curating a dataset of 2000 paired ambiguous and unambiguous instructions, categorized by ambiguity type (Preferences, Common Sense Knowledge, Safety), and human-validated using LLMs for data collection. iv) Experiments using SOTA LLMs on AmbiK demonstrate a limited success in resolving ambiguity, as no method achieves over 20% Set Size Correctness (SSC), indicating a misalignment between predicted and actual ambiguity sets. v) AmbiK dataset’s challenging nature suggests that LLMs logits are often inadequate approximations of uncertainty for task planning in complex environments, highlighting a need for improved uncertainty estimation techniques for AI practitioners developing embodied agents.  |
| CASS: Nvidia to AMD Transpilation with Data, Models, and Benchmark (Read more on [arXiv](https://arxiv.org/abs/2505.16968) or [HuggingFace](https://huggingface.co/papers/2505.16968))| Salman Khan, Seung Hun Eddie Han, GustavoStahl, Sarim-Hash, ahmedheakl | i) The paper introduces CASS, a dataset and model suite for cross-architecture GPU code transpilation. ii) The research objective is to address the portability gap in GPU code across Nvidia (CUDA) and AMD (HIP/RDNA3) architectures. iii) The methodology involves creating a 70k aligned CUDA-HIP source and SASS-RDNA3 assembly dataset and fine-tuning domain-specific language models on it. iv) Results include achieving 95% accuracy in source translation and 37.5% assembly translation, with the translated assemblies matching native performance in over 85% of test cases regarding runtime and memory behavior. v) CASS provides AI practitioners with resources for GPU compiler tooling, binary compatibility analysis, and LLM-guided hardware translation, as demonstrated by the presented CASS models outperforming GPT-40.  |
| A Controllable Examination for Long-Context Language Models (Read more on [arXiv](https://arxiv.org/abs/2506.02921) or [HuggingFace](https://huggingface.co/papers/2506.02921))| Fei Yuan, Zihan Qiu, Wenhao Zhu, Zeyu Huang, thomasyyj | i) LongBioBench, a novel benchmark, is introduced for evaluating long-context language models (LCLMs) using artificially generated biographies. ii) The research aims to assess the understanding, reasoning, and trustworthiness of LCLMs in a controlled setting, addressing limitations of existing real-world and synthetic benchmarks. iii) The methodology involves constructing a dataset of configurable biographies and evaluating 18 LCLMs across various tasks, including understanding, reasoning, and trustworthiness. iv) Results demonstrate that most models exhibit deficiencies in semantic understanding and reasoning, with performance decreasing as context length increases; moreover, LongBioBench has a high correlation (0.853) with the scores of HELMET. v) LongBioBench provides AI practitioners with a configurable and interpretable benchmark for evaluating and improving the long-context capabilities of language models, particularly regarding semantic understanding and reasoning over retrieved information.  |
| SuperWriter: Reflection-Driven Long-Form Generation with Large Language
  Models (Read more on [arXiv](https://arxiv.org/abs/2506.04180) or [HuggingFace](https://huggingface.co/papers/2506.04180))| Roy Ka-Wei Lee, Juanzi Li, Yushi Bai, Yuhao Wu, Zhiqiang007 | SuperWriter-Agent enhances long-form text generation by incorporating structured thinking. The research addresses maintaining coherence and consistency in large language models (LLMs) for extended text. It fine-tunes a 7B SuperWriter-LM with a structured dataset. SuperWriter-LM achieves state-of-the-art performance with results showing an increase of performance. Practitioners can leverage structured thinking steps to enhance the coherence and quality of long-form text generation models.  |
| Ψ-Sampler: Initial Particle Sampling for SMC-Based Inference-Time
  Reward Alignment in Score Models (Read more on [arXiv](https://arxiv.org/abs/2506.01320) or [HuggingFace](https://huggingface.co/papers/2506.01320))| Minhyuk Sung, Kyeongmin Yeo, Yunhong Min, Taehoon Yoon | i) The paper introduces Ψ-SAMPLER, a Sequential Monte Carlo (SMC) framework utilizing preconditioned Crank-Nicolson Langevin (pCNL)-based initial particle sampling for improved inference-time reward alignment in score-based generative models. ii) The research addresses the problem of inefficient exploration of high-reward regions in existing SMC-based reward alignment methods due to Gaussian prior initialization. iii) The methodology involves a pCNL algorithm for efficient posterior sampling in high-dimensional latent spaces, combining dimension-robust proposals with gradient-informed dynamics to generate initial particles for SMC. iv) Experiments show Ψ-SAMPLER consistently outperforms baselines across reward alignment tasks, including achieving a negative smooth L1 loss of 0.850 in quantity-aware generation compared to 1.804 with a base SMC method. v) AI practitioners can leverage Ψ-SAMPLER to improve the efficiency and performance of inference-time reward alignment in score-based generative models by incorporating posterior-based initialization via the pCNL algorithm.  |
| Voyager: Long-Range and World-Consistent Video Diffusion for Explorable
  3D Scene Generation (Read more on [arXiv](https://arxiv.org/abs/2506.04225) or [HuggingFace](https://huggingface.co/papers/2506.04225))| Zhenwei Wang, Yuhao Liu, Tengfei Wang, Wangguandong Zheng, tyhuang | Voyager introduces a video diffusion framework for generating world-consistent, explorable 3D scenes from a single image. The research addresses the problem of generating long-range, spatially consistent 3D scenes suitable for applications like video games and VR. The methodology involves a world-consistent video diffusion model integrating RGB and depth information, a world caching mechanism with point culling, and a scalable data engine for training data curation. Experiments on the RealEstate 10K dataset demonstrate Voyager achieves a PSNR of 18.751, outperforming existing methods in novel view synthesis. The framework enables AI practitioners to generate and reconstruct 3D scenes with improved spatial consistency, facilitating applications requiring explorable virtual environments; further work is needed to understand the limitations of this approach to unseen or complex scene geometries.  |
| LayerFlow: A Unified Model for Layer-aware Video Generation (Read more on [arXiv](https://arxiv.org/abs/2506.04228) or [HuggingFace](https://huggingface.co/papers/2506.04228))| Yiyang Wang, Yuanpeng Tu, Hao Luo, Sihui Ji, xichenhku | i) LayerFlow is a unified model for layer-aware video generation, supporting transparent foreground, clean background, blended scenes, video decomposition, and conditional generation. ii) The research objective is to develop a single framework capable of generating and manipulating video layers, addressing challenges in representation and data scarcity. iii) The methodology involves a DiT-based text-to-video model, layer embeddings for layer awareness, and a multi-stage training strategy with Motion and Content LoRAs using both static images and dynamic videos. iv) The model achieves improved inter-layer coherence and aesthetic quality, shown qualitatively and quantitatively via user studies where LayerFlow performs significantly better in text consistency and overall quality over alternatives. v) LayerFlow offers AI practitioners a unified approach to layer-aware video generation, enabling flexible content creation and manipulation with potential applications in visual production workflows.  |
| SVGenius: Benchmarking LLMs in SVG Understanding, Editing and Generation (Read more on [arXiv](https://arxiv.org/abs/2506.03139) or [HuggingFace](https://huggingface.co/papers/2506.03139))| Xingyu Wu, Xinyu Dong, yanyc, zjuxhl, xiaoooobai | i) SVGenius is introduced as a benchmark for evaluating Large Language Models (LLMs) and Multimodal LLMs in SVG processing across understanding, editing, and generation. ii) The research aims to comprehensively assess LLMs' capabilities in manipulating Scalable Vector Graphics (SVG), addressing limitations of existing benchmarks. iii) SVGenius evaluates models via 2,377 queries spanning perceptual and semantic QA, code optimization, bug fixing, style editing, text-to-SVG, image-to-SVG, and style transfer tasks, utilizing real-world data from 24 domains with systematic complexity stratification. iv) Results show proprietary models outperform open-source alternatives, but all models exhibit performance degradation with increased complexity, with a gap between 82.72% to 42.22% in Perceptual QA across difficulty levels using GPT-40, and reasoning-enhanced training proves effective for complex tasks, while style transfer remains challenging. v) SVGenius provides AI practitioners with a systematic framework and baseline results for developing and assessing vector graphics models, identifying areas for improvement such as handling complexity and stylistic variations in SVG processing.  |
| Image Editing As Programs with Diffusion Models (Read more on [arXiv](https://arxiv.org/abs/2506.04158) or [HuggingFace](https://huggingface.co/papers/2506.04158))| Xinchao Wang, Zhenxiong Tan, Songhua Liu, Yujia Hu, adamdad | i) The paper introduces Image Editing As Programs (IEAP), a DiT-based framework for instruction-driven image editing. ii) The primary objective is to address the limitations of current diffusion models in handling structurally inconsistent edits that require layout modifications. iii) The methodology involves decomposing complex editing instructions into sequences of atomic operations (RoI localization, inpainting, editing, compositing, global transformation), orchestrated by a VLM-based agent. iv) Experiments demonstrate that IEAP achieves state-of-the-art performance on standard benchmarks, with a GPT-4o average score of 4.51 on the AnyEdit test set. v) IEAP provides AI practitioners with a modular and interpretable approach to image editing that improves accuracy and semantic fidelity, especially in complex scenarios.  |
| Unleashing the Reasoning Potential of Pre-trained LLMs by Critique
  Fine-Tuning on One Problem (Read more on [arXiv](https://arxiv.org/abs/2506.03295) or [HuggingFace](https://huggingface.co/papers/2506.03295))| Wenhu Chen, Lijun Wu, Kai Zou, Ping Nie, Yubo Wang | i) The paper introduces Critique Fine-Tuning (CFT), a compute-efficient method to enhance LLM reasoning. ii) The study investigates whether critique data from a single problem can effectively unleash LLMs' reasoning potential. iii) The methodology involves generating diverse solutions to a single problem, using teacher LLMs for critiques, and fine-tuning student LLMs on the critique data. iv) Qwen-Math-7B-CFT achieves a 15% average improvement on six math benchmarks and 16% on three logic reasoning benchmarks, using only 5 GPU hours. v) CFT offers a simple, general, and compute-efficient approach for AI practitioners to improve reasoning capabilities of LLMs, potentially surpassing RL methods with significantly less compute.  |
| TimeHC-RL: Temporal-aware Hierarchical Cognitive Reinforcement Learning
  for Enhancing LLMs' Social Intelligence (Read more on [arXiv](https://arxiv.org/abs/2505.24500) or [HuggingFace](https://huggingface.co/papers/2505.24500))| Wenqi Zhang, Xiang Huang, Yuchuan Wu, Xing Gao, Guiyang Hou | i) This paper introduces TimeHC-RL, a novel reinforcement learning framework to enhance LLMs' social intelligence by incorporating temporal awareness and hierarchical cognitive processing. ii) The research objective is to improve LLMs' cognitive development in social domains, particularly from a post-training perspective, by modeling temporal dynamics and diverse cognitive modes. iii) The methodology involves a temporal-aware reward mechanism and a hierarchical cognition framework encompassing intuitive reactions, surface-level thinking, and deliberate thinking within a reinforcement learning paradigm. iv) Experiments demonstrate that TimeHC-RL, with a 7B backbone model, achieves a 29.0 point comprehensive performance improvement in In-Domain evaluation compared to the backbone model, rivaling the performance of advanced models such as DeepSeek-R1 and OpenAI-O3. v) TimeHC-RL provides AI practitioners with a new approach to enhance LLMs' social intelligence by explicitly modeling temporal dynamics and incorporating a more nuanced cognitive hierarchy, thus enabling more contextually appropriate and human-like social reasoning capabilities in AI systems.  |
| IllumiCraft: Unified Geometry and Illumination Diffusion for
  Controllable Video Generation (Read more on [arXiv](https://arxiv.org/abs/2506.03150) or [HuggingFace](https://huggingface.co/papers/2506.03150))| Ming-Hsuan Yang, Ronald Clark, Yi-Hsuan Tsai, Yi-Wen Chen, Yuanze Lin | IllumiCraft is presented as a unified diffusion framework for controllable video generation by jointly modeling geometry and illumination. The research aims to enable high-quality video relighting, addressing limitations in existing methods regarding explicit geometric cues. The key methodology integrates HDR video, synthetically relit frames, and 3D point tracks within a DiT-based diffusion model architecture. Experiments show IllumiCraft cuts FVD by 37% compared to Light-A-Video on 49-frame background-conditioned relighting. The principal implication is a potential for AI practitioners to utilize the explicit incorporation of geometric and illumination guidance for enhanced control and fidelity in video generation tasks, specifically video relighting.  |
| VisCoder: Fine-Tuning LLMs for Executable Python Visualization Code
  Generation (Read more on [arXiv](https://arxiv.org/abs/2506.03930) or [HuggingFace](https://huggingface.co/papers/2506.03930))| Wenhu Chen, Xiang Yue, Kai Zou, Ping Nie, yuanshengni | VisCoder introduces a fine-tuned language model for generating executable Python visualization code. The study addresses the challenge of creating accurate visualization code from natural language and data inputs. The methodology involves instruction-tuning the Qwen2.5-Coder-Instruct model using VisCode-200K, a dataset containing over 200K examples including validated code paired with natural language instructions and multi-turn revision dialogues from Code-Feedback. VisCoder-3B improves execution pass rate by 19.6% over Qwen2.5-Coder on the PandasPlotBench. This work provides AI practitioners with a model and a dataset to improve the reliability and accuracy of automatically generated data visualizations.  |
| MMR-V: What's Left Unsaid? A Benchmark for Multimodal Deep Reasoning in
  Videos (Read more on [arXiv](https://arxiv.org/abs/2506.04141) or [HuggingFace](https://huggingface.co/papers/2506.04141))| Shangqing Tu, Jiachun Li, Hongbang Yuan, Zhuoran Jin, Kejian Zhu | i) The paper introduces MMR-V, a new benchmark for evaluating multi-modal deep reasoning in videos. ii) The main objective is to assess the capability of MLLMs to perform long-range, multi-frame reasoning and inference beyond direct perception in videos. iii) The methodology involves constructing a dataset of 317 videos and 1257 tasks with manual annotation, distractor generation, and categorization into implicit and explicit reasoning types. iv) Experiments show that the best-performing model, o4-mini, achieves 52.5% accuracy on the MMR-V benchmark. v) The principal implication for AI practitioners is that current MLLMs struggle with complex video reasoning, requiring further research into improving multi-modal analysis and evidence mining capabilities for tasks beyond simple perception.  |
| Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis (Read more on [arXiv](https://arxiv.org/abs/2506.04142) or [HuggingFace](https://huggingface.co/papers/2506.04142))| Juanzi Li, Lei Hou, Zhuoran Jin, Shangqing Tu, Kejian Zhu | i) This paper introduces a novel approach to trustworthy LLM evaluation by analyzing and mitigating the impact of shortcut neurons. ii) The research aims to address the issue of data contamination in LLM evaluation by identifying and suppressing shortcut reasoning mechanisms. iii) The methodology involves comparative and causal analysis to locate shortcut neurons, followed by a shortcut neuron patching technique during evaluation. iv) Experiments show the method effectively mitigates contamination, as demonstrated by a Spearman correlation coefficient exceeding 0.95 with the MixEval benchmark, and reduces original model accuracy by 37% after patching. v) AI practitioners can utilize this method to obtain more trustworthy evaluations of LLMs by addressing the impact of shortcut neurons, leading to more reliable model deployment and development.  |
| Rectified Sparse Attention (Read more on [arXiv](https://arxiv.org/abs/2506.04108) or [HuggingFace](https://huggingface.co/papers/2506.04108))| Jian Chen, Yuqing Xia, Li Dong, Tianzhu Ye, Yutao Sun | i) Rectified Sparse Attention (ReSA) addresses KV cache misalignment in sparse decoding to improve long-sequence generation. ii) The research aims to enhance the efficiency of long-sequence generation in Large Language Models without sacrificing quality. iii) ReSA combines block-sparse attention with periodic dense rectification to refresh the KV cache at fixed intervals. iv) Experiments show ReSA achieves up to 2.42x end-to-end speedup during decoding at 256K sequence length while maintaining near-lossless generation quality. v) AI practitioners can utilize ReSA for scalable long-context inference, especially in memory-constrained environments, offering a practical solution for deploying Large Language Models.  |
| DenseDPO: Fine-Grained Temporal Preference Optimization for Video
  Diffusion Models (Read more on [arXiv](https://arxiv.org/abs/2506.03517) or [HuggingFace](https://huggingface.co/papers/2506.03517))| Ashkan Mirzaei, Willi Menapace, Ivan Skorokhodov, Anil Kag, Dazitu616 | i) DenseDPO improves video diffusion models by introducing fine-grained temporal preference optimization. ii) The paper addresses how to improve video diffusion models with human preference learning while mitigating motion bias. iii) The methodology involves creating video pairs by denoising corrupted copies of a ground truth video, segmenting videos for per-segment preference labeling, and utilizing vision-language models (VLMs) for automated preference annotation. iv) DenseDPO improves motion generation over vanilla DPO while matching it in text alignment, visual quality, and temporal consistency, even with only one-third of the labeled data. v) The use of segment-level preference allows practitioners to effectively train video diffusion models with more accurate and dense supervision while reducing biases and annotation costs, potentially unlocking automatic preference annotation via VLMs.  |
| Beyond the Surface: Measuring Self-Preference in LLM Judgments (Read more on [arXiv](https://arxiv.org/abs/2506.02592) or [HuggingFace](https://huggingface.co/papers/2506.02592))| Yankai Lin, Enrui Hu, Xinyu Zhang, Hao Wang, JaxChen | i) The paper introduces the DBG score to more accurately measure self-preference bias in Large Language Model (LLM) judges. ii) The research objective is to disentangle self-preference bias from response quality when evaluating LLMs as judges. iii) The methodology involves introducing gold judgments as proxies for ground truth response quality and comparing these with the judge model's scores to compute the DBG score. iv) Experiments reveal that LLMs exhibit self-preference bias, with larger models showing less bias than smaller ones; for example, the DBG score of Llama-3.1-70B is 0.4% whereas Llama-3.1-8B is 21.6%. v) The findings imply that LLM developers should prioritize larger models for judgment tasks to mitigate self-preference bias, and the DBG score offers a more reliable evaluation metric.  |
| Critique-GRPO: Advancing LLM Reasoning with Natural Language and
  Numerical Feedback (Read more on [arXiv](https://arxiv.org/abs/2506.03106) or [HuggingFace](https://huggingface.co/papers/2506.03106))| Chaochao Lu, Kaituo Feng, Hao Sun, Xiaoying Zhang, YipengZhang | i) Critique-GRPO is introduced as an online reinforcement learning framework for enhancing LLM reasoning. ii) The research investigates whether integrating natural language critiques alongside numerical rewards improves LLM reasoning compared to using numerical rewards alone. iii) The methodology involves fine-tuning Qwen2.5-7B-Base and Qwen3-8B-Base models using a modified Group Relative Policy Optimization (GRPO) algorithm that incorporates both natural language critiques and numerical feedback. iv) Experiments across eight reasoning tasks show that Critique-GRPO improves average pass@1 scores by approximately 4.5% and 5% respectively, and also reveals that models exhibit effective refinements when provided with chain-of-thought critiques. v) The findings imply that AI practitioners can enhance LLM reasoning capabilities more effectively by leveraging both natural language critiques and numerical rewards in reinforcement learning frameworks, and this can be more useful than imitation learning by expert demonstrations. |
| TalkingMachines: Real-Time Audio-Driven FaceTime-Style Video via
  Autoregressive Diffusion Models (Read more on [arXiv](https://arxiv.org/abs/2506.03099) or [HuggingFace](https://huggingface.co/papers/2506.03099))| Weimin Wang, Chetwin Low | TalkingMachines introduces an efficient framework for real-time, audio-driven character animation. The research objective is to transform pre-trained video generation models into real-time capable systems. It employs an adapted image-to-video Diffusion Transformer (DiT) model and asymmetric knowledge distillation with sparse causal attention. The framework distills a model to 2 diffusion steps achieving real-time performance and reducing latency for interactive applications with less than 30% end-to-end generation time spent on VAE decoding and device-to-host transfer per video chunk. This disaggregation server design helps practitioners overcome computational bottlenecks in real-time streaming, including GPU allocation, communication-computation overlap, and memory reuse.  |
| Robustness in Both Domains: CLIP Needs a Robust Text Encoder (Read more on [arXiv](https://arxiv.org/abs/2506.03355) or [HuggingFace](https://huggingface.co/papers/2506.03355))| Matthias Hein, Yongtao Wu, Naman Deep Singh, Elias Abad Rocamora, chs20 | i) The paper introduces LEAF, a novel adversarial finetuning method for improving the robustness of CLIP text encoders. ii) The main objective is to enhance the robustness of CLIP models against adversarial text perturbations without sacrificing performance in the image domain. iii) The methodology involves an efficient adversarial finetuning technique utilizing a parallelizable Levenshtein distance-constrained attack within training batches. iv) The results show that LEAF improves the zero-shot adversarial accuracy in the text domain from 44.5% to 63.3% on AG-News with k=1, while maintaining vision performance and improving text-to-image generation quality and multimodal retrieval under adversarial noise. v) Robust CLIP text encoders, produced via LEAF, facilitate better reconstruction of input text from embeddings, and could improve the reliability of multimodal systems against adversarial attacks which is particularly relevant for deploying such models in production.  |
| DiffDecompose: Layer-Wise Decomposition of Alpha-Composited Images via
  Diffusion Transformers (Read more on [arXiv](https://arxiv.org/abs/2505.21541) or [HuggingFace](https://huggingface.co/papers/2505.21541))| Xiangtai Li, Xuequan Lu, Qianyu Zhou, Hang Zhao, Zitong Wang | i) The paper introduces DiffDecompose, a diffusion transformer-based framework for layer-wise decomposition of alpha-composited images. ii) The research aims to recover constituent layers from single overlapped images with semi-transparent or transparent layer non-linear occlusions. iii) The proposed DiffDecompose framework employs a diffusion transformer architecture and leverages In-Context Decomposition and Layer Position Encoding Cloning. iv) The framework achieves an average improvement of 36.3% in RMSE, +1.2% in SSIM, and 52.8% in LPIPS compared to existing methods on the AlphaBlend dataset. v) The framework introduces a novel approach for disentangling composite images which provides AI practitioners with more accurate image extraction while preserving fine-grained details.  |
| Adapt before Continual Learning (Read more on [arXiv](https://arxiv.org/abs/2506.03956) or [HuggingFace](https://huggingface.co/papers/2506.03956))| Yanan Sun, Chunhui Ding, Tao Feng, JacobYuan, Kurt1024 | Adapting PTMs before core continual learning process (ACL) framework enhances plasticity and stability in PTM-based continual learning. This research addresses the stability-plasticity dilemma in continual learning with pre-trained models by adapting PTMs before the core CL process. The methodology involves refining the PTM backbone through an adaptation phase, aligning embeddings with original class prototypes and distancing them from others, before applying CL techniques. Experiments demonstrate that ACL significantly improves CL performance, achieving gains of up to 10.41% in Average Optimal Accuracy (AOA). ACL provides AI practitioners with a versatile solution to improve PTM-based continual learning by enhancing plasticity and stability.  |
| RefEdit: A Benchmark and Method for Improving Instruction-based Image
  Editing Model on Referring Expressions (Read more on [arXiv](https://arxiv.org/abs/2506.03448) or [HuggingFace](https://huggingface.co/papers/2506.03448))| Chitta Baral, Yezhou Yang, Shivam Singh, Bimsara Pathiraja, mpatel57 | RefEdit introduces a benchmark and method for improved instruction-based image editing with referring expressions. The paper addresses the challenge of instruction-based image editing models struggling with complex scenes by introducing RefEdit-Bench, a benchmark based on RefCOCO. A synthetic data generation pipeline using GPT-40 and FlowChef is developed, and a new model, RefEdit, is trained on this data. RefEdit, trained on 20,000 editing triplets, outperforms baselines trained on millions of samples. The findings imply that targeted, high-quality synthetic data improves model precision in complex editing scenarios for AI practitioners.  |
| Quantitative LLM Judges (Read more on [arXiv](https://arxiv.org/abs/2506.02945) or [HuggingFace](https://huggingface.co/papers/2506.02945))| Pranchal Agarwal, Tushar Parmanand Budhwani, Jeevana Kruthi Karnuthala, Aishwarya Sahoo, Franck-Dernoncourt | i) This paper introduces quantitative LLM judges, a framework to enhance LLM-based evaluation by decoupling qualitative reasoning from quantitative score prediction. ii) The research aims to improve the accuracy of LLM-as-a-judge by using the judge's textual evaluation to predict more accurate numerical scores aligned with human assessments. iii) The methodology involves training generalized linear models (GLMs) on top of LLM embeddings of textual evaluations from a base judge, using human scores for calibration in different tasks like absolute rating and relative preference prediction. iv) Results show that quantitative judges outperform base judges on both absolute rating and relative preference datasets, achieving up to 6.93x speedups over fine-tuning while maintaining comparable or improved performance in metrics such as MSE, accuracy, and correlation metrics; for example, the LS judge achieved an MSE of 2.626 on the Summarize from Feedback dataset, significantly lower than the base judge's 6.346. v) The framework provides AI practitioners with a computationally efficient and statistically robust alternative to fine-tuning LLMs for evaluation, especially useful when human feedback is limited.  |
| BenchHub: A Unified Benchmark Suite for Holistic and Customizable LLM
  Evaluation (Read more on [arXiv](https://arxiv.org/abs/2506.00482) or [HuggingFace](https://huggingface.co/papers/2506.00482))| Hitesh Patel, Guijin Son, Haneul Yoo, aliceoh, EunsuKim | i) BENCHHUB is introduced as a benchmark repository for evaluating Large Language Models (LLMs) across diverse domains. ii) The research objective is to provide a unified, customizable, and scalable infrastructure for LLM evaluation tailored to specific needs or domains. iii) The methodology involves aggregating and classifying 303K questions from 38 existing benchmark datasets, categorizing them based on skills, subjects, and target types, and automating this process using a Qwen-2.5-7B-based model. iv) Experiments with various LLM families demonstrate significant performance variations across domain-specific subsets, and categorization errors up to 1.5% yield negligible disruption to model rankings. v) BENCHHUB offers AI practitioners a flexible platform for domain-aware benchmarking, enabling identification of underrepresented areas and facilitating more transparent model comparisons.  |
| DLP: Dynamic Layerwise Pruning in Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.23807) or [HuggingFace](https://huggingface.co/papers/2505.23807))| Yingting Li, Yingying Zhang, Jiale Han, Bo Cheng, yulichen | i) The paper introduces Dynamic Layerwise Pruning (DLP), a novel method for unstructured pruning in large language models (LLMs). ii) The research aims to improve LLM pruning by adaptively determining layer importance, addressing the limitations of uniform and predefined layerwise pruning strategies. iii) DLP integrates model weights with input activation information, using the median to determine layer unimportance and allocate sparsity rates inversely proportional to importance. iv) Experiments show that at 70% sparsity, DLP reduces the perplexity of LLaMA2-7B by 7.79 and achieves up to 3.7x end-to-end acceleration on CPU, compared to state-of-the-art. v) DLP offers AI practitioners a compression technique compatible with PEFT and various existing LLM compression techniques, enabling efficient deployment of pruned LLMs in resource-constrained environments.  |
| TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management
  in LLM-based Agentic Multi-Agent Systems (Read more on [arXiv](https://arxiv.org/abs/2506.04133) or [HuggingFace](https://huggingface.co/papers/2506.04133))| Christos Emmanouilidis, Manoj Karkee, Ranjan Sapkota, shainar | i) This paper reviews Trust, Risk, and Security Management (TRISM) for LLM-based agentic multi-agent systems (AMAS). ii) The research objective is to provide a structured analysis of TRISM in the context of the unique characteristics of agentic AI. iii) The methodology involves a systematic literature review across databases to identify relevant research and synthesize findings related to explainability, security, lifecycle governance, and privacy. iv) The paper identifies unique threat vectors and introduces a risk taxonomy for agentic AI, projecting a global market growth for AI agents from $5.4 billion in 2024 to $7.6 billion in 2025. v) For AI practitioners, the paper provides a roadmap to align emerging multi-agent systems with TRiSM principles for safe, accountable, and transparent deployment.  |
| Rex-Thinker: Grounded Object Referring via Chain-of-Thought Reasoning (Read more on [arXiv](https://arxiv.org/abs/2506.04034) or [HuggingFace](https://huggingface.co/papers/2506.04034))| Lei Zhang, Junzhi Yu, Zhaoyang Zeng, Xingyu Chen, Qing Jiang | i) The paper introduces Rex-Thinker, a model for object referring that utilizes chain-of-thought reasoning. ii) The research aims to improve object referring by creating a grounded model that is both verifiable and trustworthy. iii) The methodology involves formulating object referring as a chain-of-thought reasoning task and constructing a large-scale dataset, HumanRef-CoT, to facilitate step-by-step reasoning. iv) Experiments show that Rex-Thinker achieves state-of-the-art performance on the HumanRef benchmark with improved accuracy and fewer hallucinated outputs, demonstrating a 13.8 point improvement in rejection score. v) The CoT-based approach improves interpretability and reduces hallucinations, providing a more robust and reliable object referring system for practical AI applications, especially those requiring high reliability.  |
| Rethinking the Stability-Plasticity Trade-off in Continual Learning from
  an Architectural Perspective (Read more on [arXiv](https://arxiv.org/abs/2506.03951) or [HuggingFace](https://huggingface.co/papers/2506.03951))| Yanan Sun, Tao Feng, JacobYuan, Kurt1024 | i) This paper introduces Dual-Arch, a novel continual learning framework to address the stability-plasticity dilemma by leveraging dual architectures. ii) The research investigates how to balance stability and plasticity at the architectural level in continual learning. iii) The methodology employs distinct network architectures dedicated to either stability or plasticity, using knowledge distillation for knowledge transfer. iv) Experiments show Dual-Arch enhances existing CL methods' performance, achieving up to 10.29% improvement in Last Accuracy, while reducing parameter counts by up to 87%. v) The study provides AI practitioners with a parameter-efficient architectural solution for improving continual learning models by independently allocating networks for stability and plasticity and transferring knowledge via distillation.  |
| VLMs Can Aggregate Scattered Training Patches (Read more on [arXiv](https://arxiv.org/abs/2506.03614) or [HuggingFace](https://huggingface.co/papers/2506.03614))| Chaochao Lu, Chao Yang, Lingjie Chen, Zhanhui Zhou | VLMs can inadvertently stitch together harmful visual information from distributed training data. The research investigates if vision-language models (VLMs) can integrate visual information scattered across multiple training samples with shared textual descriptions, enabling a threat model for bypassing data moderation. The study finetunes open-source VLMs on synthetic datasets consisting of image patches paired with text, evaluating the models' ability to verbalize identifiers associated with the full images from either complete images or text references. Experiments demonstrate that VLMs exhibit strong image-based visual stitching; models finetuned on image patches with a split factor of 8 can verbalize IDs, while adversarial experiments show a 9% evasion rate against OpenAI moderation when using 8x8 patches. The findings imply that AI practitioners should develop moderation techniques that account for cross-sample reasoning to prevent the unintended aggregation of harmful content in VLMs.  |
| Improving Knowledge Distillation Under Unknown Covariate Shift Through
  Confidence-Guided Data Augmentation (Read more on [arXiv](https://arxiv.org/abs/2506.02294) or [HuggingFace](https://huggingface.co/papers/2506.02294))| Lukas Schott, Matthias Hein, Kevin Alexander Laube, Niclas Popp | i) This paper introduces ConfiG, a confidence-guided data augmentation strategy for knowledge distillation under unknown covariate shift. ii) The main research question is whether a student model can become robust to unknown spurious features in a setting with covariate shift if a robust teacher model is available. iii) The methodology involves a diffusion-based data augmentation framework that generates images by maximizing the disagreement between teacher and student models. iv) Experiments on CelebA and SpuCo Birds demonstrate that ConfiG significantly improves worst group accuracy (e.g., achieving 66.1% on CelebA), and spurious mAUC on spurious ImageNet, outperforming diffusion-based data augmentation baselines. v) AI practitioners can use ConfiG to improve the robustness and generalization of student models distilled from large foundation models, particularly when deploying in environments with potential covariate shift and unknown spurious correlations.  |
| Follow the Flow: Fine-grained Flowchart Attribution with Neurosymbolic
  Agents (Read more on [arXiv](https://arxiv.org/abs/2506.01344) or [HuggingFace](https://huggingface.co/papers/2506.01344))| Ryan A. Rossi, Nedim Lipka, Manan Suri, Franck-Dernoncourt, puneetm | i) This paper introduces fine-grained flowchart attribution to improve the reliability and explainability of LLM responses in flowchart-based question answering. ii) The research aims to address the problem of visual hallucination in LLMs when interpreting flowcharts by tracing specific components that ground a referring LLM response. iii) The proposed FlowPathAgent uses a neurosymbolic approach that segments flowcharts, converts them into structured symbolic graphs, and employs an agentic approach for generating attribution paths. iv) Experiments on the newly introduced FlowExplainBench show that FlowPathAgent outperforms strong baselines by 10-14% in mitigating visual hallucinations in LLM answers over flowchart QA. v) FlowPathAgent's neurosymbolic architecture provides AI practitioners with a verifiable and explainable method for processing flowcharts, enhancing decision-making reliability in critical applications.  |
| Survey of Active Learning Hyperparameters: Insights from a Large-Scale
  Experimental Grid (Read more on [arXiv](https://arxiv.org/abs/2506.03817) or [HuggingFace](https://huggingface.co/papers/2506.03817))| Maik Thiele, Claudio Hartmann, Anja Reusch, Tim Rieß, Julius Gonsior | Survey of Active Learning Hyperparameters: Insights from a Large-Scale Experimental Grid analyzes the hyperparameter space of Active Learning (AL) to address reproducibility and adoption challenges. The study aims to quantify the impact of AL hyperparameters and provide guidelines for reliable experimental evaluations. The authors performed an extensive grid search over 4.6 million hyperparameter combinations, analyzing the influence of each parameter on AL performance. The study found that subsets of at least 4,000 combinations can produce results comparable to the complete grid, enabling computational efficiency. The analysis also showed that the implementation of AL strategies within different frameworks can greatly impact performance, more so than the choice of strategies, indicating the need for careful design.  |
| Solving Inverse Problems with FLAIR (Read more on [arXiv](https://arxiv.org/abs/2506.02680) or [HuggingFace](https://huggingface.co/papers/2506.02680))| Jan Eric Lenssen, Bernt Schiele, Andreas Dombos, Dominik Narnhofer, juliuse | FLAIR is introduced as a training-free variational framework integrating flow-based latent generative models for solving inverse imaging problems. The research aims to develop a variational objective for flow matching to leverage generative models as priors, incorporating deterministic trajectory adjustments for atypical modes and decoupled optimization for data consistency. The methodology involves a flow-matching loss aligned with learned velocity fields, hard data consistency steps projecting estimates onto the measurement manifold, and a time-dependent calibration scheme. Results on standard imaging benchmarks demonstrated FLAIR outperforms existing methods, achieving, for instance, a LPIPS of 0.213 on FFHQ for SR ×8 compared to Resample's 0.400. FLAIR offers AI practitioners an improved, training-free approach to incorporating generative priors in inverse problems, enhancing reconstruction quality and sample diversity, though it inherits the limitations of its generative model backbone.  |
| FinChain: A Symbolic Benchmark for Verifiable Chain-of-Thought Financial
  Reasoning (Read more on [arXiv](https://arxiv.org/abs/2506.02515) or [HuggingFace](https://huggingface.co/papers/2506.02515))| Rushil Thareja, Georgi Georgiev, Debopriyo Banerjee, Dhruv Sahnan, Zhuohan Xie | i) The paper introduces FINCHAIN, a new symbolic benchmark for verifiable chain-of-thought (CoT) financial reasoning. ii) The main objective is to create a benchmark for systematically evaluating the ability of language models to perform multi-step financial reasoning with verifiable intermediate steps. iii) The methodology involves constructing 54 financial reasoning topics across 12 domains, each with five parameterized templates including executable Python traces for automatic data generation and the introduction of CHAINEVAL, a metric for evaluating both final answers and intermediate reasoning steps. iv) Results from benchmarking 30 LLMs on FINCHAIN indicate that even state-of-the-art models struggle with complex symbolic tasks and multi-step financial reasoning, with top models achieving 58% Final Answer Correctness (FAC). v) The principal implication is that further research is needed to improve the capacity of LLMs to handle symbolic and multi-hop inference for financial reasoning, as domain-specific fine-tuning alone is insufficient.  |
