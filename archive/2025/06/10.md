

## Papers for 2025-06-10

| Title | Authors | Summary |
|-------|---------|---------|
| Reinforcement Pre-Training (Read more on [arXiv](https://arxiv.org/abs/2506.08007) or [HuggingFace](https://huggingface.co/papers/2506.08007))| Tianzhu Ye, Qingxiu Dong, frontierai, YaoTang23, unilm | i) This paper introduces Reinforcement Pre-Training (RPT), a novel scaling paradigm for large language models by reframing next-token prediction as a reinforcement learning task. ii) The main research objective is to improve language modeling accuracy and provide a strong pre-trained foundation for reinforcement fine-tuning by incentivizing next-token reasoning. iii) RPT employs on-policy reinforcement learning with intrinsic, verifiable rewards based on the correctness of next-token predictions, leveraging vast amounts of text data without external annotations. iv) Experiments show that RPT significantly improves next-token prediction accuracy, with RPT-14B achieving consistently higher accuracy across all difficulty levels compared to R1-Distill-Qwen-14B, and reaching the performance of R1-Distill-Qwen-32B. v) RPT offers AI practitioners an effective pre-training approach that enhances both language modeling and reasoning capabilities, providing a stronger foundation for subsequent reinforcement fine-tuning and improving zero-shot performance on downstream tasks.  |
| Lingshu: A Generalist Foundation Model for Unified Multimodal Medical
  Understanding and Reasoning (Read more on [arXiv](https://arxiv.org/abs/2506.07044) or [HuggingFace](https://huggingface.co/papers/2506.07044))| 26hzhang, gowitheflow, Jianyu, kenchan0226, xww033 | i) LINGSHU is a new medical-specialized multimodal large language model (MLLM) aimed at improving medical understanding and reasoning. ii) The primary objective is to address the limitations of existing MLLMs in medical applications by enhancing medical knowledge coverage, reducing hallucinations, and improving reasoning capabilities. iii) The methodology includes a comprehensive data curation procedure acquiring medical knowledge from imaging, texts, and general-domain data, along with multi-stage training. iv) Results show that LINGSHU outperforms existing open-source multimodal models on medical tasks like multimodal QA, text-based QA, and medical report generation, demonstrating a 7.2% average accuracy improvement over the second-best model in medical VQA tasks. v) LINGSHU offers AI practitioners a framework for building more robust and reliable MLLMs tailored for specialized domains like medicine, particularly concerning data curation and model training strategies. |
| MiniCPM4: Ultra-Efficient LLMs on End Devices (Read more on [arXiv](https://arxiv.org/abs/2506.07900) or [HuggingFace](https://huggingface.co/papers/2506.07900))| Yuxuan Li, MiniCPM Team, BigDong, guojunshaoyao, xcjthu | i) This paper introduces MiniCPM4, a highly efficient large language model (LLM) designed for end-side devices. ii) The main objective is to achieve efficiency in LLMs through innovations in model architecture, training data, training algorithms, and inference systems. iii) The methodology includes proposing InfLLM v2 (a trainable sparse attention mechanism), UltraClean (a data filtering strategy), and CPM.cu (CUDA inference framework). iv) MiniCPM4-8B achieves a 7-fold speed improvement in processing 128K-length documents compared to Qwen3-8B on end-side devices. v) The research implies that systematic innovation can create efficient LLMs for resource-constrained environments, significantly reducing computational costs for AI practitioners.  |
| Saffron-1: Towards an Inference Scaling Paradigm for LLM Safety
  Assurance (Read more on [arXiv](https://arxiv.org/abs/2506.06444) or [HuggingFace](https://huggingface.co/papers/2506.06444))| Hanghang Tong, Jingrui He, Tianxin Wei, Gaotang Li, Ruizhong Qiu | i) This paper introduces SAFFRON, a novel inference scaling paradigm for enhancing LLM safety. ii) The primary research objective is to address the exploration-efficiency dilemma in scaling inference for LLM safety assurance. iii) The methodology involves replacing the process reward model (PRM) with a multifurcation reward model (MRM), trained with partial supervision and a conservative exploration constraint, and employing a Trie-based key-value caching strategy. iv) Results show that SAFFRON achieves a lower attack success rate (ASR) of 0.409 on Harmful HEx-PHI, outperforming baseline methods under the same inference compute budget. v) AI practitioners can leverage SAFFRON to improve the robustness of LLMs against jailbreak attacks by employing a multifurcation reward model, thereby significantly enhancing safety in resource-constrained environments.  |
| OneIG-Bench: Omni-dimensional Nuanced Evaluation for Image Generation (Read more on [arXiv](https://arxiv.org/abs/2506.07977) or [HuggingFace](https://huggingface.co/papers/2506.07977))| Shuhan Wu, Peng Xing, Jingjing Chang, wchengad, fangyixiao | i) OneIG-Bench is introduced as a comprehensive benchmark for fine-grained evaluation of text-to-image models across multiple dimensions. ii) The paper aims to provide a holistic framework for evaluating T2I models across dimensions including prompt-image alignment, text rendering, reasoning, stylization, and diversity. iii) The methodology involves a curated dataset of over 1000 prompts categorized into six core assessment categories, along with quantitative metrics tailored to each dimension. iv) Experiments show that models like GPT-4o demonstrate superior performance in knowledge retention and reasoning ability, but no single model exhibits outstanding performance across all specific subjects and that OneIG-Bench facilitates identification of model strengths and weaknesses. v) AI practitioners can leverage OneIG-Bench for in-depth model performance analysis, assisting in pinpointing strengths and bottlenecks in T2I pipelines and enabling focused improvements.  |
| SpatialLM: Training Large Language Models for Structured Indoor Modeling (Read more on [arXiv](https://arxiv.org/abs/2506.07491) or [HuggingFace](https://huggingface.co/papers/2506.07491))| Rui Tang, Chuan Fang, Junhao Zhong, bertjiazheng, ysmao | SPATIALLM fine-tunes large language models for structured 3D indoor scene understanding from point cloud data. The research aims to enhance LLMs' spatial understanding capabilities for tasks like layout estimation and 3D object detection. A large-scale synthetic dataset of 12,328 indoor scenes with 3D annotations was created to train a standard multimodal LLM architecture. The model achieves state-of-the-art performance in layout estimation on public benchmarks and competitive results in 3D object detection, reaching 86.5% IOU2D@0.25 on the Structured3D dataset for layout estimation after fine-tuning. This provides a feasible approach for leveraging LLMs to enhance spatial understanding in applications like augmented reality and robotics, showing how existing LLMs can be augmented with new datasets for specific spatial reasoning tasks.  |
| Astra: Toward General-Purpose Mobile Robots via Hierarchical Multimodal
  Learning (Read more on [arXiv](https://arxiv.org/abs/2506.06205) or [HuggingFace](https://huggingface.co/papers/2506.06205))| Yansheng Wang, Ziyang Liu, Jiaxin Hu, Peiyu He, sc-bd | Astra presents a dual-model architecture for mobile robot navigation using hierarchical multimodal learning. The research addresses the challenges of goal localization, self-localization, and path planning in complex indoor environments. Astra employs a multimodal LLM (Astra-Global) for global tasks and a multitask network (Astra-Local) with a 4D spatial-temporal encoder for local tasks, trained via supervised finetuning, reinforcement learning, and self-supervision. Experiments show Astra achieves a high end-to-end mission success rate (84.2% in warehouses, 99.1% in office buildings). This work offers AI practitioners a comprehensive framework for developing adaptable and high-performing mobile robots in diverse environments by combining LLMs with task-specific networks.  |
| Rethinking Cross-Modal Interaction in Multimodal Diffusion Transformers (Read more on [arXiv](https://arxiv.org/abs/2506.07986) or [HuggingFace](https://huggingface.co/papers/2506.07986))| Wangmeng Zuo, Zhaoxi Chen, Zhengyao Lv, ChenyangSi, ldiex | i) This paper introduces TACA, a parameter-efficient method for enhancing text-image alignment in Multimodal Diffusion Transformers (MM-DiTs). ii) The research aims to address cross-modal attention suppression and timestep-insensitive weighting in MM-DiTs to improve text-image alignment. iii) The proposed TACA method dynamically rebalances cross-modal attention using temperature scaling and timestep-dependent adjustment and is combined with LoRA fine-tuning. iv) Experiments on T2I-CompBench show that TACA improves spatial relationship understanding by 16.4% on FLUX.1-Dev and by 28.3% on SD3.5-Medium. v) TACA offers AI practitioners a computationally inexpensive method to improve semantic fidelity in text-to-image diffusion models by dynamically balancing cross-modal attention.  |
| GTR-CoT: Graph Traversal as Visual Chain of Thought for Molecular
  Structure Recognition (Read more on [arXiv](https://arxiv.org/abs/2506.07553) or [HuggingFace](https://huggingface.co/papers/2506.07553))| Xingjian Wei, Yifan He, Jiang Wu, Hoter, jcwang0602 | i) The paper introduces GTR-Mol-VLM, a new framework for Optical Chemical Structure Recognition (OCSR) using graph traversal as a visual chain of thought. ii) The research objective is to improve OCSR performance, particularly in complex molecular structures with abbreviated functional groups, by addressing limitations in existing image-captioning-based vision-language models (VLMs). iii) The methodology employs a Graph Traversal as Visual Chain of Thought mechanism for incremental parsing through atom-bond predictions and a data-centric approach called "Faithfully Recognize What You've Seen" to manage abbreviated structures. iv) GTR-Mol-VLM outperforms existing specialist models and chemistry-domain VLMs, with an approximately 14 percentage point improvement over the second-best baseline on molecular images with functional group abbreviations. v) GTR-Mol-VLM's graph traversal and data correction techniques offer AI practitioners advanced methods for parsing complex visual structures, enhancing accuracy and consistency in applications requiring detailed structural analysis, such as cheminformatics and AI for Science.  |
| Through the Valley: Path to Effective Long CoT Training for Small
  Language Models (Read more on [arXiv](https://arxiv.org/abs/2506.07712) or [HuggingFace](https://huggingface.co/papers/2506.07712))| Wei Lu, Jiaxi Li, Albus-Chen, RogerLos | i) This paper investigates performance degradation in small language models (SLMs) when trained with limited long chain-of-thought (CoT) data. ii) The research question focuses on understanding and mitigating the "Long CoT Degradation" phenomenon observed in SLMs during CoT training. iii) The methodology includes supervised fine-tuning (SFT) with varying amounts of long CoT data and reinforcement learning (RL) across models from the Qwen, LLaMA, and Gemma families, along with analysis of reflection behavior and cumulative error. iv) The primary result is the empirical discovery that SLMs trained on only 8k long CoT examples can lose up to 75% of their original performance before fine-tuning. v) This highlights the need for scaled supervision during SFT or potentially RL to enhance the model, as smaller models may be overwhelmed and produce less accurate reasoning.  |
| BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation (Read more on [arXiv](https://arxiv.org/abs/2506.07530) or [HuggingFace](https://huggingface.co/papers/2506.07530))| Xilin Chen, Ruiping Wang, Chuyan Xiong, Hongyu Wang | BitVLA introduces a 1-bit Vision-Language-Action model for robotics manipulation with ternary parameters. The research aims to reduce the memory footprint of VLA models for deployment on resource-constrained robotic systems. The methodology involves quantizing a full-precision vision encoder to 1.58-bit using distillation-aware training with a full-precision teacher model. BitVLA achieves a comparable performance to OpenVLA-OFT (4-bit quantized) on the LIBERO benchmark while only consuming 29.8% of the memory. BitVLA provides AI practitioners with a cost-effective, high-performance solution for robotics manipulation suitable for memory-constrained edge devices by substantially reducing model size.  |
| Pre-trained Large Language Models Learn Hidden Markov Models In-context (Read more on [arXiv](https://arxiv.org/abs/2506.07298) or [HuggingFace](https://huggingface.co/papers/2506.07298))| Jennifer J. Sun, Yahya Satter, Zhaolin Gao, sarahdean, DaiYijia | Pre-trained Large Language Models (LLMs) can effectively model data generated by Hidden Markov Models (HMMs) via in-context learning. The research investigates whether LLMs can learn and predict HMM-generated sequences in-context, how HMM properties affect ICL performance, and whether these findings translate to real-world datasets. The methodology involves controlled experiments on synthetic HMMs, varying parameters like state/observation space, mixing rate, entropy, and applying LLMs to real-world animal decision-making tasks. LLMs achieve predictive accuracy approaching the theoretical optimum on synthetic HMMs, and ICL achieves competitive performance with domain-specific models on animal decision-making tasks, and LLM in-context learning achieves an average prediction accuracy of 86.2% on the IBL mice dataset. ICL offers a data-efficient and accessible approach for next-observation prediction, particularly valuable when rapid insights are needed or when data for training bespoke models is scarce, and the practical guidelines provided are useful to researchers who wish to utilize LLMs as powerful, efficient statistical tools in complex scientific data analysis.  |
| The Illusion of Thinking: Understanding the Strengths and Limitations of
  Reasoning Models via the Lens of Problem Complexity (Read more on [arXiv](https://arxiv.org/abs/2506.06941) or [HuggingFace](https://huggingface.co/papers/2506.06941))| Samy Bengio, Maxwell Horton, Keivan Alizadeh, Iman Mirzadeh, parshinsh | i) The paper analyzes Large Reasoning Models (LRMs) using controllable puzzle environments to assess their reasoning capabilities beyond final answer accuracy. ii) The research investigates how LRMs perform and scale with increasing problem complexity, focusing on the structure and quality of reasoning traces. iii) The methodology involves evaluating LRMs and standard LLMs on algorithmic puzzles, systematically manipulating complexity and analyzing both final answers and intermediate reasoning steps using puzzle simulators. iv) The primary results demonstrate that LRMs face complete accuracy collapse beyond certain complexity thresholds, and their reasoning effort, measured in tokens, initially increases but then declines with increasing complexity, eventually collapsing to near-zero accuracy. v) This indicates that AI practitioners should consider the scaling limitations of current LRMs' reasoning capabilities relative to problem complexity, and their limited ability to perform exact computations, potentially requiring new designs for reasoning systems.  |
| CCI4.0: A Bilingual Pretraining Dataset for Enhancing Reasoning in Large
  Language Models (Read more on [arXiv](https://arxiv.org/abs/2506.07463) or [HuggingFace](https://huggingface.co/papers/2506.07463))| Yang Yu, Jijie Li, Yonghua, ldwang, ZacLiu | CCI4.0 is introduced as a large-scale bilingual pretraining dataset to improve reasoning in LLMs. The research aims to enhance LLMs' reasoning through a curated dataset and diverse reasoning templates. The methodology involves a two-stage deduplication process, multi-classifier quality scoring, and domain-aware fluency filtering, resulting in a 35TB dataset and 4.5 billion CoT templates. Evaluations show pretraining on CCI4.0 improves performance on benchmarks like MMLU and ARC-Challenge, with CCI4.0 achieving a 33.09 average score across benchmarks versus 32.92 for Nemotron-CC-HQ. AI practitioners can leverage CCI4.0 for pretraining LLMs, yielding enhanced reasoning capabilities, particularly in math and code-related tasks.  |
| Well Begun is Half Done: Low-resource Preference Alignment by
  Weak-to-Strong Decoding (Read more on [arXiv](https://arxiv.org/abs/2506.07434) or [HuggingFace](https://huggingface.co/papers/2506.07434))| Tianyu Liu, Yuxuan Fan, Wen Luo, SylvainWei, songff | i) The paper introduces Weak-to-Strong Decoding (WSD), a novel framework for low-resource preference alignment in Large Language Models (LLMs). ii) The primary objective is to enhance the alignment ability of base LLMs with human preferences using a small aligned draft model to guide the initial decoding stages. iii) WSD employs a small, fine-tuned model to generate an aligned prefix, followed by the base LLM continuing the response generation, governed by an auto-switch mechanism based on confidence scores. iv) Experiments show WSD improves base LLMs’ performance on preference alignment benchmarks, achieving a win-rate of 98.19% on HH-RLHF with Llama-3-70B, while also mitigating alignment tax on downstream tasks like GSM8K and HumanEval. v) WSD provides AI practitioners with a computationally efficient method to improve LLM alignment without significant performance degradation on other tasks, especially useful when fine-tuning resources are limited.  |
| GUI-Reflection: Empowering Multimodal GUI Models with Self-Reflection
  Behavior (Read more on [arXiv](https://arxiv.org/abs/2506.08012) or [HuggingFace](https://huggingface.co/papers/2506.08012))| Lewei Lu, Jiaheng Yu, Bo Wang, Shengnan Ma, Penghao Wu | i) This paper introduces GUI-Reflection, a framework that enhances multimodal GUI models with self-reflection and error correction capabilities. ii) The research aims to equip GUI agents with self-reflection and correction capabilities for more robust and adaptable GUI automation. iii) The key methodology involves three training stages: GUI-specific pre-training using GUI-Reflection Task Suite, offline supervised fine-tuning (SFT) with automatically constructed reflection data, and online reflection tuning in a mobile GUI environment. iv) A success rate of 34.72% on level-2 tasks was achieved when combining reflection data during offline SFT with reflection tuning online, compared to 14.58% for a baseline model trained without reflection data in offline SFT and using only filtered behavior cloning. v) GUI-Reflection provides AI practitioners with tools and methodologies to improve the robustness and adaptability of GUI automation models by explicitly training for error recognition and recovery, potentially reducing reliance on nearly error-free training data.  |
| ConfQA: Answer Only If You Are Confident (Read more on [arXiv](https://arxiv.org/abs/2506.07309) or [HuggingFace](https://huggingface.co/papers/2506.07309))| Alicia Sun, Vera Yan, Kai Sun, Yifan Ethan Xu, MaggieHuang | i) The paper introduces ConfQA, a fine-tuning strategy designed to reduce hallucination in large language models (LLMs). ii) The main research objective is to develop a method to enable LLMs to refrain from generating factual statements when confidence is low, instead opting to state "I am unsure." iii) The methodology involves fine-tuning LLMs using a dampening prompt "answer only if you are confident" and training data consisting of simple factual statements derived from knowledge graphs, specifically attribute values. iv) The primary result is a reduction in hallucination rate from 20-40% to under 5% across multiple factuality benchmarks after applying ConfQA. v) The principal implication for AI practitioners is that ConfQA provides a practical approach for improving the reliability of LLMs in knowledge-intensive tasks by reducing hallucination, which allows for seamless switching between parameterized and symbolic knowledge, with an accuracy gain to beyond 95%.  |
| Vision Transformers Don't Need Trained Registers (Read more on [arXiv](https://arxiv.org/abs/2506.08010) or [HuggingFace](https://huggingface.co/papers/2506.08010))| Yossi Gandelsman, Alexei Efros, Amil Dravid, Nick Jiang | i) The paper introduces a training-free method to improve Vision Transformers by addressing high-norm token artifacts. ii) The main objective is to develop a training-free approach that mitigates noisy attention maps in Vision Transformers without retraining models from scratch. iii) The methodology involves identifying register neurons responsible for creating high-norm activations on outlier tokens and redirecting these activations to an untrained appended token. iv) The study demonstrates a 20-point improvement in correct localization for unsupervised object discovery using the proposed test-time register approach. v) AI practitioners can use this training-free method to enhance existing pre-trained Vision Transformer models, improving performance on downstream visual tasks and interpretability, without incurring the cost of retraining.  |
| Dreamland: Controllable World Creation with Simulator and Generative
  Models (Read more on [arXiv](https://arxiv.org/abs/2506.08006) or [HuggingFace](https://huggingface.co/papers/2506.08006))| Honglin He, Weizhen Wang, Leon Liu, Ziyang Leng, Sicheng Mo | Dreamland presents a hybrid world generation framework combining simulators and generative models for controllable scene creation. The research addresses the lack of element-wise controllability in existing video generative models for dynamic world creation. It uses a layered world abstraction (LWA) to bridge a physics-based simulator and a pretrained generative model. Dreamland outperforms existing baselines with 50.8% improved image quality and 17.9% stronger controllability. This hybrid pipeline offers AI practitioners enhanced capabilities for synthetic data generation with simulator-level control, enhancing embodied agent training. The paper constructs a dataset called D3Sim (Diverse Driving Scenario in Real WorlD and Simulation) for training and benchmarking hybrid generation pipelines. It's unclear what specific kind of embodied AI agents the technique would best serve or what types of pre-trained generative models are supported.  |
| Image Reconstruction as a Tool for Feature Analysis (Read more on [arXiv](https://arxiv.org/abs/2506.07803) or [HuggingFace](https://huggingface.co/papers/2506.07803))| Andrey Kuznetsov, Elizaveta Goncharova, Dmitrii Tarasov, combat-helicopter | Vision encoder interpretability is analyzed via image reconstruction quality. The research aims to interpret vision features through image reconstruction by comparing encoders trained with differing objectives. The methodology involves reconstructing images from latent feature tensors and analyzing the effects of feature space manipulations on the reconstructed images. The study found that SigLIP2 produces significantly higher-fidelity reconstructions than SigLIP, and orthogonal rotations in the embedding space yield interpretable color transformations. This approach enables AI practitioners to assess and compare the informativeness of different vision encoder feature representations, informing model selection and feature space manipulation for downstream applications. There is no quantifiable measure of reconstruction quality.  |
| Cartridges: Lightweight and general-purpose long context representations
  via self-study (Read more on [arXiv](https://arxiv.org/abs/2506.06266) or [HuggingFace](https://huggingface.co/papers/2506.06266))| Dylan Zinsley, Neel Guha, Simran Arora, Ryan Ehrlich, sabrieyuboglu | i) The paper introduces CARTRIDGES, a method for creating lightweight KV-cache representations of long-context corpora for efficient inference. ii) The research aims to develop a memory-efficient alternative to in-context learning (ICL) that maintains performance on long-context tasks. iii) The methodology involves training smaller KV caches offline using a self-study approach that generates synthetic conversations via context distillation. iv) CARTRIDGES trained with self-study match ICL performance while using 38.6× less memory and enabling 26.4× higher throughput, and extends effective context length from 128k to 484k tokens on MTOB. v) CARTRIDGES provide AI practitioners with a composable and efficient mechanism for managing and serving long-context applications, reducing memory footprint and improving throughput.  |
| Bootstrapping World Models from Dynamics Models in Multimodal Foundation
  Models (Read more on [arXiv](https://arxiv.org/abs/2506.06006) or [HuggingFace](https://huggingface.co/papers/2506.06006))| Shay B. Cohen, Anna Korhonen, Yftah Ziser, ducdauge, yfqiu-nlp | i) The paper introduces techniques to improve world models in vision-language models (VLMs) by leveraging dynamics models. ii) The main objective is to investigate whether vision-and-language foundation models contain a realistic world model and a dynamics model, and to improve world models through dynamics models. iii) The methodology involves fine-tuning VLMs to acquire a dynamics model and using it to bootstrap a world model through weak supervision with synthetic data and inference-time verification. iv) The best model achieves competitive performance in action-centric image editing on AURORA-BENCH, improving on state-of-the-art models by 15% on real-world subsets according to GPT4o-as-judge. v) The implication is that dynamics models can enhance world model capabilities in VLMs, offering a promising approach for AI practitioners working on embodied agents and multimodal reasoning.  |
| PolyVivid: Vivid Multi-Subject Video Generation with Cross-Modal
  Interaction and Enhancement (Read more on [arXiv](https://arxiv.org/abs/2506.07848) or [HuggingFace](https://huggingface.co/papers/2506.07848))| Yuan Zhou, Jiangning Zhang, Zhengguang Zhou, Zhentao Yu, Teng Hu | PolyVivid is introduced as a multi-subject video customization framework enabling flexible and identity-consistent generation. The research aims to improve fine-grained video generation controllability, particularly for multi-subject customization with consistent identity and interaction. A VLLM-based text-image fusion module, a 3D-RoPE-based enhancement module, and an attention-inherited identity injection module are employed. Experiments demonstrate that PolyVivid achieves superior performance in identity fidelity, video realism, and subject alignment, and it achieves superior similarity scores for both face and object identity (Face-sim and DINO-sim) versus other methods. PolyVivid offers AI practitioners a method for generating high-fidelity, controllable videos with multiple customized subjects, potentially improving video content creation pipelines.  |
| Learning What Reinforcement Learning Can't: Interleaved Online
  Fine-Tuning for Hardest Questions (Read more on [arXiv](https://arxiv.org/abs/2506.07527) or [HuggingFace](https://huggingface.co/papers/2506.07527))| Xiaochen Ma, Lexiang Tang, Meiyi Qiang, Hao Liang, RoadQAQ | i) This paper introduces ReLIFT, a novel training approach combining reinforcement learning (RL) and supervised fine-tuning (SFT) to enhance large language model (LLM) reasoning. ii) The main research objective is to overcome the limitations of RL in inducing capabilities exceeding the base model by integrating SFT for knowledge acquisition. iii) ReLIFT employs an interleaved training process where RL is primarily used, with SFT triggered online using high-quality solutions collected for the most challenging questions encountered during RL. iv) The primary result is an average improvement of over +5.2 points across five competition-level benchmarks and one out-of-distribution benchmark compared to zero-RL models. v) The principal implication is that ReLIFT provides a scalable method for AI practitioners to improve LLM reasoning by adaptively interleaving RL and SFT, leveraging targeted fine-tuning to address the limitations of standard RL approaches.  |
| Overclocking LLM Reasoning: Monitoring and Controlling Thinking Path
  Lengths in LLMs (Read more on [arXiv](https://arxiv.org/abs/2506.07240) or [HuggingFace](https://huggingface.co/papers/2506.07240))| Lior Wolf, Itamar Zimerman, royeis | i) This paper introduces a method for monitoring and controlling the reasoning path length in Large Language Models (LLMs). ii) The main research question is how to understand and manipulate the mechanisms by which LLMs regulate the length of their reasoning processes during explicit thought. iii) The methodology involves analyzing hidden representations to extract "progress vectors" that indicate the model's position within the reasoning phase, followed by interventions that manipulate these vectors. iv) The primary result is that intervening on these progress vectors can reduce unnecessary reasoning steps, improving answer accuracy and inference latency; for example, it shows that our method increases the number of correct answers on Math-500 by at least 80% in the 512 token-budget regime and boosts correct responses on GSM-8K by an average of 80% across the 256 and 512 token settings. v) The principal implication for AI practitioners is a technique for improving the efficiency and effectiveness of LLMs by mitigating overthinking through controlled manipulation of internal progress encodings, providing better test-time scaling.  |
| GeometryZero: Improving Geometry Solving for LLM with Group Contrastive
  Policy Optimization (Read more on [arXiv](https://arxiv.org/abs/2506.07160) or [HuggingFace](https://huggingface.co/papers/2506.07160))| Qipeng Guo, Zimian Peng, Dianyi Wang, Yibin Wang, LibraTree | i) GeometryZero presents a novel reinforcement learning framework, Group Contrastive Policy Optimization (GCPO), to improve geometry problem-solving capabilities of LLMs. ii) The research aims to address the limitations of existing GRPO-based methods in geometry reasoning due to their reliance on unconditional rewards for auxiliary construction. iii) The methodology involves introducing Group Contrastive Masking and Length Reward to adaptively provide positive or negative reward signals for auxiliary construction based on contextual utility. iv) Empirical evaluations on Geometry3K and MathVista demonstrate that GeometryZero models consistently outperform baselines, achieving an average improvement of 4.29% across all benchmarks. v) GCPO provides AI practitioners with a method for training moderate-sized LLMs to judiciously employ auxiliary constructions in geometry reasoning, offering an alternative to relying on colossal LLMs.  |
| Robust Preference Optimization via Dynamic Target Margins (Read more on [arXiv](https://arxiv.org/abs/2506.03690) or [HuggingFace](https://huggingface.co/papers/2506.03690))| Xingyu Lu, Zhibo Zhu, Jiancan Wu, Junkang Wu, Sunshine279 | i) The paper introduces γ-PO, a direct preference optimization method utilizing dynamic target margins to enhance the robustness of aligning large language models. ii) The primary objective is to mitigate performance degradation in DPO due to noisy preference data by dynamically adjusting reward margins. iii) The methodology involves instance-specific margin calibration, prioritizing high-confidence pairs while suppressing noise from ambiguous pairs. iv) Experiments across AlpacaEval2 and Arena-Hard show γ-PO achieves an average 4.4% improvement over baselines. v) γ-PO offers a plug-and-play solution for AI practitioners to improve LLM alignment with minimal code changes and computational overhead.  |
| Play to Generalize: Learning to Reason Through Game Play (Read more on [arXiv](https://arxiv.org/abs/2506.08011) or [HuggingFace](https://huggingface.co/papers/2506.08011))| Junfei Xiao, Alan Yuille, Shiyi Lan, Yinsong Ma, Yunfei Xie | i) The paper introduces Visual Game Learning (ViGaL), a novel post-training paradigm leveraging gameplay to enhance multimodal reasoning in Large Language Models (MLLMs). ii) The research investigates whether reinforcement learning (RL) through arcade-like games can improve the out-of-domain generalization capabilities of MLLMs on multimodal reasoning tasks. iii) The methodology involves post-training a 7B-parameter MLLM using rule-based RL on games like Snake and Rotation, employing custom game environments and reward designs. iv) Results demonstrate that ViGaL achieves enhanced out-of-domain performance, with ViGaL (RL on game) exhibiting a higher average accuracy increase than MM-Eureka (RL on math) across three multimodal math benchmarks, increasing MathVerse accuracy by 0.5%. v) ViGaL offers AI practitioners a controllable and scalable pre-training approach using synthetic games to unlock generalizable multimodal reasoning abilities in MLLMs, potentially reducing reliance on large-scale domain-specific data.  |
| MegaHan97K: A Large-Scale Dataset for Mega-Category Chinese Character
  Recognition with over 97K Categories (Read more on [arXiv](https://arxiv.org/abs/2506.04807) or [HuggingFace](https://huggingface.co/papers/2506.04807))| Yixin Zhao, Peirong Zhang, lianwen, shiyx1, ZZXF | i) The paper introduces MegaHan97K, a new large-scale dataset for mega-category Chinese character recognition. ii) The objective is to address the absence of comprehensive datasets for recognizing the vast number of Chinese characters, particularly infrequent and archaic ones. iii) The methodology involves creating a dataset with three subsets: handwritten, historical, and synthetic, covering 97,455 categories. iv) The MegaHan97K dataset includes Chinese characters of 97,455 categories, which is at least six times more than existing datasets, and a average improvement of 22.43% compared to without the synthetic subset. v) The MegaHan97K dataset provides AI practitioners with a new benchmark for evaluating and improving Chinese character recognition models, particularly for cultural heritage preservation and digital applications, however it increased storage demands under the mega-category setting.  |
| Improving large language models with concept-aware fine-tuning (Read more on [arXiv](https://arxiv.org/abs/2506.07833) or [HuggingFace](https://huggingface.co/papers/2506.07833))| Dacheng Tao, Jiaxing Huang, Xikun Zhang, michaelchenkj | i) The paper introduces Concept-Aware Fine-Tuning (CAFT), a multi-token training method for improving conceptual understanding in Large Language Models (LLMs). ii) The primary objective is to address the limitation of next-token prediction in LLMs, which hinders their ability to form coherent, high-level concepts. iii) CAFT trains auxiliary heads to predict multiple future tokens simultaneously and incorporates a modified cross-entropy loss function, facilitating concept-aware learning during fine-tuning. iv) Experiments demonstrate that CAFT improves performance across diverse tasks, with HumanEval coding accuracy increasing from 40.9% (LoRA Fine-tuning) to 45.1% when using CAFT. v) CAFT democratizes multi-token prediction for broader use by AI practitioners enabling them to enhance the conceptual understanding and performance of LLMs in downstream applications.  |
| Evaluating LLMs Robustness in Less Resourced Languages with Proxy Models (Read more on [arXiv](https://arxiv.org/abs/2506.07645) or [HuggingFace](https://huggingface.co/papers/2506.07645))| Karolina Seweryn, llmAttack, mchraba | Evaluating robustness of LLMs in low-resource languages is critical. This work aims to assess the robustness of LLMs to perturbations in less-resourced languages, specifically Polish. The study employed a framework for generating perturbed datasets using proxy models and attribution methods to identify important words for targeted attacks. Experiments with Polish datasets showed that LLMs are susceptible to character and word-level attacks with a SHAP attribution success rate of 37% for Diacritical perturbations on RoBERTa and that these attacks drastically alter model predictions. These findings suggest potential vulnerabilities in LLMs internal safety mechanisms, underlining the need for AI practitioners to prioritize robustness evaluations, especially when deploying multilingual models in lower-resourced language contexts.  |
| Proactive Assistant Dialogue Generation from Streaming Egocentric Videos (Read more on [arXiv](https://arxiv.org/abs/2506.05904) or [HuggingFace](https://huggingface.co/papers/2506.05904))| Anuj Kumar, Andrea Madotto, Zhaojiang Lin, Xin Luna Dong, 594zyc | i) This paper presents a framework for proactive assistant dialogue generation from streaming egocentric videos, including a dataset, evaluation metrics, and an end-to-end model. ii) The primary research objective is to develop an AI system capable of generating prompt, appropriate, and helpful guidance from streaming egocentric videos in real-time. iii) The methodology involves synthesizing dialogues from annotated egocentric videos using large language models (LLMs) to create a dataset (PROASSIST), developing automatic evaluation metrics, and building an end-to-end multimodal LLM (MLLM). iv) Results include a synthetic dialogue dataset of 30,135 dialogues across 479 hours of video, and an MLLM with negative frame sub-sampling improving F1 scores in response timing decisions, by over 8 percentage points. v) For AI practitioners, this work offers a large-scale dataset and evaluation framework for training and benchmarking proactive AI assistants capable of guiding users through tasks using real-time video inputs.  |
| EVOREFUSE: Evolutionary Prompt Optimization for Evaluation and
  Mitigation of LLM Over-Refusal to Pseudo-Malicious Instructions (Read more on [arXiv](https://arxiv.org/abs/2505.23473) or [HuggingFace](https://huggingface.co/papers/2505.23473))| Chong Teng, Fei Li, Xin Zhang, Xiaofeng Mao, Xiaorui Wu | EVOREFUSE introduces an evolutionary prompt optimization algorithm to generate diverse, high-confidence pseudo-malicious instructions for evaluating and mitigating LLM over-refusals. The research aims to develop a method for automatically generating diverse refusal-inducing instructions to address limitations in existing instruction curation techniques. The methodology uses an evolutionary algorithm optimizing an Evidence Lower Bound (ELBO) objective, incorporating mutation and recombination operations guided by salient cues identified in over-refusal datasets. The study demonstrates that EVOREFUSE achieves a 140.41% higher average refusal triggering rate across 9 LLMs compared to existing benchmarks and that fine-tuning LLAMA3.1-8B-INSTRUCT with EVOREFUSE-ALIGN reduces over-refusals by 14.31% using SFT and 40.04% using DPO. This highlights a novel strategy for hardening LLMs against over-refusals by generating targeted training data, improving their helpfulness without compromising safety.  |
