

## Papers for 2025-06-03

| Title | Authors | Summary |
|-------|---------|---------|
| Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective
  Reinforcement Learning for LLM Reasoning (Read more on [arXiv](https://arxiv.org/abs/2506.01939) or [HuggingFace](https://huggingface.co/papers/2506.01939))| lyq333, Zhenru, xionghuichen, chujiezheng, shenzhi-wang | i) The paper identifies high-entropy minority tokens in Chain-of-Thought reasoning as critical forks that drive effective RLVR. ii) The research aims to understand the mechanisms of RLVR through the lens of token entropy patterns and improve RLVR performance. iii) The methodology involves analyzing token entropy patterns in CoT reasoning and restricting policy gradient updates to forking tokens during RLVR training. iv) Results show that restricting RLVR training to the top 20% of high-entropy tokens achieves comparable or superior performance to full-gradient updates, with a +11.04 improvement on AIME'25 and +7.71 on AIME'24 for a Qwen3-32B model. v) AI practitioners can leverage high-entropy minority tokens to optimize RLVR training for LLM reasoning, potentially reducing computational costs and improving performance. |
| REASONING GYM: Reasoning Environments for Reinforcement Learning with
  Verifiable Rewards (Read more on [arXiv](https://arxiv.org/abs/2505.24760) or [HuggingFace](https://huggingface.co/papers/2505.24760))| Richard Jones, Joe Sharratt, JeanKaddour, OllieStanley, zafstojano | i) The paper introduces REASONING GYM (RG), a diverse library of reasoning environments with verifiable rewards for reinforcement learning (RL) of reasoning models. ii) The main objective is to provide a scalable and controllable training environment that alleviates the data scarcity bottleneck faced by current RL-based reasoning models. iii) RG uses procedural generation to create over 100 distinct data generators and verifiers across various domains including algebra, geometry, and logic, enabling adjustable complexity and automatic reward mechanisms. iv) Experiments reveal that frontier LLMs exhibit low zero-shot performance on many RG tasks, with difficulty cliffs causing performance drops of up to 62% in code generation; RLVR training on RG tasks improves performance on external benchmarks like MATH by 9.7% for Qwen2.5-3B-Instruct. v) The RG library and RLVR training can be used by AI practitioners to systematically evaluate and improve the reasoning capabilities of language models via RL, addressing current limitations in reasoning benchmarks.  |
| Taming LLMs by Scaling Learning Rates with Gradient Grouping (Read more on [arXiv](https://arxiv.org/abs/2506.01049) or [HuggingFace](https://huggingface.co/papers/2506.01049))| danxu, MarcusB3n, ZedongWangAI, Juanxi, Lupin1998 | i) This paper introduces Scaling with Gradient Grouping (SGG), an optimizer wrapper for improving large language model (LLM) training. ii) The primary objective is to enhance adaptive learning rate estimation in LLMs to mitigate training instability and improve convergence. iii) SGG dynamically clusters gradient statistics within each layer and applies cluster-specific scaling to learning rates. iv) Experiments on C4 pre-training demonstrated that Adam combined with SGG surpassed recent optimizers across model sizes (60M to 1B), and low-rank pre-training with SGG yielded up to 30.4% lower validation perplexity over LoRA baselines. v) SGG offers AI practitioners a robust and easily integrated method for improving LLM training stability, convergence, and performance across various fine-tuning scenarios without architecture modification.  |
| Temporal In-Context Fine-Tuning for Versatile Control of Video Diffusion
  Models (Read more on [arXiv](https://arxiv.org/abs/2506.00996) or [HuggingFace](https://huggingface.co/papers/2506.00996))| Jaegul Choo, Junha Hyung, Kinam Kim | Temporal In-Context Fine-Tuning (TIC-FT) is introduced as a method for conditional video diffusion models. The main research objective is to adapt pre-trained video diffusion models to diverse conditional generation tasks efficiently. The key methodology involves temporally concatenating condition and target frames with intermediate buffer frames of increasing noise levels, fine-tuning the model using as few as 10-30 samples without architectural modifications. TIC-FT achieves strong performance, evidenced by its superior condition alignment and generation quality across various tasks, and requires less than one hour of training time for CogVideoX-5B on a single A100 GPU with 20 training samples over 6,000 steps. This approach implies AI practitioners can adapt large video diffusion models to new conditional tasks with minimal data and computational resources while maintaining condition fidelity.  |
| Jigsaw-R1: A Study of Rule-based Visual Reinforcement Learning with
  Jigsaw Puzzles (Read more on [arXiv](https://arxiv.org/abs/2505.23590) or [HuggingFace](https://huggingface.co/papers/2505.23590))| Feiyu Xiong, Zhiyu Li, Bo Tang, RyanZhu, wangzifu | i) This paper investigates rule-based visual reinforcement learning (RL) using jigsaw puzzles as a structured framework for multimodal large language models (MLLMs). ii) The main objective is to study how MLLMs perform on rule-based visual RL tasks and whether training on jigsaw puzzles can generalize to other visual tasks. iii) The methodology involves training MLLMs with rule-based RL on jigsaw puzzles of varying complexities and assessing their performance on both jigsaw puzzles and downstream vision tasks. iv) Results show that MLLMs can achieve near-perfect accuracy on jigsaw puzzles after fine-tuning, generalizing to unseen configurations, and RL exhibits better generalization than supervised fine-tuning (SFT). v) The research implies that rule-based visual RL with jigsaw puzzles can enhance MLLMs' visual reasoning capabilities, which are generalizable for downstream vision tasks, though an initial SFT phase may hinder subsequent RL optimization.  |
| SmolVLA: A Vision-Language-Action Model for Affordable and Efficient
  Robotics (Read more on [arXiv](https://arxiv.org/abs/2506.01844) or [HuggingFace](https://huggingface.co/papers/2506.01844))| imstevenpmwork, pepijn223, fracapuano, danaaubakirova, mshukor | SmolVLA presents a compact and efficient vision-language-action model for robotics. The research addresses the high computational cost of existing VLAs, aiming for affordable and efficient robotics. It employs a compact pretrained VLM with flow matching-trained action expert, asynchronous inference, and training on community-contributed datasets. SmolVLA achieves comparable performance to larger VLAs while reducing training and inference costs, with approximately 40% faster training time and 6x less memory consumption than a 3.3 billion parameter baseline. This research offers a resource-efficient VLA architecture for AI practitioners, enabling deployment on consumer-grade hardware.  |
| ARIA: Training Language Agents with Intention-Driven Reward Aggregation (Read more on [arXiv](https://arxiv.org/abs/2506.00539) or [HuggingFace](https://huggingface.co/papers/2506.00539))| Siyu Yuan, Yikai Zhang, Xintao, sheep33333, rhyang2021 | ARIA introduces a method for training language agents in open-ended environments by aggregating rewards in intention space. The research aims to address reward sparsity in reinforcement learning for language agents by projecting actions into a lower-dimensional intention space. Hierarchical clustering of sentence embeddings is used to create an intention space where semantically similar actions share rewards, reducing reward variance. Experiments show ARIA reduces policy gradient variance and improves performance by an average of 9.95% across four tasks compared to baseline methods. This method provides AI practitioners with a technique for improving RL-based language agent training by densifying reward signals through intention-aware aggregation, fostering better policy optimization.  |
| LoHoVLA: A Unified Vision-Language-Action Model for Long-Horizon
  Embodied Tasks (Read more on [arXiv](https://arxiv.org/abs/2506.00411) or [HuggingFace](https://huggingface.co/papers/2506.00411))| Zhijie Deng, Yihan Wang, Siqi Kou, Jiaxuan Sun, Yysrc | LoHoVLA introduces a unified vision-language-action model for long-horizon embodied tasks, integrating high-level planning and low-level control. The research aims to improve performance on complex, multi-step robotic tasks by addressing limitations in existing VLA models and hierarchical architectures. LoHoVLA leverages a large pretrained VLM backbone, generating both language and action tokens, and employs a hierarchical closed-loop control mechanism for error mitigation. Experiments on the LoHoSet dataset demonstrate that LoHoVLA achieves a significantly higher success rate, up to 97.8%/91.5% on seen tasks compared to baseline methods in the Ravens simulator. The findings suggest that unified architectures, as opposed to modular structures, show promise for advancing generalizable embodied intelligence, directly benefiting AI practitioners working on robotics. The paper is unclear regarding the specific implementation details of the closed-loop control mechanism and the architecture of the base VLM.  |
| Learning Video Generation for Robotic Manipulation with Collaborative
  Trajectory Control (Read more on [arXiv](https://arxiv.org/abs/2506.01943) or [HuggingFace](https://huggingface.co/papers/2506.01943))| Runsen Xu, Jianhong Bai, Xian Liu, Xintao Wang, Xiao Fu | i) The paper introduces RoboMaster, a novel video generation framework for robotic manipulation that uses collaborative trajectory control. ii) The research aims to improve the visual fidelity of generated robotic manipulation videos by addressing feature entanglement issues. iii) RoboMaster decomposes the interaction process into pre-interaction, interaction, and post-interaction phases, each guided by the dominant agent and uses a collaborative trajectory formulation and object embeddings for consistency. iv) Experiments on the Bridge V2 dataset demonstrate that RoboMaster outperforms existing methods, achieving a trajectory error of 16.47 for the robot and 24.16 for the object, alongside state-of-the-art visual quality metrics. v) RoboMaster's collaborative trajectory control provides AI practitioners with a new method for generating high-quality robotic manipulation data, enabling more realistic and controllable simulation environments.  |
| ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and
  Understanding (Read more on [arXiv](https://arxiv.org/abs/2506.01853) or [HuggingFace](https://huggingface.co/papers/2506.01853))| Jun Zhu, Shenghao Xie, Zhengyi Wang, Junliang Ye, zzzrw | ShapeLLM-Omni is introduced as a native 3D multimodal large language model for understanding and generating 3D assets and text. The research aims to extend multimodal LLMs with 3D capabilities using a next-token prediction paradigm. A 3D VQVAE is trained to encode 3D meshes into discrete tokens, and a large-scale dataset, 3D-Alpaca, is constructed for continuous training, incorporating generation, comprehension, and editing tasks. The Qwen-2.5-vl-7B-Instruct model is instruction-tuned on the 3D-Alpaca dataset, and the model achieves a CLIP score of 84.5 in image-to-3D tasks. The resulting model enables new avenues for AI practitioners to unify text, images, and 3D data processing within a single architecture, though more work is needed to reach the level of a true "3D version of ChatGPT-40".  |
| SRPO: Enhancing Multimodal LLM Reasoning via Reflection-Aware
  Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2506.01713) or [HuggingFace](https://huggingface.co/papers/2506.01713))| Dongfei Cui, Yu Zhang, Che Liu, Zhihao Dou, Zhongwei Wan | i) The paper introduces SRPO, a two-stage reflection-aware reinforcement learning framework for enhancing multimodal reasoning in large language models (MLLMs). ii) The research aims to improve MLLM reasoning accuracy and reflection quality, particularly in complex tasks requiring self-correction. iii) The methodology involves constructing a reflection-focused dataset using an advanced MLLM and incorporating a Group Relative Policy Optimization (GRPO) framework with a novel reward mechanism that encourages concise and cognitively meaningful reflection. iv) Experiments using Qwen-2.5-VL-7B and Qwen-2.5-VL-32B show SRPO significantly outperforms state-of-the-art models, achieving a 75.8% accuracy on MathVista using Qwen-2.5-VL-7B. v) SRPO provides AI practitioners with a method for enhancing MLLMs by integrating explicit self-reflection and self-correction mechanisms, improving their reasoning accuracy and reflection quality across diverse multimodal tasks.  |
| EarthMind: Towards Multi-Granular and Multi-Sensor Earth Observation
  with Large Multimodal Models (Read more on [arXiv](https://arxiv.org/abs/2506.01667) or [HuggingFace](https://huggingface.co/papers/2506.01667))| Luc Van Gool, Danda Pani Paudel, Zhitong Xiong, Bin Ren, Yan Shu | EarthMind introduces a novel vision-language framework for Earth Observation (EO) data by integrating multi-granular and multi-sensor information. The research aims to enhance LMM understanding of EO data through spatial attention and cross-modal fusion. EarthMind employs Spatial Attention Prompting (SAP) to enhance pixel-level grounding and a cross-modal fusion mechanism for integrating optical and SAR modalities. Experiments on the proposed EarthMind-Bench demonstrate state-of-the-art performance, surpassing GPT-40 despite being only 4B in scale, and it outperforms existing methods on other public EO benchmarks. EarthMind provides AI practitioners with a framework and benchmark for developing more effective LMMs capable of handling complex EO tasks involving multi-sensor data and varying levels of granularity.  |
| AReaL: A Large-Scale Asynchronous Reinforcement Learning System for
  Language Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.24298) or [HuggingFace](https://huggingface.co/papers/2505.24298))| Zhiyu Mei, Chen Zhu, Xujie Shen, Jiaxuan Gao, Wei Fu | AReAL is an asynchronous reinforcement learning system designed to enhance the capabilities of large language models for reasoning tasks. The research aims to improve training efficiency by decoupling LLM generation and training in RL. AREAL implements a fully asynchronous architecture with continuous rollout workers and parallel model updates along with staleness-enhanced PPO and system-level optimizations. Experiments on math and code reasoning benchmarks show AReaL achieves up to 2.57x training speedup compared to synchronous systems with comparable or improved final performance. AReaL's asynchronous RL system improves GPU utilization and training throughput, offering AI practitioners a more efficient approach to training large reasoning models.  |
| MiCRo: Mixture Modeling and Context-aware Routing for Personalized
  Preference Learning (Read more on [arXiv](https://arxiv.org/abs/2505.24846) or [HuggingFace](https://huggingface.co/papers/2505.24846))| Feng Luo, Yifan Sun, Jingyan Shen, Ray2333, FlippyDora | i) MiCRo introduces a two-stage framework for personalized preference learning using mixture modeling and context-aware routing with binary preference datasets. ii) The research aims to capture diverse human preferences without fine-grained annotations and adapt to individual users efficiently at deployment. iii) The methodology involves training a context-aware mixture of Bradley-Terry reward models followed by an online routing strategy adapting mixture weights based on contextual information. iv) Experiments show MiCRo achieves an average test accuracy of 0.7830 on HelpSteer2 and 0.8218 on RPR, outperforming baselines in adapting to user preferences within datasets. v) MiCRo offers AI practitioners a label-efficient solution for personalized preference learning, enabling efficient adaptation to specific user preferences with minimal additional supervision in Reinforcement Learning from Human Feedback (RLHF) applications.  |
| Incentivizing Reasoning for Advanced Instruction-Following of Large
  Language Models (Read more on [arXiv](https://arxiv.org/abs/2506.01413) or [HuggingFace](https://huggingface.co/papers/2506.01413))| Yuchen Shi, Zihan Xu, Zongyi Li, Gang Li, yolay | i) This paper introduces a systematic method, RAIF, to improve LLMs' ability to follow complex instructions. ii) The primary objective is to enhance the instruction-following capabilities of LLMs, particularly with complex, multi-constraint instructions. iii) The methodology involves decomposing complex instructions, reproducible data acquisition, reinforcement learning with rule-centric reward signals, and sample-wise contrastive learning for better CoT enforcement. iv) Evaluations on seven benchmarks demonstrate that a 1.5B LLM achieves 11.74% performance gains using RAIF, performing comparably to an 8B LLM. v) The RAIF method offers AI practitioners a scalable approach to improve instruction-following in LLMs, especially where complex and multifaceted instructions are involved. |
| Reasoning Like an Economist: Post-Training on Economic Problems Induces
  Strategic Generalization in LLMs (Read more on [arXiv](https://arxiv.org/abs/2506.00577) or [HuggingFace](https://huggingface.co/papers/2506.00577))| Yifang Chen, Xiangqi Jin, Xingyu Dong, Steven-Shaobo, MasterZhou | i) This paper investigates the efficacy of post-training Large Language Models (LLMs) on economic reasoning problems to improve strategic generalization in Multi-Agent Systems (MAS). ii) The main research question is whether Supervised Fine-Tuning (SFT) and Reinforcement Learning with Verifiable Rewards (RLVR) can effectively enhance LLMs' ability to generalize to multi-agent scenarios using economic reasoning as a testbed. iii) The methodology involves creating Recon, a 7B-parameter LLM post-trained on a hand-curated dataset of 2,100 economic reasoning problems, followed by evaluation on economic benchmarks and multi-agent games. iv) Primary results show a 14.7% absolute gain on economic reasoning benchmarks and improved Nash equilibrium convergence by 9.5 points in multi-agent games after post-training. v) The principal implication is that domain-aligned post-training is a scalable route for aligning LLMs with economic rationality, potentially fostering strategic behavior in MAS, demonstrating the benefit of structured post-training techniques for latent alignment in LLMs.  |
| Cora: Correspondence-aware image editing using few step diffusion (Read more on [arXiv](https://arxiv.org/abs/2505.23907) or [HuggingFace](https://huggingface.co/papers/2505.23907))| Andrea Tagliasacchi, Negar Hassanpour, Sauradip Nag, Aryan Mikaeili, Amirhossein-Alimohammadi | i) Cora introduces a novel image editing framework leveraging correspondence-aware techniques within few-step diffusion models. ii) The research aims to enhance structural and textural consistency in edited images, particularly for edits involving significant structural changes, while maintaining balance between content generation and preservation. iii) The methodology incorporates correspondence-aware noise correction utilizing DIFT features, interpolated attention maps via both linear and spherical interpolation, and structural alignment through Hungarian matching of source and target image queries. iv) Experiments show that Cora excels in maintaining structure, textures, and identity across diverse edits, achieving a user study ranking of 3.29, demonstrating superiority over alternatives. v) Cora provides AI practitioners with a method for high-fidelity image editing, enabling control over appearance and structure while generating new content, improving results on tasks that would normally produce texture inconsistencies and require significant training data.  |
| DyePack: Provably Flagging Test Set Contamination in LLMs Using
  Backdoors (Read more on [arXiv](https://arxiv.org/abs/2505.23001) or [HuggingFace](https://huggingface.co/papers/2505.23001))| Soheil Feizi, mmoayeri, wangwenxiao, yizecheng | i) DyePack is a framework for detecting test set contamination in Large Language Models (LLMs) by using backdoor attacks. ii) The paper aims to identify LLMs trained on benchmark test sets, thus inflating performance metrics, without access to model internals. iii) The method involves injecting backdoor samples with stochastic targets into the test data and verifying the activation of backdoors in evaluated models. iv) DyePack detected all contaminated models on MMLU-Pro with a false positive rate as low as 0.000073% using eight backdoors. v) This approach provides AI practitioners with a tool for validating the integrity of LLM benchmark evaluations, ensuring fair model comparisons, and preventing inaccurate performance assessments.  |
| VisualSphinx: Large-Scale Synthetic Vision Logic Puzzles for RL (Read more on [arXiv](https://arxiv.org/abs/2505.23977) or [HuggingFace](https://huggingface.co/papers/2505.23977))| Bhaskar Ramasubramanian, Yuetai Li, Fengqing Jiang, zhangchenxu, EthanSta | i) VISUALSPHINX presents a large-scale synthetic dataset of visual logic puzzles to enhance multimodal reasoning in vision language models (VLMs). ii) The paper aims to address the lack of large-scale, well-structured training datasets for logical inference over visual inputs in VLMs. iii) A rule-to-image synthesis pipeline is used, employing a rule-level genetic algorithm and program-based image generation to create diverse puzzles. iv) The QWEN2.5-VL-7B model fine-tuned on VISUALSPHINX demonstrates a 26.64% improvement in overall accuracy on visual logic puzzles and increased the average accuracy on the MathVista-testmini benchmark from 59.4% to 64.0%. v) AI practitioners can use VISUALSPHINX to train VLMs for improved performance on logical reasoning tasks, including algebraic, arithmetic, and geometric reasoning.  |
| From Token to Action: State Machine Reasoning to Mitigate Overthinking
  in Information Retrieval (Read more on [arXiv](https://arxiv.org/abs/2505.23059) or [HuggingFace](https://huggingface.co/papers/2505.23059))| Seung-won Hwang, yeonseokjeong, waylight3 | i) The paper introduces State Machine Reasoning (SMR), a transition-based reasoning framework to mitigate overthinking in information retrieval (IR). ii) The research aims to address redundant trajectories and misguided reasoning that hamper effective Chain-of-Thought (CoT) prompting in IR. iii) The methodology involves defining discrete actions (REFINE, RERANK, STOP) to structure the reasoning process as transitions between query and document states. iv) Experiments on BEIR and BRIGHT benchmarks demonstrate a 3.4% improvement in nDCG@10 and a 74.4% reduction in token usage using SMR compared to CoT prompting. v) The results suggest that AI practitioners can leverage SMR as a tuning-free and generalizable alternative to CoT reasoning to enhance retrieval performance while reducing computational overhead.  |
| WHEN TO ACT, WHEN TO WAIT: Modeling Structural Trajectories for Intent
  Triggerability in Task-Oriented Dialogue (Read more on [arXiv](https://arxiv.org/abs/2506.01881) or [HuggingFace](https://huggingface.co/papers/2506.01881))| Kyrie Zhixuan Zhou, Yuanli Wang, Jindan Huang, simonycl, FreaxRuby | i) This paper introduces STORM, a framework for modeling and analyzing intent triggerability in task-oriented dialogues by capturing user intent evolution. ii) The research aims to address the Intent-Action Alignment Problem by determining when user expressions have reached cognitive readiness for effective system action. iii) The methodology employs two LLMs (UserLLM and AgentLLM) to simulate conversations, tracks evolving user states within session-specific records, and uses a web-based visualization interface. iv) Experiments reveal that moderate profile uncertainty (40-60%) can outperform complete information access in certain scenarios, and access to user profiles increases satisfaction scores by 15-40%. v) AI practitioners should reconsider optimal information completeness in human-AI collaboration, and design uncertainty-calibrated dialogue systems to align immediate satisfaction with cognitive alignment.  |
| Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision
  Geometry Priors (Read more on [arXiv](https://arxiv.org/abs/2505.24625) or [HuggingFace](https://huggingface.co/papers/2505.24625))| Liwei Wang, Yanyang Li, Shijia Huang, zd11024 | This paper introduces Video-3D Geometry LLM (VG LLM) to enhance MLLMs' 3D scene understanding from video. The research aims to enable MLLMs to understand and reason about 3D spaces directly from video data without explicit 3D data input. The methodology involves employing a 3D visual geometry encoder to extract 3D prior information from video sequences and fuse it with visual tokens before feeding into the MLLM backbone (Qwen2.5-VL). Experiments show that the 4B VG LLM achieves an average score of 46.1% on VSI-Bench, surpassing Gemini-1.5-Pro, on tasks requiring complex spatial reasoning. VG LLM offers AI practitioners a method to enhance MLLMs’ spatial reasoning by implicitly modeling inter-frame correspondences, achieving competitive performance without relying on explicit 3D data.  |
| Stepsize anything: A unified learning rate schedule for
  budgeted-iteration training (Read more on [arXiv](https://arxiv.org/abs/2505.24452) or [HuggingFace](https://huggingface.co/papers/2505.24452))| Zhouchen Lin, zhou Xun, Yiming Dong, Anda Tang, Taoer | i) This paper proposes a Unified Budget-Aware (UBA) learning rate schedule for budgeted-iteration training. ii) The research aims to develop a theoretically grounded learning rate schedule that consistently outperforms commonly-used schedules under different constrained training budgets. iii) The methodology involves constructing a budget-aware optimization framework incorporating robustness to landscape curvature variations and deriving the UBA schedule controlled by a single hyper-parameter. iv) Experimental results show that UBA surpasses commonly-used schedules across diverse vision and language tasks, and UBA achieves state-of-the-art performance across approximately half of the benchmarks in language tasks while consistently outperforming baselines in average scores. v) The UBA schedule provides AI practitioners with a reliable, unified, and theoretically-grounded learning rate strategy for improved performance in resource-constrained training scenarios, eliminating the need for per-network numerical optimization.  |
| CodeV-R1: Reasoning-Enhanced Verilog Generation (Read more on [arXiv](https://arxiv.org/abs/2505.24183) or [HuggingFace](https://huggingface.co/papers/2505.24183))| Chongxiao Li, Xiaoyun Zhang, Hanqi Lyu, dihuang, zhuyaoyu | CodeV-R1 introduces a reinforcement learning framework for Verilog generation from natural language. The research addresses the challenges of automated verification, data scarcity, and high computational cost in applying RLVR to HDL generation. It employs a rule-based testbench generator for equivalence checking, a round-trip data synthesis method for creating high-quality NL-code pairs, and a two-stage "distill-then-RL" training pipeline with an adaptive DAPO RLVR algorithm. CodeV-R1-7B achieves 68.6% pass@1 on VerilogEval v2 and 72.9% pass@1 on RTLLM v1.1, surpassing prior state-of-the-art by 12~20%. The developed model, training pipeline, and dataset will be released to facilitate research in EDA and LLM communities.  |
| Normalized Attention Guidance: Universal Negative Guidance for Diffusion
  Model (Read more on [arXiv](https://arxiv.org/abs/2505.21179) or [HuggingFace](https://huggingface.co/papers/2505.21179))| Yi-Zhe Song, Kai Zou, Hmrishav, ChenDY | Normalized Attention Guidance (NAG) provides a training-free negative guidance approach for diffusion models. The research addresses the challenge of effective negative guidance in diffusion models, especially in few-step sampling regimes where Classifier-Free Guidance (CFG) fails. The key methodology involves applying extrapolation in attention space with L1-based normalization and feature refinement. Experiments demonstrate consistent improvements in text alignment, fidelity, and human-perceived quality, with results showing ImageReward increases across evaluated models and metrics. The primary implication is that NAG provides AI practitioners with a universal plug-in for modern diffusion frameworks enabling effortless negative guidance without retraining, addressing limitations of CFG.  |
| WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web
  Tasks (Read more on [arXiv](https://arxiv.org/abs/2506.01952) or [HuggingFace](https://huggingface.co/papers/2506.01952))| Tatsumi Sunada, Atsuki Sato, Kazuki Egashira, Zaiying Zhao, AtsuMiyai | i) WebChoreArena, a new benchmark, is introduced to evaluate web browsing agents on complex and tedious tasks. ii) The objective is to extend WebArena's scope to assess agents' capabilities in labor-intensive scenarios requiring massive memory, calculation, and long-term memory. iii) The methodology involves curating 532 tasks across four simulated websites used in WebArena and evaluating the performance of agents using LLMs such as GPT-40, Claude 3.7 Sonnet, and Gemini 2.5 Pro with BrowserGym and AgentOccam. iv) Results show that Gemini 2.5 Pro achieved 44.9% accuracy on WebChoreArena, indicating substantial room for improvement compared to WebArena. v) WebChoreArena serves as a more precise benchmark for evaluating and differentiating the performance of advanced LLMs, highlighting areas for improvement in memory utilization and complex task handling for AI web browsing agents.  |
| Pro3D-Editor : A Progressive-Views Perspective for Consistent and
  Precise 3D Editing (Read more on [arXiv](https://arxiv.org/abs/2506.00512) or [HuggingFace](https://huggingface.co/papers/2506.00512))| Zhendong Mao, Mengqi Huang, Yang Zheng, CNcreator0331 | i) The paper introduces Pro3D-Editor, a novel framework for consistent and precise text-guided 3D editing. ii) The research aims to achieve inter-view consistent 3D editing by addressing the limitations of view-indiscriminate approaches. iii) The methodology uses a progressive-views paradigm involving Primary-view Sampler, Key-view Render with Mixture-of-View-Experts Low-Rank Adaptation (MoVE-LoRA), and Full-view Refiner modules. iv) Experiments demonstrate Pro3D-Editor achieves a 47.4% improvement in LPIPS and a 9.7% improvement in DINO-I compared to existing methods. v) AI practitioners can leverage Pro3D-Editor's progressive-views paradigm to improve spatial consistency and accuracy in text-guided 3D editing tasks.  |
| OWSM v4: Improving Open Whisper-Style Speech Models via Data Scaling and
  Cleaning (Read more on [arXiv](https://arxiv.org/abs/2506.00338) or [HuggingFace](https://huggingface.co/papers/2506.00338))| Jinchuan Tian, William Chen, Yui Sudo, Shakeel Muhammad, pyf98 | i) This paper introduces OWSM v4, an improved series of open Whisper-style speech models achieved through data scaling and cleaning of the YODAS dataset. ii) The primary objective is to enhance the performance of open-source speech foundation models by integrating and curating a large-scale web-crawled dataset. iii) The methodology involves a scalable data-cleaning pipeline using public LID and ASR models to address language label errors and audio-text misalignments in the YODAS dataset. iv) The new OWSM v4 models significantly outperform previous versions on multilingual benchmarks, achieving a 9.4% average WER on MLS with the medium-sized model and outperforming Whisper-medium. v) The principal implication for AI practitioners is the availability of cleaned YODAS data and improved OWSM models, which can be used to develop and deploy high-quality, fully open-source multilingual speech recognition systems, with data cleaning scripts, pre-trained models, and training logs made publicly available.  |
| Stress-testing Machine Generated Text Detection: Shifting Language
  Models Writing Style to Fool Detectors (Read more on [arXiv](https://arxiv.org/abs/2505.24523) or [HuggingFace](https://huggingface.co/papers/2505.24523))| Giovanni Puccetti, Alessio Miaschi, Cristiano Ciaccio, Michele Papucci, andreapdr | i) This paper presents a pipeline to generate more challenging machine-generated text (MGT) to evaluate the robustness of MGT detectors. ii) The main research question is how to make MGT more difficult to detect by aligning the writing style of LLMs with human-written text (HWT). iii) The methodology involves fine-tuning LLMs using Direct Preference Optimization (DPO) with parallel datasets of HWT and MGT, targeting specific linguistic features. iv) Results show that detectors' performance drops significantly after one DPO iteration; for example, MAGE's accuracy drops from 76% to 47% on the XSUM dataset when evaluated on Llama dpo-1-ling generated texts. v) The principal implication for AI practitioners is the need to improve MGT detection methods by focusing on robustness to adversarial attacks exploiting stylistic cues, as current detectors rely on shallow linguistic features.  |
| VAU-R1: Advancing Video Anomaly Understanding via Reinforcement
  Fine-Tuning (Read more on [arXiv](https://arxiv.org/abs/2505.23504) or [HuggingFace](https://huggingface.co/papers/2505.23504))| Xiaodong Cun, Xi Shen, Qixiang Chen, Liyun Zhu | i) The paper introduces VAU-R1, a reinforcement fine-tuning framework for video anomaly understanding, and VAU-Bench, a new benchmark. ii) The objective is to enhance anomaly reasoning in multimodal large language models (MLLMs) and to provide a comprehensive benchmark for evaluating this capability. iii) The methodology involves reinforcement fine-tuning (RFT) using Group Relative Policy Optimization (GRPO) and a novel VAU-Bench dataset with chain-of-thought annotations. iv) Empirical results show that VAU-R1 improves question answering accuracy and temporal grounding, with Qwen2.5-VL-3B+RFT achieving an accuracy of 87.08% on multiple choice QA in the MSAD dataset. v) This work offers AI practitioners a data-efficient reinforcement learning approach and a new evaluation benchmark to improve the reasoning and temporal localization capabilities of MLLMs in video anomaly understanding tasks.  |
| LLM in the Loop: Creating the PARADEHATE Dataset for Hate Speech
  Detoxification (Read more on [arXiv](https://arxiv.org/abs/2506.01484) or [HuggingFace](https://huggingface.co/papers/2506.01484))| Helmut Schmid, Ashish Yashwanth Kangen, Lukas Kouba, Ercong Nie, shuzyuan | i) This paper introduces PARADEHATE, a new parallel dataset for hate speech detoxification created using an LLM-in-the-loop pipeline. ii) The research aims to address the scarcity of high-quality parallel datasets for hate speech detoxification by automating data creation. iii) The methodology involves replacing human annotators in the ParaDetox pipeline with a GPT-40-mini model for rephrasing, content preservation checks, and toxicity evaluation. iv) Results show that models fine-tuned on PARADEHATE, such as BART, achieve improved style accuracy (0.95), fluency (0.78), and BLEU score (0.31) compared to baseline methods. v) LLM-generated detoxification text provides a scalable alternative to human annotation, potentially improving the effectiveness of hate speech detoxification models. |
| zip2zip: Inference-Time Adaptive Vocabularies for Language Models via
  Token Compression (Read more on [arXiv](https://arxiv.org/abs/2506.01084) or [HuggingFace](https://huggingface.co/papers/2506.01084))| Chris Wendler, Maxime Peyrard, Yunzhen yao, Saibo Geng, nathanrchn | zip2zip introduces a framework for dynamically adapting language model vocabularies at inference time through token compression. The research investigates how to reduce token sequence length to improve LLM efficiency by enabling inference-time vocabulary adaptation. The method uses LZW compression to create reusable hypertokens, incorporates an embedding layer for new hypertokens, and trains a compression-aware language model. The study demonstrates a 20-60% reduction in input and output sequence lengths with fine-tuning, translating to latency improvements, though it notes a potential degradation in language modeling performance, especially on tasks requiring numerical computation where malformed numbers are generated due to the dynamic tokenization. This dynamic tokenization framework provides AI practitioners with a method for enhancing LLM inference speed by reducing sequence length, although there is a trade-off with potentially reduced accuracy in numerical tasks.  |
| SATA-BENCH: Select All That Apply Benchmark for Multiple Choice
  Questions (Read more on [arXiv](https://arxiv.org/abs/2506.00643) or [HuggingFace](https://huggingface.co/papers/2506.00643))| Stephanie Eckman, Chi Xue, Xi Fang, Shixian Cui, xwjzds | i) SATA-BENCH is introduced as a benchmark for evaluating large language models (LLMs) on Select All That Apply (SATA) questions. ii) The research aims to assess LLMs' ability to identify multiple correct answers in diverse domains. iii) The methodology involves curating a dataset of 1,604 human-validated SATA questions and evaluating 27 LLMs, along with proposing a Choice Funnel decoding strategy. iv) Results indicate that even the strongest model achieves only 41.8% exact match, highlighting a gap in reliably identifying all correct answers, and Choice Funnel achieves up to 29% higher exact match compared to baselines. v) The benchmark and Choice Funnel framework provide AI practitioners with tools to diagnose and improve multi-answer reasoning in LLMs for realistic applications requiring robust decision-making.  |
| Cascading Adversarial Bias from Injection to Distillation in Language
  Models (Read more on [arXiv](https://arxiv.org/abs/2505.24842) or [HuggingFace](https://huggingface.co/papers/2505.24842))| Milad Nasr, Ilia Shumailov, Matthew Jagielski, Jamie Hayes, Harsh Chaudhari | i) This paper demonstrates that adversarial biases can be injected into teacher language models via data poisoning and subsequently amplified in distilled student models. ii) The research investigates the vulnerability of distilled language models to adversarial bias injection during training. iii) The methodology involves injecting poisoned samples into the teacher model's instruction tuning data and then distilling the model. iv) Results show that with only 25 poisoned samples (0.25% poisoning rate), the student model generated biased responses 76.9% of the time in a targeted propagation scenario. v) This work implies a need for specialized safeguards to mitigate the propagation of adversarial biases in distilled language models. |
| ComposeAnything: Composite Object Priors for Text-to-Image Generation (Read more on [arXiv](https://arxiv.org/abs/2505.24086) or [HuggingFace](https://huggingface.co/papers/2505.24086))| Cordelia Schmid, Shizhe Chen, zk95 | i) The paper introduces ComposeAnything, a training-free framework for improved compositional text-to-image generation leveraging composite object priors. ii) The primary objective is to enhance text-to-image models for complex compositions involving novel arrangements and high object counts. iii) The methodology employs Large Language Models (LLMs) for 2.5D semantic layout generation and a prior-guided diffusion process that combines object prior reinforcement and spatial-controlled denoising. iv) ComposeAnything outperforms state-of-the-art methods on T2I-CompBench, achieving a 16.9% absolute gain on 2D-Spatial compared to the SD3-M base model, and NSR-1K benchmarks for prompts with 2D/3D spatial arrangements, high object counts, and surreal compositions. v) This framework provides AI practitioners with an interpretable and robust method for compositional image generation that can be readily integrated with existing diffusion-based text-to-image models without retraining.  |
| MagiCodec: Simple Masked Gaussian-Injected Codec for High-Fidelity
  Reconstruction and Generation (Read more on [arXiv](https://arxiv.org/abs/2506.00385) or [HuggingFace](https://huggingface.co/papers/2506.00385))| Ziyang Ma, Chenpeng Du, Jiawei Chen, Yakun Song, xiaobinzhuang | MagiCodec is a novel single-layer Transformer-based audio codec designed for high-fidelity reconstruction and improved downstream modelability. The research addresses the optimization trade-off between reconstruction quality and generative capacity in neural audio codecs. MagiCodec employs Gaussian noise injection and latent regularization within a multistage training pipeline to enhance semantic expressiveness while maintaining fidelity. Experimental results show MagiCodec achieves state-of-the-art reconstruction quality with a Word Error Rate (WER) of 3.16% at 850 bps and superior performance in downstream tasks, such as text-to-speech. The Zipf-like code distribution and demonstrated modelability suggest MagiCodec offers AI practitioners a potentially superior discrete audio representation for language-model-based audio generative architectures.  |
| OmniResponse: Online Multimodal Conversational Response Generation in
  Dyadic Interactions (Read more on [arXiv](https://arxiv.org/abs/2505.21724) or [HuggingFace](https://huggingface.co/papers/2505.21724))| Bernard Ghanem, Siyang Song, Bing Li, Jianghui Wang, Cheng Luo | OmniResponse introduces a model for online multimodal conversational response generation (OMCRG) in dyadic interactions. The research aims to generate synchronized verbal and non-verbal listener feedback conditioned on a speaker's multimodal input. The methodology involves a Multimodal Large Language Model (MLLM) with a Chrono-Text module for temporal anchoring of text tokens and a TempoVoice module for controllable online TTS synchronized with facial reactions. Experiments on the new ResponseNet dataset demonstrate that OmniResponse significantly outperforms baselines, achieving improvements in semantic speech content, audio-visual synchronization, and generation quality. The work provides AI practitioners with a framework for developing more realistic and synchronized conversational AI agents.  |
| Think Again! The Effect of Test-Time Compute on Preferences, Opinions,
  and Beliefs of Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.19621) or [HuggingFace](https://huggingface.co/papers/2505.19621))| Michal Shmueli-Scheuer, Ateret Anaby-Tavor, Itay Nakash, George Kour | i) This paper benchmarks and analyzes the subjective inclinations of Large Language Models (LLMs) across various domains using a newly developed survey. ii) The research aims to evaluate if LLMs exhibit subjective preferences, opinions, and beliefs, and to what extent increased test-time compute influences these tendencies. iii) The study employs a benchmark called the Preference, Opinion, and Belief survey (POBs) to assess LLMs' subjective inclinations, along with metrics for reliability, neutrality, and consistency, testing direct prompting, reasoning, and self-reflection. iv) Results indicate that increasing test-time compute does not significantly improve neutrality or consistency, and newer model versions exhibit decreased consistency and increased bias, with models showing a negative correlation between non-neutrality and topical consistency (r ~ 0.9). v) AI practitioners need to carefully evaluate and audit LLMs for unintended biases and inconsistencies before deployment, as increasing test-time compute alone does not guarantee mitigation and newer versions may exhibit greater bias.  |
| LIFT the Veil for the Truth: Principal Weights Emerge after Rank
  Reduction for Reasoning-Focused Supervised Fine-Tuning (Read more on [arXiv](https://arxiv.org/abs/2506.00772) or [HuggingFace](https://huggingface.co/papers/2506.00772))| Tianjin Huang, Chaoqun Yang, Oleg Balabanov, Tianyu Pang, Zihang Liu | i) The paper introduces Low-rank Informed Sparse Fine-Tuning (LIFT), a method for efficient LLM fine-tuning that leverages low-rank approximation to identify and update principal weights. ii) The research investigates whether sparse fine-tuning can achieve comparable or superior reasoning performance to full fine-tuning by identifying critical parameters via rank reduction. iii) The methodology involves performing SVD on weight matrices, approximating with low rank, and selectively fine-tuning the parameters with the highest magnitude in the reduced-rank representation. iv) LIFT achieves up to 4.42% better performance than LoRA on commonsense reasoning tasks, and up to 2.02% higher overall performance than full FT on GPQA Diamond. v) LIFT enables AI practitioners to achieve improved reasoning performance in LLMs with memory efficiency comparable to LoRA, offering a practical alternative to full fine-tuning.  |
| Pitfalls in Evaluating Language Model Forecasters (Read more on [arXiv](https://arxiv.org/abs/2506.00723) or [HuggingFace](https://huggingface.co/papers/2506.00723))| Florian Tramèr, Jonas Geiping, Shashwat Goel, Daniel Paleka | i) Language model (LLM) forecaster evaluations face challenges related to temporal leakage and real-world performance extrapolation. ii) The research identifies and analyzes pitfalls in evaluating LLMs for forecasting future events. iii) The methodology involves a systematic analysis of evaluation flaws and concrete examples from prior work to demonstrate issues like logical leakage, unreliable date-restricted retrieval, piggybacking on human forecasts, and gaming benchmarks. iv) The study found at least 3.8% of a forecasting dataset included questions for events that resolved early, making forecasting unnecessary. v) AI practitioners need to employ more rigorous evaluation methodologies to assess the forecasting abilities of LLMs due to the potential for inflated performance claims.  |
| CityLens: Benchmarking Large Language-Vision Models for Urban
  Socioeconomic Sensing (Read more on [arXiv](https://arxiv.org/abs/2506.00530) or [HuggingFace](https://huggingface.co/papers/2506.00530))| Tianjian Ouyang, Xin Zhang, Hetian Pang, Jie Feng, Tianhui Liu | CityLens is introduced as a benchmark for evaluating large language-vision models (LLVMs) in predicting urban socioeconomic indicators. The research aims to assess LLVM capabilities in tasks such as economy, education, crime, transport, health, and environment using satellite and street view imagery across 17 globally distributed cities. The methodology employs three evaluation paradigms: Direct Metric Prediction, Normalized Metric Estimation, and Feature-Based Regression, benchmarking 17 state-of-the-art LLVMs. Results show that while LLVMs demonstrate perceptual and reasoning capabilities, they still exhibit limitations in predicting urban socioeconomic indicators. The analysis indicates that building height achieves an R2 of 0.59 in Feature-Based Regression while many tasks have R2 close to zero, suggesting difficulty in linking visual context with structured socioeconomic quantities. CityLens provides AI practitioners with a unified framework for diagnosing limitations in LLVMs regarding urban socioeconomic understanding and prediction, highlighting areas for improvement in model architecture and training data for urban sensing applications.  |
| Massively Multilingual Adaptation of Large Language Models Using
  Bilingual Translation Data (Read more on [arXiv](https://arxiv.org/abs/2506.00469) or [HuggingFace](https://huggingface.co/papers/2506.00469))| Hengyu Luo, Indraneil Paul, Jaakko Paavola, Zihao Li, jisx | i) This paper investigates the impact of bilingual translation data on massively multilingual adaptation of large language models. ii) The research question is to determine if including bilingual translation data enhances massively multilingual continual pre-training. iii) The methodology involves constructing a bilingual translation corpus (MaLA) with over 2,500 language pairs and 500 languages, followed by continual pre-training of Llama 3 & 3.1 (8B) models. iv) The primary result is that bilingual data generally enhances multilingual performance compared to monolingual data, with a remarkable increase of machine translation performance from 9% to 140% increase in BLEU scores on the Flores200 dataset for English translation directions. v) The principal implication for AI practitioners is the demonstration that continual pre-training with bilingual data can improve multilingual performance, especially for machine translation tasks and low-resource languages.  |
| From Guidelines to Practice: A New Paradigm for Arabic Language Model
  Evaluation (Read more on [arXiv](https://arxiv.org/abs/2506.01920) or [HuggingFace](https://huggingface.co/papers/2506.01920))| Abdulrahman Al-Batati, Yasser Al-Habashi, Adel Ammar, Omer Nacar, Serry Sibaee | i) This paper introduces a novel evaluation framework for Arabic Language Models (LLMs) to address limitations in existing datasets regarding linguistic accuracy and cultural alignment. ii) The primary objective is to establish theoretical guidelines and introduce the Arabic Depth Mini Dataset (ADMD) for comprehensive Arabic LLM evaluation. iii) The methodology involves analyzing existing Arabic evaluation datasets, developing theoretical guidelines, curating the ADMD dataset, and evaluating five leading language models using the ADMD. iv) Results indicate variations in model performance across domains, with Claude 3.5 Sonnet achieving the highest overall accuracy of 30% and notable strength in mathematical theory in Arabic, Arabic language, and Islamic domains. v) The principal implication is a need for improved Arabic LLM evaluation methodologies that emphasize cultural competence alongside technical capabilities, impacting AI practitioners developing or deploying Arabic LLMs.  |
| Synthesis of discrete-continuous quantum circuits with multimodal
  diffusion models (Read more on [arXiv](https://arxiv.org/abs/2506.01666) or [HuggingFace](https://huggingface.co/papers/2506.01666))| Gorka Muñoz-Gil, Hans J. Briegel, Ikko Hamamura, Zohim Chandani, Floki00 | i) This paper introduces a multimodal denoising diffusion model (DM) for quantum circuit synthesis, addressing both discrete gate selection and continuous parameter prediction. ii) The primary objective is to efficiently compile quantum operations by simultaneously generating a circuit's structure and its continuous parameters. iii) The methodology involves leveraging two independent diffusion processes within a multimodal framework: one handling discrete gate selection and the other predicting continuous gate parameters. iv) The model was benchmarked on unitary compilation, achieving successful compilation with low infidelity for up to 5-qubit circuits with up to 16 gates, and revealing dependence on the number of gates and the percentage of parameterized gates. v) This research provides AI practitioners with a method for rapid quantum circuit generation, enabling the creation of large datasets for heuristic extraction and potentially offering new insights for quantum circuit synthesis.  |
| MIKU-PAL: An Automated and Standardized Multi-Modal Method for Speech
  Paralinguistic and Affect Labeling (Read more on [arXiv](https://arxiv.org/abs/2505.15772) or [HuggingFace](https://huggingface.co/papers/2505.15772))| Jiatong Shi, Ruoyi Zhang, Yifan Cheng | MIKU-PAL introduces an automated multimodal framework for labeling emotional speech. The research aims to automate high-consistency emotion annotation from unlabeled video data, addressing limitations of current emotional speech datasets. The methodology employs face detection and tracking with a multimodal large language model (MLLM) to analyze audio, visual, and text modalities. MIKU-PAL achieved a Fleiss к score of 0.93 for consistency and can annotate up to 26 emotion categories with 83% human-validated rationality. Releasing MIKU-EmoBench, a 131.2-hour dataset of fine-grained emotional speech, provides AI practitioners with a new benchmark for emotional text-to-speech and visual voice cloning.  |
