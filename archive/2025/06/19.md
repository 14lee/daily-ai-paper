

## Papers for 2025-06-19

| Title | Authors | Summary |
|-------|---------|---------|
| Sekai: A Video Dataset towards World Exploration (Read more on [arXiv](https://arxiv.org/abs/2506.15675) or [HuggingFace](https://huggingface.co/papers/2506.15675))| Shaoheng Lin, Xiaofeng Mao, Chuanhao Li, Zhen Li, kpzhang | i) The paper introduces SEKAI, a large-scale, annotated, first-person view video dataset designed for world exploration using video generation techniques. ii) The main objective is to provide a dataset that overcomes the limitations of existing datasets for training interactive world exploration models. iii) The methodology involves collecting videos from YouTube and a video game, followed by preprocessing, location, scene, weather, crowd density, camera trajectory, and caption annotation using vision-language models and SfM. iv) SEKAI-Real comprises over 5,000 hours of walking or drone view videos from over 100 countries and Sekai-Real-HQ demonstrates a more balanced location distribution and the average number of caption tokens exceeds 200, and a subset is used to train an interactive video world exploration model. v) SEKAI offers AI practitioners a significantly expanded and richly annotated resource to improve the training and development of world exploration and video generation models with better diversity and long-duration videos.  |
| ProtoReasoning: Prototypes as the Foundation for Generalizable Reasoning
  in LLMs (Read more on [arXiv](https://arxiv.org/abs/2506.15211) or [HuggingFace](https://huggingface.co/papers/2506.15211))| Yunqi Qiu, Tingting Ma, Xinnian Liang, Zijun Chen, Feng He | i) This paper introduces ProtoReasoning, a framework using abstract prototypes to enhance the generalizable reasoning abilities of Large Language Models (LLMs). ii) The research investigates whether training LLMs with abstract reasoning prototypes improves cross-domain generalization capabilities. iii) The methodology involves supervised fine-tuning (SFT) on LLMs using datasets of logical reasoning problems represented in Prolog and planning problems in PDDL, coupled with automated verification. iv) Experiments show ProtoReasoning achieves a 4.7% improvement on the Enigmata-Eval logical reasoning benchmark, as well as a 6.3% boost on planning tasks. v) The principal implication for AI practitioners is that leveraging abstract prototypes can improve LLM generalization on structurally similar problems, suggesting a novel method for enhancing reasoning capabilities. |
| GenRecal: Generation after Recalibration from Large to Small
  Vision-Language Models (Read more on [arXiv](https://arxiv.org/abs/2506.15681) or [HuggingFace](https://huggingface.co/papers/2506.15681))| Yueh-Hua Wu, Yu-Chiang Frank Wang, Yong Man Ro, rhachiuma, BK-Lee | i) This paper introduces GenRecal, a general-purpose VLM distillation framework. ii) The research addresses the challenge of knowledge transfer between heterogeneous VLMs differing in architectures and token types. iii) GenRecal employs a Recalibrator to align feature representations between teacher and student VLMs. iv) Experiments show GenRecal significantly improves baseline performance, with InternVL2.5-8B-GenRecal achieving up to 93.6% accuracy on MMB, outperforming large-scale open- and closed-source VLMs. v) GenRecal enables AI practitioners to efficiently distill knowledge across diverse VLMs for resource-constrained deployment, facilitating the creation of smaller, more efficient models.  |
| BUT System for the MLC-SLM Challenge (Read more on [arXiv](https://arxiv.org/abs/2506.13414) or [HuggingFace](https://huggingface.co/papers/2506.13414))| Jan Černocký, Samuele Cornell, Dominik Klement, Jiangyu Han, Alexander Polok | i) The paper introduces a two-speaker ASR system combining DiCoW and DiariZen for the MLC-SLM challenge. ii) The primary objective is to develop a multilingual multi-talker ASR system robust to out-of-domain scenarios and annotation inconsistencies. iii) The methodology involves fine-tuning DiCoW, a diarization-conditioned Whisper variant, and DiariZen, a WavLM-based diarization pipeline, on the MLC-SLM challenge dataset. iv) The resulting system achieves a micro-average tcpWER/CER of 16.75% on the MLC-SLM challenge and DiariZen outperforms Pyannote with a DER of 12.7% after fine-tuning. v) AI practitioners can leverage the released DiCoW and DiariZen models to enhance multilingual ASR systems, while being mindful of potential annotation inconsistencies when fine-tuning diarization components.  |
| Embodied Web Agents: Bridging Physical-Digital Realms for Integrated
  Agent Intelligence (Read more on [arXiv](https://arxiv.org/abs/2506.15677) or [HuggingFace](https://huggingface.co/papers/2506.15677))| Maxine Wu, Xingcheng Yao, Bingxuan Li, Rui Sun, Yining Hong | Embodied Web Agents introduces a paradigm for AI agents that integrate physical embodiment with web-scale knowledge access. The research investigates how AI agents can perform tasks requiring both physical interaction and web-based reasoning, such as cooking using online recipes or navigating using dynamic map data. The proposed methodology involves creating a unified simulation platform integrating 3D environments with web interfaces, and constructing the Embodied Web Agents Benchmark comprising diverse tasks like cooking, navigation, shopping, tourism, and geolocation. Experimental results using LLM agents (GPT, Gemini, Qwen, and Intern) show a significant performance gap compared to human capabilities, with a 34.72% overall accuracy for GPT in navigation tasks. The primary implication for AI practitioners is the need to address challenges in cross-domain integration to improve AI systems' ability to seamlessly connect physical and digital realms. Some aspects of the experimental setup and results lacked specifics, such as quantified human baselines and detailed task decompositions.  |
| Semantically-Aware Rewards for Open-Ended R1 Training in Free-Form
  Generation (Read more on [arXiv](https://arxiv.org/abs/2506.15068) or [HuggingFace](https://huggingface.co/papers/2506.15068))| Zichao Liang, Xiyang Wu, Yuhang Zhou, Yapei Chang, Zongxia Li | i) The paper introduces PrefBERT, a lightweight BERT-based scoring model for evaluating and training open-ended long-form generation models using Group Relative Policy Optimization (GRPO). ii) The research aims to address the challenge of evaluating open-ended text generation in GRPO by providing better semantic reward feedback compared to traditional metrics. iii) PrefBERT is trained on response evaluation datasets with human ratings, enabling it to offer more semantically-aware rewards for GRPO training. iv) Evaluations show PrefBERT leads to improved alignment with human preferences in generated text, with models exhibiting higher Likert scores and success rates compared to models trained with ROUGE-L and BERTScore. v) The primary implication is that AI practitioners can use PrefBERT as a more effective and efficient reward signal in GRPO to train language models for open-ended generation, leading to outputs better aligned with human preferences; some evaluations are unclear regarding full details of dataset curation.  |
| SciVer: Evaluating Foundation Models for Multimodal Scientific Claim
  Verification (Read more on [arXiv](https://arxiv.org/abs/2506.15569) or [HuggingFace](https://huggingface.co/papers/2506.15569))| Arman Cohan, Zexi Kuang, Yifei Shen, Chengye Wang, yilunzhao | i) SCIVER is introduced as a new benchmark for evaluating foundation models in multimodal scientific claim verification. ii) The main objective is to assess the ability of foundation models to verify claims within a multimodal scientific context, using a benchmark with expert-annotated supporting evidence. iii) The methodology involves constructing a dataset of 3,000 examples over 1,113 scientific papers, spanning four reasoning types, and evaluating 21 multimodal foundation models. iv) Experimental results show that GPT-4.1 achieves 70.8% accuracy on analytical reasoning tasks, significantly lower than human expert performance (90.0%). v) The substantial performance gap between foundation models and human experts on SCIVER indicates a need for improvements in models' comprehension and reasoning abilities for multimodal scientific literature tasks, particularly for complex reasoning types.  |
| Truncated Proximal Policy Optimization (Read more on [arXiv](https://arxiv.org/abs/2506.15050) or [HuggingFace](https://huggingface.co/papers/2506.15050))| Chengyi Wang, Jiaze Chen, Yu Yue, Lingjun Liu, Tiantian Fan | This paper introduces Truncated Proximal Policy Optimization (T-PPO), an extension to PPO designed to improve training efficiency. The research aims to enhance the training efficiency of reasoning Large Language Models (LLMs) while maintaining performance. The methodology involves Extended Generalized Advantage Estimation (EGAE) for incomplete responses and a selective token filtering mechanism. Results show that T-PPO achieves a 2.5x improvement in training efficiency and reaches 62 pass@1 on the AIME 2024 benchmark using a 32B base model. AI practitioners can leverage T-PPO to accelerate the training of reasoning LLMs without sacrificing performance.  |
| CoMemo: LVLMs Need Image Context with Image Memory (Read more on [arXiv](https://arxiv.org/abs/2506.06279) or [HuggingFace](https://huggingface.co/papers/2506.06279))| Jifeng Dai, Wenhai Wang, Xizhou Zhu, jackroos, CLLBJ16 | i) CoMemo is a novel large vision-language model (LVLM) architecture designed to improve multimodal processing. ii) The research investigates how to mitigate suboptimal characteristics in LVLMs related to attention allocation and positional encoding for high-resolution images. iii) The study introduces a dual-path architecture combining a Context image path with an image Memory path, and a novel positional encoding mechanism called ROPE-DHR (ROPE-Dynamic High-Resolution). iv) CoMemo achieves superior performance compared to conventional LVLM architectures across seven benchmarks, including a 17.2% relative improvement on Caption tasks. v) AI practitioners can utilize the CoMemo architecture and ROPE-DHR to enhance visual information processing in LVLMs, especially for tasks requiring long-context comprehension and high-resolution image understanding.  |
| SwarmAgentic: Towards Fully Automated Agentic System Generation via
  Swarm Intelligence (Read more on [arXiv](https://arxiv.org/abs/2506.15672) or [HuggingFace](https://huggingface.co/papers/2506.15672))| Shijie Zhou, Haokun Chen, Shijie Tang, Chenyang Lin, Yao Zhang | SwarmAgentic is a novel framework for fully automated agentic system generation using swarm intelligence. The research aims to construct agentic systems from scratch and jointly optimize agent functionality and collaboration through language-driven exploration, without human intervention. It leverages a language-driven Particle Swarm Optimization (PSO) process, reformulating the approach into symbolic transformations for non-differentiable design spaces. The proposed Failure-Aware Velocity Update incorporates LLM-guided flaw identification, enabling targeted self-optimization across iterations. Empirical results show SwarmAgentic achieves a +261.8% relative improvement over ADAS on the TravelPlanner benchmark. This framework provides a fully automated methodology, enhancing scalability and adaptability in agentic system design, offering AI practitioners a method for structurally unconstrained task automation.  |
| MoTE: Mixture of Ternary Experts for Memory-efficient Large Multimodal
  Models (Read more on [arXiv](https://arxiv.org/abs/2506.14435) or [HuggingFace](https://huggingface.co/papers/2506.14435))| Yitao Zhai, Yan Feng, Ruiping Wang, Jiayu Xu, Hongyu Wang | MoTE introduces a memory-efficient Mixture-of-Experts (MoE) architecture for large multimodal models. The paper aims to reduce the memory footprint of MoE models by training ternary routed experts from a dense checkpoint, replacing the full-precision experts. The proposed method freezes the pre-trained feed-forward network (FFN) as a shared expert and trains ternary routed experts during up-cycling using quantization-aware training. Experiments show that MoTE achieves comparable performance to a full-precision MoE-LLaVA baseline with a smaller memory footprint, outperforming it by 4.3% average accuracy on end tasks with a 3.4GB expert memory budget after post-training quantization. This method provides AI practitioners with a more scalable and deployable MoE architecture suitable for memory-constrained devices.  |
| OS-Harm: A Benchmark for Measuring Safety of Computer Use Agents (Read more on [arXiv](https://arxiv.org/abs/2506.14866) or [HuggingFace](https://huggingface.co/papers/2506.14866))| Zico Kolter, Francesco Croce, Hao Zhao, Agatha Duzan, Thomas Kuntz | OS-HARM is a benchmark designed to measure the safety of computer use agents interacting with graphical user interfaces. The research addresses the overlooked safety aspects of computer use agents by creating a benchmark to evaluate their harmful behavior potential. The study introduces 150 tasks covering deliberate misuse, prompt injection attacks, and model misbehavior within the OSWorld environment, coupled with an automated judge for evaluating accuracy and safety. Experiments showed that computer use agents exhibit vulnerability to misuse and prompt injections, with 04-mini complying with prompt injections in 20% of cases, and the automated judge achieves F1 scores of 0.76 and 0.79 for accuracy and safety, respectively. The principal implication for AI practitioners is the need for improved safety mechanisms and evaluation protocols in computer use agents to mitigate potential risks associated with their deployment and interaction with computer systems.  |
| ImmerseGen: Agent-Guided Immersive World Generation with Alpha-Textured
  Proxies (Read more on [arXiv](https://arxiv.org/abs/2506.14315) or [HuggingFace](https://huggingface.co/papers/2506.14315))| Lin Ma, Panwang Pan, Keke Wang, Bangbang Yang, yjyyy | i) ImmerseGen is a framework for generating photorealistic 3D environments using alpha-textured proxies, guided by agents, for immersive VR experiences. ii) The main objective is to create compact and photorealistic 3D worlds from text prompts suitable for real-time rendering on VR headsets, overcoming limitations of high-poly mesh modeling and massive 3D Gaussians. iii) The method involves hierarchical scene composition with lightweight geometric proxies (simplified terrain and billboard meshes), terrain-conditioned texturing for the base world, RGBA asset texturing for scenery, and VLM-based modeling agents for scene creation. iv) Experiments demonstrate that ImmerseGen achieves up to 79+ FPS rendering performance on VR devices using the Snapdragon XR2 Gen 2 platform, outperforming previous methods in visual quality and spatial coherence. v) ImmerseGen provides AI practitioners with a method to generate complex 3D environments with efficient memory usage suitable for real-time VR applications via the use of alpha-textured proxies and agent-guided asset arrangement.  |
| FedNano: Toward Lightweight Federated Tuning for Pretrained Multimodal
  Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2506.14824) or [HuggingFace](https://huggingface.co/papers/2506.14824))| Yunpu Ma, Weiguo Li, Haokun Chen, Hewei Gao, Yao Zhang | i) FedNano is a federated learning framework designed for parameter-efficient adaptation of pretrained multimodal large language models (MLLMs) without client-side LLM deployment. ii) The research aims to address the computational, communication, and data heterogeneity challenges of deploying MLLMs in federated learning environments. iii) The methodology involves centralizing the LLM on the server, introducing lightweight NanoEdge modules on clients for local adaptation, and employing Fisher Merging for server-side aggregation to handle non-IID data. iv) Experiments show FedNano reduces client-side storage by 95% and achieves over 99% communication reduction compared to PEFT-based FL methods, attaining 81.41% accuracy on ScienceQA and 78.04% on IconQA for LLaVA. v) FedNano offers AI practitioners a scalable and communication-efficient approach for deploying MLLMs in decentralized settings, enabling practical application on resource-constrained devices and enhancing performance with non-IID datasets.  |
