

## Papers for 2025-05-13

| Title | Authors | Summary |
|-------|---------|---------|
| Seed1.5-VL Technical Report (Read more on [arXiv](https://arxiv.org/abs/2505.07062) or [HuggingFace](https://huggingface.co/papers/2505.07062))| kuma-zhao, yuanlp, 0nejiawei, chb1997, anyuzx | Seed1.5-VL is a vision-language foundation model, comprising a 532M-parameter vision encoder and a 20B active parameter Mixture-of-Experts LLM, designed for general-purpose multimodal understanding and reasoning. The primary objective is to detail the development of Seed1.5-VL, focusing on advancing multimodal capabilities by addressing data scarcity through extensive data synthesis and achieving efficient training for its asymmetrical architecture. Key methodologies include pre-training on 3 trillion diverse tokens covering images, videos, text, and HCI data, with specialized data pipelines for OCR, grounding, and 3D understanding, followed by post-training using Supervised Fine-tuning, RLHF, RLVR, and iterative rejection sampling for LongCoT. Seed1.5-VL achieves state-of-the-art performance on 38 out of 60 public benchmarks, including 85.6% on MathVista (thinking mode) and 87.2% on the WebVoyager GUI agent task. For AI practitioners, this report offers a comprehensive guide to building efficient and high-performing VLMs, detailing data curation, training strategies for MoE-based LLMs with native-resolution vision encoders, and infrastructure optimizations, particularly valuable for developing versatile multimodal AI systems. |
| MiMo: Unlocking the Reasoning Potential of Language Model -- From
  Pretraining to Posttraining (Read more on [arXiv](https://arxiv.org/abs/2505.07608) or [HuggingFace](https://huggingface.co/papers/2505.07608))| whatseeker, Prestonprom, HugoZHL, dwzhu, xiabingquan | This paper introduces MiMo-7B, a large language model optimized across pre-training and post-training stages specifically for reasoning tasks. The primary objective is to unlock and enhance the inherent reasoning potential of language models by systematically improving data processing, model architecture, and reinforcement learning techniques. Key methodologies include a three-stage pre-training data mixing strategy on 25 trillion tokens with a Multi-Token Prediction objective, and post-training using reinforcement learning on 130K verifiable math/code problems with a novel test-difficulty-driven code-reward scheme and strategic data resampling. The final RL-tuned model, MiMo-7B-RL, achieves superior performance, notably scoring 55.4 on AIME 2025, surpassing OpenAI o1-mini by 4.7 points, and significantly outperforming it on LiveCodeBench v5 (MiMo-7B-RL: 57.8, o1-mini: 53.8). The principal implication for AI practitioners is that targeted optimizations in both pre-training and post-training, particularly with high-quality verifiable data and refined RL reward mechanisms, can enable smaller models to achieve state-of-the-art reasoning capabilities comparable to or exceeding much larger or proprietary models. |
| Step1X-3D: Towards High-Fidelity and Controllable Generation of Textured
  3D Assets (Read more on [arXiv](https://arxiv.org/abs/2505.07747) or [HuggingFace](https://huggingface.co/papers/2505.07747))| PanJianxiong, flybirdtian, shian7, wchengad, xuanyangz | Step1X-3D introduces an open framework for high-fidelity, controllable generation of textured 3D assets through rigorous data curation and a novel two-stage 3D-native architecture. The primary objective is to overcome fundamental challenges in 3D generation, such as data scarcity and algorithmic limitations, by providing an open and reproducible solution. Its methodology combines a pipeline curating over 5 million initial assets into a 2 million high-quality dataset, a hybrid VAE-DiT for Truncated Signed Distance Function (TSDF)-based geometry generation, and a diffusion model for geometrically-conditioned, view-consistent texture synthesis, notably supporting direct transfer of 2D control techniques like LoRA. Step1X-3D achieves state-of-the-art results among open-source methods, notably attaining the highest texture CLIP-Score of 0.853 in comparative benchmarks and competitive geometry scores (e.g., Uni3D-I of 0.361). For AI practitioners, this framework offers a robust, open-source baseline with models, training code, and curated data, facilitating advancements in controllable 3D asset generation and simplifying the integration of established 2D control mechanisms into 3D workflows. |
| Learning from Peers in Reasoning Models (Read more on [arXiv](https://arxiv.org/abs/2505.07787) or [HuggingFace](https://huggingface.co/papers/2505.07787))| Benyou, tangzhy, Jiaxi0775, wydu, Zeno-Luo | This paper introduces Learning from Peers (LeaP), a method for Large Reasoning Models (LRMs) to overcome the "Prefix Dominance Trap"—where poor initial reasoning hinders recovery—by sharing intermediate insights among parallel inference paths. The primary objective is to enhance the limited self-correction capabilities of LRMs by enabling them to learn from diverse reasoning trajectories. LeaP's methodology involves periodic communication (every T tokens) where each reasoning path summarizes its current state, sharing these summaries with peers via a routing mechanism (e.g., Dispersed, Hybrid); a fine-tuned LeaP-T series is proposed for smaller models. Key results show significant improvements: QwQ-32B with LeaP achieves nearly 5 absolute points higher Pass@1 on average than its baseline, and on a 14B model, LeaP reduced the "Prefix Dominance Trap" performance gap from 19.88 to 7.81 points on an AIME 2024 subset. For AI practitioners, this research offers a strategy to build more robust reasoning systems by facilitating collaborative error correction and diverse exploration during inference, improving performance even when initial reasoning is flawed. |
| Unified Continuous Generative Models (Read more on [arXiv](https://arxiv.org/abs/2505.07447) or [HuggingFace](https://huggingface.co/papers/2505.07447))| Yi Jiang, tlin-taolin, sp12138sp | This paper introduces a unified framework, UCGM, for continuous generative models. The research aims to provide a unified training and sampling methodology applicable to both multi-step and few-step generative models. The proposed methodology uses a unified training objective parameterized by a consistency ratio and a novel self-boosting mechanism for improved performance. Experiments on ImageNet 256x256 using a 675M diffusion transformer model show UCGM-T achieves 1.30 FID in 20 sampling steps and 1.42 FID in 2 sampling steps. AI practitioners can leverage UCGM for improved training efficiency and sample quality across different continuous generative modeling paradigms, with reduced reliance on classifier-free guidance.  |
| REFINE-AF: A Task-Agnostic Framework to Align Language Models via
  Self-Generated Instructions using Reinforcement Learning from Automated
  Feedback (Read more on [arXiv](https://arxiv.org/abs/2505.06548) or [HuggingFace](https://huggingface.co/papers/2505.06548))| Pawan Goyal, Somak Aditya, Aniruddha Roy, abhi1nandy2, Pretam | REFINE-AF is a task-agnostic framework that aligns smaller open-source language models using self-generated instructions and Reinforcement Learning from Automated Feedback (RLAF). The primary objective is to investigate the effectiveness of smaller LLMs (LLaMA 2-7B/13B, Mistral 7B) for task-agnostic instruction generation and assess the impact of RLAF in this process. The methodology involves a three-stage pipeline: iterative instruction generation from a seed set, RLAF using a reward model (based on `oasst-rm-pythia-1.4b` and UniEval metrics) with PPO to refine input-output pair generation, followed by supervised fine-tuning on the resultant dataset. REFINE-AF demonstrated superior performance over the SELF INSTRUCT baseline on the SUPER-NI benchmark, with the LLaMA 2 13B model achieving a 6.6133 average ROUGE-L score and outperforming in 66.39% of tasks using 15,000 generated instructions. For AI practitioners, this research offers a cost-effective method to generate diverse, high-quality instruction datasets for fine-tuning smaller, open-source LLMs, thereby enhancing their instruction-following capabilities with reduced human effort. |
| DanceGRPO: Unleashing GRPO on Visual Generation (Read more on [arXiv](https://arxiv.org/abs/2505.07818) or [HuggingFace](https://huggingface.co/papers/2505.07818))| appleluo, ChenMnZ, ltzhu, wujie10, xzyhku | This paper introduces DanceGRPO, a unified framework adapting Group Relative Policy Optimization (GRPO) to enhance visual generation across diverse generative paradigms, tasks, and models. The research aims to overcome limitations in existing RL-based visual generation, such as incompatibility with ODE-based sampling and training instability, by developing a versatile RL framework for aligning models with human preferences. DanceGRPO reformulates sampling for diffusion and rectified flow models as Markov Decision Processes, unifies them using Stochastic Differential Equations, and applies a GRPO objective with strategies for noise initialization, timestep selection, and multi-reward aggregation. DanceGRPO achieves substantial improvements, outperforming baselines by up to 181% on benchmarks like VideoAlign (e.g., a 181% relative improvement in motion quality for HunyuanVideo) and demonstrating robust performance across various models and tasks. DanceGRPO provides AI practitioners with a scalable and effective Reinforcement Learning from Human Feedback (RLHF) solution for aligning complex visual generative models across image and video domains, enabling more stable and higher-quality visual synthesis. |
| AttentionInfluence: Adopting Attention Head Influence for Weak-to-Strong
  Pretraining Data Selection (Read more on [arXiv](https://arxiv.org/abs/2505.07293) or [HuggingFace](https://huggingface.co/papers/2505.07293))| Steven Wu, Kai Hua, shenke18, zhangysk | This paper introduces AttentionInfluence, a training-free method that uses attention head masking in a small pretrained language model to select high-quality, reasoning-intensive pretraining data for improving larger LLMs. The main objective is to develop an efficient, scalable, and unsupervised method for identifying diverse, high-quality pretraining data to enhance complex reasoning in LLMs, without relying on labeled data or supervised classifiers. AttentionInfluence identifies "retrieval heads" in a small pretrained language model (e.g., 1.3B parameters) using a synthetic task, then computes a data quality score based on the relative loss difference when these heads are masked versus unmasked; this score is used to rank and select data from a large corpus. Using data selected by a 1.3B model, a 7B pretrained model demonstrated substantial improvements, such as a +3.5pp increase on the HumanEval benchmark and +2.7pp on GSM8K, compared to a baseline trained on the unselected corpus. This method offers AI practitioners a scalable, computationally cheaper, and training-free alternative for curating reasoning-centric pretraining datasets, enabling smaller models to effectively guide data selection for training more capable larger models, thus demonstrating weak-to-strong generalization. |
| WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional
  Websites from Scratch (Read more on [arXiv](https://arxiv.org/abs/2505.03733) or [HuggingFace](https://huggingface.co/papers/2505.03733))| shiwk20, hht1113, Houxing, Yqy6, luzimu | This paper introduces WebGen-Bench, a benchmark to evaluate LLM-based agents on generating multi-file interactive websites from scratch. The primary objective is to systematically assess and improve LLM agents' ability to create functional and aesthetically pleasing websites based on natural language instructions. The methodology involves curating diverse website generation instructions (human + GPT-4o), creating 647 test cases (GPT-4o + manual refinement), and employing an automated pipeline with a web-navigation agent (WebVoyager) for functional testing and GPT-4o for aesthetic scoring. The best general-purpose agent combination (Bolt.diy with DeepSeek-R1) achieved only 27.8% accuracy, while fine-tuning Qwen2.5-Coder-32B-Instruct on a subset of their WebGen-Instruct dataset (creating WebGen-LM-32B) reached 38.2% accuracy. For AI practitioners, this work highlights the current limitations of LLMs in complex, from-scratch code generation tasks like website creation but demonstrates that targeted fine-tuning with specialized instructional datasets can significantly enhance these capabilities. |
| Learning Dynamics in Continual Pre-Training for Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.07796) or [HuggingFace](https://huggingface.co/papers/2505.07796))| Daniel Dajun Zeng, Lu Wang, Xingjin Wang, linjinglian, Howe77 | This paper introduces a CPT scaling law that models learning dynamics in continually pre-trained large language models by decoupling the effects of distribution shift and learning rate annealing to predict validation loss. The primary objective is to quantitatively describe and predict how general (Dpt) and specific-domain (Dcpt) validation losses evolve throughout the CPT process under various training configurations. The methodology involves deriving the scaling law by combining a base pre-training loss component (L_base, affected by summed learning rate S1 and annealing area S2) with a distribution shift component (ΔL, modeled as a power-law function of CPT summed LR S1_cpt), fitting parameters using Huber loss minimization. Key results demonstrate that this CPT scaling law (L(t) = Lo + A*(S1_pt + S1_cpt)^-α - C1*S2_pt - C2*S2_cpt + B*(1 - (1 + E*S1_cpt)^-β)) accurately fits validation loss curves across different learning rate schedules, datasets, model sizes, and replay ratios, with the distribution shift term fitting achieving R² values like 0.994 (Dpt) and 0.985 (Dcpt) initially. For AI practitioners, this scaling law provides a predictive tool to optimize CPT hyperparameters—such as loss potential, peak LR, and replay ratio—to effectively balance general and domain-specific performance (Finding 5) and can guide the adaptation of open-source models with unknown pre-training details. |
| Skywork-VL Reward: An Effective Reward Model for Multimodal
  Understanding and Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.07263) or [HuggingFace](https://huggingface.co/papers/2505.07263))| Yi Peng, Wei Shen, Jiangbo Pei, OrlandoHugBot, shawn0wang | The paper introduces Skywork-VL Reward, a novel multimodal reward model designed for robust evaluation of multimodal understanding and reasoning in Vision-Language Models (VLMs). Its primary objective is to provide reliable reward signals for aligning diverse VLMs, including advanced reasoners, with human preferences across a wide range of tasks. The methodology involves curating a large-scale preference dataset of approximately 190,000 pairs and fine-tuning a Qwen2.5-VL-7B-Instruct base model with an added reward head using a multi-stage, pairwise ranking loss approach. Skywork-VL Reward achieves state-of-the-art 73.1% overall accuracy on the VL-RewardBench, and its preference data, when used for Mixed Preference Optimization (MPO), improved a VLM's MathVista score from 69.2% to 73.5%. For AI practitioners, Skywork-VL Reward offers an effective open-source tool for VLM alignment, and its utility in generating high-quality preference data can significantly boost the reasoning capabilities of downstream VLMs. |
| Reinforced Internal-External Knowledge Synergistic Reasoning for
  Efficient Adaptive Search Agent (Read more on [arXiv](https://arxiv.org/abs/2505.07596) or [HuggingFace](https://huggingface.co/papers/2505.07596))| Kang Liu, Jun Zhao, Yiming Ju, Xiaowei Yuan, hzy | This paper introduces IKEA, a reinforcement learning-based agent that synergistically reasons with internal and external knowledge for efficient adaptive search by discerning its own knowledge boundaries. The primary objective is to develop an efficient adaptive search agent that can determine when to use its internal parametric knowledge versus external retrieved knowledge, thereby reducing redundant retrievals and improving reasoning accuracy. IKEA employs reinforcement learning with a novel knowledge-boundary aware reward function and a specially constructed training dataset (balanced between internally-known and externally-required questions) to learn optimal retrieval timing. Evaluations demonstrate that IKEA significantly outperforms baselines; for instance, on Qwen2.5-7B, IKEA achieved an average Exact Match (EM) of 50.05% while reducing retrieval frequency by 50.81% (to 0.91 retrievals) compared to the Search-R1 baseline (45.00% EM, 1.85 retrievals). AI practitioners can leverage IKEA's approach of knowledge-boundary aware rewards and dataset construction to train more efficient and accurate retrieval-augmented LLM agents that better utilize internal knowledge, leading to reduced latency and computational cost in knowledge-intensive tasks. |
| H^{3}DP: Triply-Hierarchical Diffusion Policy for Visuomotor
  Learning (Read more on [arXiv](https://arxiv.org/abs/2505.07819) or [HuggingFace](https://huggingface.co/papers/2505.07819))| Pu Hua, Zhecheng Yuan, Yufeng Tian, binaryXwizard, Lyy0725 | H³DP introduces a triply-hierarchical diffusion policy for visuomotor learning that integrates depth-aware input, multi-scale visual features, and hierarchical action generation to improve robotic manipulation. The primary objective is to enhance visuomotor policy learning by explicitly incorporating hierarchical structures across visual perception and action generation, thereby strengthening their coupling for improved performance in complex robotic manipulation tasks. The H³DP framework employs three hierarchical levels: 1) depth-aware input layering of RGB-D observations based on depth information, 2) multi-scale visual representations encoding semantic features at varying granularities, and 3) a hierarchically conditioned diffusion process where coarse-to-fine action generation is guided by corresponding visual features at different scales. H³DP achieved a +27.5% average relative improvement over baselines across 44 simulation tasks (resulting in a 75.6% average success rate for H³DP) and demonstrated superior performance in 4 challenging bimanual real-world manipulation tasks, with specific results like a 66.2% average success rate on instance generalization tasks. AI practitioners can leverage the triply-hierarchical design of H³DP to develop more robust and effective visuomotor learning agents, as explicitly structuring the perception-action pipeline with depth awareness, multi-scale feature encoding, and hierarchical action conditioning significantly enhances policy performance and generalization in complex, cluttered environments. |
| Continuous Visual Autoregressive Generation via Score Maximization (Read more on [arXiv](https://arxiv.org/abs/2505.07812) or [HuggingFace](https://huggingface.co/papers/2505.07812))| Jie Zhou, Fandong Meng, cccczshao | This paper introduces a Continuous Visual Autoregressive (VAR) framework enabling direct visual generation without vector quantization by optimizing strictly proper scoring rules. The main objective is to overcome information loss from quantization in traditional VAR models by developing a method for direct autoregressive generation in continuous visual data spaces. The key methodology involves using strictly proper scoring rules, primarily the energy score, as training objectives within a Transformer architecture (termed Energy-based AutoRegression or EAR), where an MLP generator implicitly models the predictive distribution. The EAR-H model achieves a Fréchet Inception Distance (FID) of 1.97 on ImageNet 256x256 conditional generation, demonstrating competitive performance with significantly higher inference efficiency compared to per-token diffusion methods. The principal implication for AI practitioners is the provision of a likelihood-free training paradigm for autoregressive models on continuous data, offering an alternative to quantization-based approaches and potentially leading to improved generation quality and efficiency for modalities beyond discrete tokens. |
| Overflow Prevention Enhances Long-Context Recurrent LLMs (Read more on [arXiv](https://arxiv.org/abs/2505.07793) or [HuggingFace](https://huggingface.co/papers/2505.07793))| rgiryes, leokarlin, OmegaLittleBob, ItamarZ, assafbk | This paper introduces OPRM, a training-free chunk-based inference strategy that significantly enhances the long-context processing capabilities of recurrent LLMs by preventing memory overflows. The research investigates the limitations of fixed-size recurrent memory in large long-context models and aims to develop a method to mitigate these limitations, thereby improving their performance on long-context tasks. The proposed OPRM method involves segmenting the input context into fixed-size chunks, processing each chunk (wrapped with original prefix and suffix) speculatively in parallel, and then selectively decoding from the chunk determined to be most relevant, typically using a minimum entropy criterion combined with an IDK filter. Primary results demonstrate substantial improvements; for instance, on LongBench, OPRM improved the overall performance of RWKV6-Finch-7B by 51%, and Falcon3-Mamba-Inst-7B with OPRM achieved a state-of-the-art 30.8 score on the LongBench v2 benchmark for its size class. The principal implication for AI practitioners is that OPRM can be applied as an inference-time technique to existing recurrent LLMs to extend their effective context length and boost performance on tasks with very long sequences without retraining, making these models more competitive for long-context applications. |
| UMoE: Unifying Attention and FFN with Shared Experts (Read more on [arXiv](https://arxiv.org/abs/2505.07260) or [HuggingFace](https://huggingface.co/papers/2505.07260))| Jing Li, Chaozheng Wang, ysngkil | i) 1-line summary: This paper introduces UMoE, a unified Mixture-of-Experts architecture that reformulates attention to share FFN-like experts between attention and feed-forward network layers, improving performance and parameter efficiency.  ii) Main research question or objective: The primary objective was to determine if attention mechanisms can be reformulated to be compatible with FFN expert designs for unified MoE application and parameter sharing, without sacrificing expressive power.  iii) Key methodology used: UMoE employs a "pre-mixing" attention reformulation where input token embeddings are first aggregated via weighted summation before being processed by shared two-layer FFN experts, with expert-dependent query projections utilizing low-rank matrices.  iv) Primary results (include at least one specific quantitative finding): UMoE achieved superior performance, with its 540M parameter model attaining a perplexity of 20.44 on FineWeb-Edu, surpassing a comparable 535M FFN-MoE (PPL 21.19), and also demonstrated stronger average zero-shot accuracy (e.g., 40.06% for the base UMoE vs. 39.55% for FFN-MoE).  v) Principal implication for AI practitioners: AI practitioners can leverage UMoE to develop more parameter-efficient and higher-performing large language models by sharing expert modules across attention and FFN layers, informed by the paper's finding that FFN layers can be conceptualized as specialized attention layers with an identity matrix for token mixing. |
| Document Attribution: Examining Citation Relationships using Large
  Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.06324) or [HuggingFace](https://huggingface.co/papers/2505.06324))| Nedim Lipka, Vipula Rawte, Franck-Dernoncourt, ryanrossi | This research investigates document attribution in LLMs by proposing a zero-shot textual entailment approach and an attention-based classification technique to verify citation reliability. The primary objective is to enhance the trustworthiness and interpretability of LLM-generated content by developing methods to accurately trace outputs to source documents and assess the reliability of these citations. The study employs a zero-shot textual entailment framework, prompting LLMs (specifically flan-ul2 and gpt4-o) to determine if a reference entails a claim, and explores an attention-based binary classification method using attention weights from a smaller LLM (flan-t5-small). The zero-shot textual entailment method using flan-ul2 achieved an F1 score of 73.8 on the in-distribution (ID) average and 83.43 on the out-of-distribution (OOD) average of AttributionBench, outperforming prior baselines (e.g., ID LFQA F1 of 85.38 vs. 80.1 baseline), while the preliminary attention-based method with flan-t5-small showed F1 score improvements over its zero-shot baseline on the LFQA subset for most layers. AI practitioners can leverage the proposed zero-shot textual entailment prompting strategy with models like flan-ul2 as a computationally efficient method to improve citation verification and attribution in document-based LLM applications, enhancing system reliability without requiring task-specific fine-tuning. |
| Physics-Assisted and Topology-Informed Deep Learning for Weather
  Prediction (Read more on [arXiv](https://arxiv.org/abs/2505.04918) or [HuggingFace](https://huggingface.co/papers/2505.04918))| Yerong Feng, Qing Ling, Yumenomae | PASSAT is a novel deep learning model for weather prediction that integrates physics, via the advection and Navier-Stokes equations, with a topology-informed spherical graph neural network to model weather evolution on a spherical manifold. The main objective is to develop a deep learning model that overcomes limitations of existing approaches by explicitly incorporating underlying physical laws and the Earth's spherical topology. PASSAT's methodology involves numerically solving the advection and Navier-Stokes equations on a spherical manifold for the advection process, while a spherical graph neural network estimates the Earth-atmosphere interaction and generates the initial velocity fields for the advection equation. On the 5.625°-resolution ERA5 dataset, PASSAT outperformed state-of-the-art deep learning models and the operational numerical weather prediction model IFS T42; for instance, for geopotential at 500hPa (z500) with a 72-hour lead time, PASSAT achieved an RMSE of 420, compared to 438 for GraphCast and 489 for IFS T42. The principal implication for AI practitioners is that synergistically combining deep learning with domain-specific physical differential equations and appropriate geometric representations can significantly improve model accuracy and physical consistency in complex spatio-temporal forecasting tasks. |
| Multi-Objective-Guided Discrete Flow Matching for Controllable
  Biological Sequence Design (Read more on [arXiv](https://arxiv.org/abs/2505.07086) or [HuggingFace](https://huggingface.co/papers/2505.07086))| Tong Chen, pranamanam, sophtang, yinuozhang | This paper introduces Multi-Objective-Guided Discrete Flow Matching (MOG-DFM), a framework for steering discrete flow matching models to design biological sequences optimizing multiple conflicting objectives. The research aims to develop a controllable method for generating Pareto-efficient peptide and DNA sequences by guiding pretrained discrete flow matching models across multiple functional and biophysical criteria. MOG-DFM iteratively guides a base discrete flow matching generator by computing a hybrid rank-directional score for candidate token transitions and applying an adaptive hypercone filter to ensure consistent multi-objective progression towards a specified trade-off. MOG-DFM significantly outperformed traditional multi-objective algorithms in peptide design, boosting non-fouling and solubility by approximately 30-50% and extending half-life by a factor of 3 to 4 compared to the next-best method. In DNA enhancer design, MOG-DFM successfully guided generation towards specific enhancer classes (e.g., achieving class 1 probability ~0.7) and desired DNA shapes (e.g., HelT ~36.0). AI engineers can leverage MOG-DFM as a versatile tool for de novo multi-property design of discrete biological sequences, enabling fine-grained control over trade-offs between complex, user-defined objectives. |
