

## Papers for 2025-05-29

| Title | Authors | Summary |
|-------|---------|---------|
| The Entropy Mechanism of Reinforcement Learning for Reasoning Language
  Models (Read more on [arXiv](https://arxiv.org/abs/2505.22617) or [HuggingFace](https://huggingface.co/papers/2505.22617))| Haozhan72, yuxinzuo, JC-Chen, YucZhang2003, ganqu | i) The paper investigates the collapse of policy entropy in reinforcement learning (RL) for reasoning language models (LLMs) and proposes techniques to mitigate this issue. ii) The research aims to understand and control the dynamics of policy entropy in RL-tuned LLMs to improve exploration and downstream task performance. iii) The methodology involves theoretical derivation of entropy dynamics, empirical analysis of covariance between action probabilities and logit changes, and the introduction of Clip-Cov and KL-Cov regularization techniques. iv) The primary result is the establishment of a transformation equation R = -a exp H + b between entropy H and downstream performance R, indicating that performance is traded from policy entropy, and experiments showed that Clip-Cov and KL-Cov led to better downstream performance by approximately 2.0% on the 7B model and 6.4% on the 32B model, on average. v) AI/ML engineers can leverage the Clip-Cov and KL-Cov methods to encourage exploration and improve the performance of RL-trained LLMs by mitigating the entropy collapse issue, ultimately leading to a better scaling of compute resources for RL.  |
| R2R: Efficiently Navigating Divergent Reasoning Paths with Small-Large
  Model Token Routing (Read more on [arXiv](https://arxiv.org/abs/2505.21600) or [HuggingFace](https://huggingface.co/papers/2505.21600))| Zhihang Yuan, Enshu Liu, Yi Ge, youyc22, fuvty | R2R introduces a token routing method for efficient LLM inference by selectively offloading token generation to SLMs. The research question is whether SLMs can follow LLM reasoning paths by replacing only divergent tokens. They develop an automatic pipeline to label divergent tokens and train a lightweight neural router to predict them based on SLM outputs. R2R achieves a 2.8x wall-clock speedup over the R1-32B LLM with comparable performance and surpasses the average accuracy of the R1-7B model by 1.6x using only an average activated parameter size of 5.6B. AI practitioners can leverage R2R to improve the test-time scaling efficiency of LLMs by reducing inference overhead while preserving reasoning quality.  |
| Skywork Open Reasoner 1 Technical Report (Read more on [arXiv](https://arxiv.org/abs/2505.22312) or [HuggingFace](https://huggingface.co/papers/2505.22312))| Chaojie Wang, Rui Yan, Jujie He, chrisliu298, skydownacai | Skywork Open Reasoner 1 introduces an RL-enhanced long Chain-of-Thought model, Skywork-OR1. The research investigates how to improve reasoning abilities of large language models using reinforcement learning, focusing on efficiency and scalability for long CoT models. The methodology involves building upon the DeepSeek-R1-Distill model series with a tailored RL approach, incorporating multi-stage training, adaptive entropy control, and detailed ablation studies. The 32B Skywork-OR1 model achieves an average accuracy increase of 15.0% across AIME24, AIME25, and LiveCodeBench, reaching 82.2% on AIME24; a 7B model achieved an average accuracy increase of 13.9%. The findings indicate that careful RL implementation, specifically mitigating premature entropy collapse and balancing exploration/exploitation, significantly improves reasoning performance, providing AI practitioners with an effective recipe for enhancing CoT models.  |
| Sherlock: Self-Correcting Reasoning in Vision-Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.22651) or [HuggingFace](https://huggingface.co/papers/2505.22651))| Ruqi Zhang, Tuwhy | i) The paper introduces Sherlock, a training framework to enhance self-correction and reasoning in Vision-Language Models (VLMs). ii) The research aims to address the limitations of reasoning VLMs, specifically their sensitivity to errors, data dependency, and generalization issues, by leveraging self-correction strategies. iii) Sherlock incorporates a trajectory-level self-correction objective, preference data construction based on visual perturbation, and a dynamic ẞ for preference tuning within a three-stage training process involving SFT, offline, and online preference learning. iv) Evaluated on eight benchmarks, Sherlock achieves an average accuracy of 64.1 with direct generation and 65.4 after self-correction, outperforming LLaVA-CoT (63.2), Mulberry (63.9), and LlamaV-01 (63.4) while using only 20k annotated data samples. v) The introduction of Sherlock, enabling self-improvement and self-correction within VLMs using limited annotated data, offers AI practitioners an efficient way to enhance the robustness and accuracy of reasoning VLMs in complex multimodal tasks.  |
| Unsupervised Post-Training for Multi-Modal LLM Reasoning via GRPO (Read more on [arXiv](https://arxiv.org/abs/2505.22453) or [HuggingFace](https://huggingface.co/papers/2505.22453))| Chen Wang, Yuting Li, weiranhuang, weiranhuang, WaltonFuture | i) The paper introduces MM-UPT, a novel framework for unsupervised post-training of Multi-Modal Large Language Models (MLLMs). ii) The main objective is to enable continual self-improvement of MLLMs without external supervision by using unlabeled multi-modal data. iii) The methodology involves leveraging Group-Regularized Policy Optimization (GRPO) with a self-rewarding mechanism based on majority voting over multiple sampled responses. iv) Experiments show that MM-UPT improves the reasoning ability of Qwen2.5-VL-7B, with an increase from 66.3% to 72.9% on MathVista using standard datasets without ground truth labels. v) MM-UPT offers AI practitioners a new paradigm for continual, autonomous enhancement of MLLMs in the absence of external supervision.  |
| SWE-rebench: An Automated Pipeline for Task Collection and
  Decontaminated Evaluation of Software Engineering Agents (Read more on [arXiv](https://arxiv.org/abs/2505.20411) or [HuggingFace](https://huggingface.co/papers/2505.20411))| Anton Shevtsov, Maksim Nekrashevich, sbkarasik, djalexj, ibragim-bad | i) SWE-rebench introduces an automated pipeline for collecting and evaluating software engineering tasks for LLM agents, addressing data scarcity and contamination. ii) The research aims to provide a scalable, automated method for generating high-quality, interactive SWE tasks and a contamination-free benchmark for evaluating agentic software engineering. iii) The methodology involves automated extraction of interactive SWE tasks from GitHub repositories, environment configuration, installation verification, and automated task quality assessment using LLMs fine-tuned on SWE-bench data. iv) SWE-rebench provides a public dataset of over 21,000 interactive Python-based SWE tasks, and the pipeline achieves a working installation recipe for at least one task in 31% of the repositories. v) AI practitioners can use SWE-rebench as a resource for reinforcement learning of SWE agents at scale and a benchmark to compare LLMs, potentially revealing inflated performance due to contamination issues on SWE-bench Verified.  |
| SageAttention2++: A More Efficient Implementation of SageAttention2 (Read more on [arXiv](https://arxiv.org/abs/2505.21136) or [HuggingFace](https://huggingface.co/papers/2505.21136))| Pengle Zhang, Haofeng Huang, Jia Wei, Xiaoming Xu, jt-zhang | SageAttention2++ introduces an optimized attention mechanism using FP8 quantization with FP16 accumulation. The research aims to enhance the efficiency of SageAttention2 by leveraging faster FP8 Matmul instructions. It employs narrowing of the FP8 quantization range to ensure values remain within the representable range of FP16. Experimental results show SageAttention2++ achieves up to a 3.9× speedup over FlashAttention2 while maintaining similar attention accuracy. This improvement offers AI practitioners a plug-and-play acceleration method for attention mechanisms in diverse models with minimal end-to-end metric loss.  |
| Advancing Multimodal Reasoning via Reinforcement Learning with Cold
  Start (Read more on [arXiv](https://arxiv.org/abs/2505.22334) or [HuggingFace](https://huggingface.co/papers/2505.22334))| Kaipeng Zheng, Yuting Li, weiranhuang, weiranhuang, WaltonFuture | i) The paper introduces a two-stage approach (SFT+RL) for enhancing multimodal reasoning in large language models (MLLMs). ii) The main research question is how different cold start strategies during supervised fine-tuning (SFT) impact downstream reinforcement learning (RL) performance in the multimodal domain. iii) The methodology involves supervised fine-tuning (SFT) using structured chain-of-thought reasoning patterns as a cold start, followed by reinforcement learning via GRPO. iv) The resulting 7B model achieves a 73.4% score on MathVista, a +7.10 points increase, and state-of-the-art performance among open-source MLLMs at both 3B and 7B scales. v) AI practitioners should consider using an SFT-based cold start approach to provide a robust foundation for RL scaling, which leads to improved performance in multimodal reasoning tasks, as it demonstrates potential for narrowing performance gaps between smaller and larger multimodal language models.  |
| Fostering Video Reasoning via Next-Event Prediction (Read more on [arXiv](https://arxiv.org/abs/2505.22457) or [HuggingFace](https://huggingface.co/papers/2505.22457))| Kenji Kawaguchi, Chao Du, Xiangyan Liu, Hongfu Liu, Haonan Wang | i) The paper introduces next-event prediction (NEP) as a self-supervised learning task for enhancing temporal reasoning in multimodal large language models (MLLMs) using past video frames to predict summaries of future events. ii) The research question is to determine an effective learning task that equips MLLMs with temporal reasoning capabilities over video inputs, addressing limitations in existing methods like video question answering and captioning. iii) The methodology involves creating a dataset, V1-33K, consisting of 33,000 video segments with paired past and future frames and employing various video instruction-tuning strategies, including supervised fine-tuning (SFT), critique fine-tuning (CFT), distillation, and mixed-tuning. iv) Experiments show that incorporating NEP enhances MLLMs' temporal understanding and reasoning, with a performance improvement on temporal benchmarks reflected in FutureBench and maintains general video understanding. A 60.0 average score on V1-33K dataset v) NEP provides a scalable and effective training paradigm for AI practitioners to improve temporal reasoning in MLLMs for various applications, enhancing their ability to infer future events without sacrificing general video understanding. |
| RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with
  Global Illumination (Read more on [arXiv](https://arxiv.org/abs/2505.21925) or [HuggingFace](https://huggingface.co/papers/2505.21925))| Xin Tong, Hongzhi Wu, Pieter Peers, doyleconan, NCJ | RenderFormer is introduced as a transformer-based neural rendering pipeline for triangle meshes, achieving global illumination effects without per-scene training. The paper explores if a rendering pipeline can be learned end-to-end, rather than overfitting a model to a fixed scene. The research formulates rendering as a sequence-to-sequence transformation, converting triangle tokens to pixel tokens using a two-stage transformer architecture. The model is trained on synthetic scenes with a single reflectance model and a limited number of light sources and triangles. Results demonstrate visually similar renderings to Blender Cycles, and the model can handle scenes with at most 4,096 triangles. RenderFormer presents a neural rendering approach to solving global illumination that can be directly incorporated into existing triangle mesh workflows.  |
| DeepResearchGym: A Free, Transparent, and Reproducible Evaluation
  Sandbox for Deep Research (Read more on [arXiv](https://arxiv.org/abs/2505.19253) or [HuggingFace](https://huggingface.co/papers/2505.19253))| Abhijay Paladugu, Kangrui Mao, Jingyuan He, Jingjie Ning, jmvcoelho | i) DeepResearchGym is introduced as an open-source framework for reproducible evaluation of deep research systems, addressing the limitations of commercial APIs. ii) The research aims to provide a transparent and reproducible environment for benchmarking deep research systems. iii) The methodology combines a reproducible search API using ClueWeb22 and FineWeb, indexed with DiskANN, and an evaluation protocol extending the Researchy Questions dataset using LLM-as-a-judge metrics. iv) The system achieves lower latency than commercial APIs while ensuring stable document rankings; systems integrated with DeepResearchGym achieve performance comparable to commercial APIs. v) AI practitioners can use DeepResearchGym to evaluate deep research systems with a reproducible search API and automatic metrics, helping to standardize the comparison between research systems, although limitations concerning the use of proprietary LLMs restrict full output reproducibility.  |
| Chain-of-Zoom: Extreme Super-Resolution via Scale Autoregression and
  Preference Alignment (Read more on [arXiv](https://arxiv.org/abs/2505.18600) or [HuggingFace](https://huggingface.co/papers/2505.18600))| Jong Chul Ye, Jeongsol Kim, Bryan Sangwoo Kim | i) The paper introduces Chain-of-Zoom (CoZ), a model-agnostic framework for extreme single-image super-resolution (SISR) based on scale autoregression and preference alignment. ii) The main objective is to extend the scalability of existing SR models beyond their training configurations, enabling high-quality image magnification at extreme resolutions without retraining. iii) The methodology involves factorizing SISR into an autoregressive chain of intermediate scale-states with multi-scale-aware text prompts generated by a fine-tuned vision-language model (VLM), using Generalized Reward Policy Optimization (GRPO) for preference alignment. iv) Experiments show CoZ attains beyond 256× enlargement with a standard 4× diffusion SR model, improving perceptual quality and fidelity, as measured by non-reference metrics such as a NIQE score of 8.2335 on DIV2K dataset compared to 16.5915 for direct SR at 64x magnification. v) CoZ provides AI practitioners with a resource-efficient method for achieving extreme image super-resolution by leveraging existing SR models and VLMs, circumventing the need to train new models for each magnification factor.  |
| Universal Reasoner: A Single, Composable Plug-and-Play Reasoner for
  Frozen LLMs (Read more on [arXiv](https://arxiv.org/abs/2505.19075) or [HuggingFace](https://huggingface.co/papers/2505.19075))| Jong Chul Ye, Choonghan Kim, Hyunmin Hwang, Hangeol Chang, kjm981995 | i) The paper introduces Universal Reasoner (UniR), a plug-and-play reasoning module for frozen LLMs. ii) The research aims to create a lightweight, composable reasoning module transferable across different LLM architectures. iii) The methodology involves decoupling reward model training from full policy updates, training a reasoning module using predefined rewards optimized with a policy gradient algorithm, and additively combining its logits with a frozen LLM backbone at inference. iv) Experiments on math reasoning tasks using Llama3.2 showed UniR achieved an average pass@1 score of 36.0, outperforming GRPO LORA. v) UniR offers AI practitioners a cost-efficient method for enhancing reasoning in LLMs without architectural dependencies, enabling modular composition of task-specific expertise.  |
| SVRPBench: A Realistic Benchmark for Stochastic Vehicle Routing Problem (Read more on [arXiv](https://arxiv.org/abs/2505.21887) or [HuggingFace](https://huggingface.co/papers/2505.21887))| Zangir Iklassov, Salem Lahlou, Martin Takac, Yahia Salaheldin Shaaban, ahmedheakl | SVRPBench introduces a new open benchmark for evaluating stochastic vehicle routing problem (SVRP) solvers under realistic urban conditions. The research aims to address the limitations of existing benchmarks by incorporating high-fidelity stochastic dynamics such as time-dependent congestion, log-normal delays, and probabilistic accidents. The methodology involves simulating diverse, constraint-rich scenarios with up to 1000 customers, multi-depot, and multi-vehicle setups, and benchmarking existing solvers. Results show that state-of-the-art RL solvers like POMO and AM degrade by over 20% under distributional shift compared to classical and metaheuristic methods. This highlights the need for AI practitioners to design robust routing algorithms that generalize beyond synthetic assumptions and adapt to real-world uncertainty, specifically to consider distributional shifts that may severely affect RL performance.  |
| What Makes for Text to 360-degree Panorama Generation with Stable
  Diffusion? (Read more on [arXiv](https://arxiv.org/abs/2505.22129) or [HuggingFace](https://huggingface.co/papers/2505.22129))| Jing Zhang, Qiang Zhang, allencbzhang, mcleanie | i) This paper analyzes the role of LoRA-adapted attention modules within Stable Diffusion for text-to-360-degree panorama generation. ii) The research investigates which trainable components in LoRA fine-tuning are most critical for adapting pre-trained diffusion models to panoramic image generation. iii) The methodology involves isolating and jointly training the query, key, value, and output weight matrices (W{q,k,v,o}) of attention modules using LoRA, followed by ablation studies. iv) The analysis reveals that the value and output weight matrices (W{v,o}) are more responsible for adapting to the panoramic domain, achieving a Fréchet Auto-Encoder Distance (FAED) of 5.90 with a specific configuration of mixture of experts on a 512x1024 resolution. v) This suggests that AI practitioners can optimize fine-tuning by focusing capacity enhancement on value and output weight matrices, while potentially freezing or down weighting query and key matrices when adapting Stable Diffusion for panoramic image generation, leading to memory-efficient training.  |
| WebDancer: Towards Autonomous Information Seeking Agency (Read more on [arXiv](https://arxiv.org/abs/2505.22648) or [HuggingFace](https://huggingface.co/papers/2505.22648))| Liwen Zhang, Wenbiao Yin, Runnan Fang, Baixuan Li, callanwu | i) WebDancer presents a framework for building autonomous information-seeking agents. ii) The research aims to develop a systematic approach for creating web agents capable of multi-step reasoning and information retrieval. iii) The methodology involves browsing data construction, trajectories sampling, supervised fine-tuning for cold start, and reinforcement learning for generalization, instantiated in a ReAct-based web agent. iv) Empirical evaluations on GAIA and WebWalkerQA demonstrate WebDancer's strong performance, achieving considerable results and highlighting the efficacy of the training paradigm. One such evaluation noted a Pass@3 score of 61.1% on GAIA and 54.6% on WebWalkerQA, for the best-performing model. v) The implication for AI practitioners is a systematic, end-to-end pipeline to construct long-term information-seeking web agents, offering a structured pathway to develop capable agentic models, especially in complex, real-world applications.  |
| Judging Quality Across Languages: A Multilingual Approach to Pretraining
  Data Filtering with Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.22232) or [HuggingFace](https://huggingface.co/papers/2505.22232))| Abbas Goher Khan, Elias Wendt, Max Lübbering, Mehdi Ali, mbrack | i) The paper introduces JQL, a multilingual pretraining data filtering approach leveraging language models for quality assessment across 35 languages. ii) The research aims to curate high-quality, diverse multilingual data efficiently while minimizing computational costs. iii) JQL uses lightweight annotators distilled from pretrained multilingual embeddings to assess data quality, evaluated empirically across 35 languages. iv) JQL substantially outperforms heuristic filtering methods like Fineweb2, increasing data retention rates while enhancing downstream model training quality; for example, using the 0.6 percentile threshold in Spanish retains over 9% more tokens than FW2 and exhibits improved quality. v) The approach provides practical insights and resources for multilingual data curation, facilitating the development of high-quality multilingual datasets for AI practitioners. |
| LIMOPro: Reasoning Refinement for Efficient and Effective Test-time
  Scaling (Read more on [arXiv](https://arxiv.org/abs/2505.19187) or [HuggingFace](https://huggingface.co/papers/2505.19187))| Kaishuai Xu, Chunpu Xu, Ruifeng Yuan, Jiashuo Wang, YangXiao-nlp | LIMOPro introduces a reasoning refinement framework to improve efficiency in large language models (LLMs). The paper addresses the question of how to optimize reasoning chains distilled from powerful language models to reduce computational demands without sacrificing accuracy. Perplexity-based Importance Refinement (PIR) is used to quantitatively evaluate the importance of each reasoning step, selectively pruning low-importance functional steps while preserving progressive reasoning components. Fine-tuning on PIR-optimized data achieves improved accuracy (up to +6.6%) with reduced token usage (up to -41%) on benchmarks like AIME, AMC, and GPQA Diamond. This provides AI practitioners with a method to deploy reasoning-capable LLMs more efficiently by optimizing the training data and reducing inference costs and response times.  |
| Towards Dynamic Theory of Mind: Evaluating LLM Adaptation to Temporal
  Evolution of Human States (Read more on [arXiv](https://arxiv.org/abs/2505.17663) or [HuggingFace](https://huggingface.co/papers/2505.17663))| Chunpu Xu, Changhe Song, Qiancheng Xu, Jiashuo Wang, YangXiao-nlp | i) The paper introduces DYNTOM, a novel benchmark to evaluate LLMs' ability to understand and track the temporal evolution of human mental states across interconnected social scenarios. ii) The research investigates how well LLMs adapt to dynamic changes in mental states, moving beyond static snapshots typically assessed in existing benchmarks. iii) DYNTOM employs a four-step framework for generating social contexts, designing mental state trajectories, creating natural dialogues, and formulating targeted questions. iv) Empirical evaluation of ten LLMs reveals that their performance lags behind human performance by 44.7%, particularly in transformation-type questions assessing mental state changes. v) The findings imply that AI practitioners should focus on improving LLMs' capacity for temporal reasoning and understanding the dynamic nature of human mental states to better simulate and interact within real-world social contexts.  |
| VRAG-RL: Empower Vision-Perception-Based RAG for Visually Rich
  Information Understanding via Iterative Reasoning with Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2505.22019) or [HuggingFace](https://huggingface.co/papers/2505.22019))| Zehui Chen, Ruixue Ding, Lin-Chen, YuZeng260, autumncc | i) The paper introduces VRAG-RL, a reinforcement learning framework for visually rich information retrieval-augmented generation. ii) The primary research objective is to enhance VLMs' reasoning and retrieval capabilities when interacting with visually rich information sources. iii) The methodology involves designing a visual perception action space for fine-grained information extraction and a retrieval-based reward function to optimize VLM interactions with search engines. iv) Experiments on SlideVQA, ViDoSeek and MMLongBench show that VRAG-RL outperforms existing methods by 20% on the Qwen2.5-VL-7B model and 30% on the Qwen2.5-VL-3B model. v) VRAG-RL provides AI practitioners with an improved framework for training VLMs to reason effectively with visually rich information, enhancing their applicability in domains requiring complex visual data interpretation and retrieval.  |
| Let's Predict Sentence by Sentence (Read more on [arXiv](https://arxiv.org/abs/2505.22202) or [HuggingFace](https://huggingface.co/papers/2505.22202))| Hoyeon Chang, Jiyeon Kim, Seungone Kim, Byeongguk Jeon, Hyeonbin Hwang | i) The paper introduces a sentence-level autoregressive language model operating within a latent embedding space for structured reasoning. ii) It investigates whether pre-trained language models can effectively perform structured reasoning over sentences rather than tokens by predicting continuous embeddings of next sentences. iii) The study employs two embedding paradigms: semantic embeddings (autoencoding) and contextual embeddings (next-sentence prediction), evaluated under discrete and continuous inference regimes. iv) Continuous inference using contextual embeddings achieves competitive performance with Chain-of-Thought reasoning while reducing inference-time FLOPs by approximately half on average across four reasoning domains. v) AI practitioners can leverage this sentence-level approach to achieve more efficient reasoning in language models, potentially reducing computational costs without sacrificing performance on certain tasks.  |
| RICO: Improving Accuracy and Completeness in Image Recaptioning via
  Visual Reconstruction (Read more on [arXiv](https://arxiv.org/abs/2505.22613) or [HuggingFace](https://huggingface.co/papers/2505.22613))| Linli Yao, Sihan Yang, Shuhuai Ren, Yishuo Cai, Yuchi Wang | i) The paper introduces RICO, a framework for refining image captions by leveraging visual reconstruction to address inaccuracies and incompleteness. ii) The primary objective is to enhance the accuracy and completeness of image captions generated by MLLMs. iii) RICO iteratively refines captions by reconstructing the caption into an image using a text-to-image model, then prompting an MLLM to identify and correct discrepancies between the original and reconstructed images. iv) Experiments show RICO improves caption quality by approximately 10% on CapsBench and CompreCap. v) RICO offers AI practitioners a method to generate higher-quality image caption datasets for improving multimodal model training.  |
| Thinking with Generated Images (Read more on [arXiv](https://arxiv.org/abs/2505.22525) or [HuggingFace](https://huggingface.co/papers/2505.22525))| Jiadi Su, Siqi Kou, Steffi Chern, Zhulin Hu, ethanchern | i) The paper introduces Thinking with Generated Images, a paradigm enabling LMMs to generate intermediate visual reasoning steps. ii) The research explores how LMMs can natively reason across text and vision modalities by generating visual subgoals and self-critiques. iii) The methodology involves a native long-multimodal thought process within unified autoregressive LMMs, with supervised fine-tuning on synthetic multimodal data. iv) Experiments on vision generation benchmarks show up to 50% relative improvement in handling complex multi-object scenarios (38% to 57%) compared to baseline approaches. v) This work provides AI practitioners with a method for enhancing LMMs visual reasoning by enabling them to dynamically generate, critique, and refine internal visual representations.  |
| PrismLayers: Open Data for High-Quality Multi-Layer Transparent Image
  Generative Models (Read more on [arXiv](https://arxiv.org/abs/2505.22523) or [HuggingFace](https://huggingface.co/papers/2505.22523))| Ji Li, Keming Wu, Yanbin Wang, Heyang Jiang, Junwen Chen | i) The paper introduces PrismLayers and PrismLayersPro, datasets for multi-layer transparent image generation. ii) The main objective is to address the lack of high-quality data for training generative models capable of producing multi-layer transparent images with accurate alpha mattes. iii) The methodology includes a training-free synthesis pipeline leveraging pre-trained diffusion models (FLUX) to generate individual layers, followed by composition guided by semantic layouts. iv) The released dataset PRISMLAYERSPRO contains 20K high-fidelity images, enabling the fine-tuning of ART, resulting in ART+ which surpasses ART in 60% user preference in terms of layer quality and prompt following. v) AI/ML practitioners can utilize PRISMLAYERSPRO and the ART+ model to develop and refine multi-layer image generation systems, opening possibilities for layer-wise image editing and creation workflows.  |
| Text2Grad: Reinforcement Learning from Natural Language Feedback (Read more on [arXiv](https://arxiv.org/abs/2505.22338) or [HuggingFace](https://huggingface.co/papers/2505.22338))| Si Qin, Tianjun Mao, Chaoyun Zhang, Lu Wang, Hanyang Wang | i) The paper introduces TEXT2GRAD, a reinforcement learning paradigm converting free-form textual feedback into span-level gradients for language model optimization. ii) The research aims to improve reinforcement learning from human feedback (RLHF) by utilizing the rich information in natural language critiques instead of scalar rewards. iii) TEXT2GRAD uses a three-component architecture: a feedback-annotation pipeline, a fine-grained reward model predicting span-level reward, and a span-level policy optimizer. iv) Evaluated across summarization, code generation, and question answering, TEXT2GRAD surpasses scalar-reward RL and prompt-only baselines, achieving a +25.3% BLEU improvement over PPO on the SLF5K summarization dataset. v) TEXT2GRAD provides a method for AI/ML engineers to perform fine-grained policy optimization by leveraging natural language feedback to adjust model parameters directly, leading to improved sample efficiency and model interpretability.  |
| Pitfalls of Rule- and Model-based Verifiers -- A Case Study on
  Mathematical Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.22203) or [HuggingFace](https://huggingface.co/papers/2505.22203))| Junxian He, Qi Zhu, Xingshan Zeng, Weihao Zeng, yuzhen17 | i) This paper analyzes the vulnerabilities of rule-based and model-based verifiers used in reinforcement learning with verifiable reward (RLVR) for mathematical reasoning. ii) The study investigates the accuracy and robustness of rule-based and model-based verifiers and assesses their impact on the RL training performance of large language models. iii) The research employs static evaluation of verifiers across multiple mathematical datasets and conducts RL training experiments to observe the effect of different verifiers on policy model optimization. iv) The results show that rule-based verifiers exhibit an average recall rate of 86% due to format sensitivity, while model-based verifiers achieve higher static accuracy but are susceptible to reward hacking, with a trained verifier leading to a significant divergence between training and oracle reward after 450 iterations. v) These findings imply that AI practitioners should exercise caution when selecting verifiers in RLVR, as high classification accuracy does not guarantee resistance to reward hacking, and should prioritize robustness to adversarial patterns.  |
| EPiC: Efficient Video Camera Control Learning with Precise Anchor-Video
  Guidance (Read more on [arXiv](https://arxiv.org/abs/2505.21876) or [HuggingFace](https://huggingface.co/papers/2505.21876))| Han Lin, Jialu Li, Jaemin Cho, Zun Wang, jaehong31 | EPiC introduces an efficient camera control learning framework for video diffusion models leveraging precise anchor-video guidance. The research aims to improve controllable 3D camera trajectories in video diffusion models by using higher quality anchor videos. The methodology involves creating anchor videos by masking source videos based on first-frame visibility and a lightweight Anchor-ControlNet to integrate anchor video guidance. EPiC achieves state-of-the-art performance on RealEstate10K and MiraData for I2V camera control, obtaining superior camera accuracy with rotation error decreasing to 0.40 ± 0.11 on RealEstate10K. EPiC offers AI practitioners an efficient training approach requiring fewer parameters and less data for precise and robust camera control in video generation tasks. It remains unclear the degree to which specific algorithmic innovation contributes compared to architectural choices.  |
| GRE Suite: Geo-localization Inference via Fine-Tuned Vision-Language
  Models and Enhanced Reasoning Chains (Read more on [arXiv](https://arxiv.org/abs/2505.18700) or [HuggingFace](https://huggingface.co/papers/2505.18700))| Yiren Song, Haofan Wang, Zihao Pan, Xiaoran Pan, Chun Wang | i) The paper introduces the GRE Suite, a framework designed to improve geo-localization inference by augmenting Vision-Language Models (VLMs) with structured reasoning chains. ii) The main objective is to enhance the accuracy and interpretability of geo-localization by addressing the limitations of current methods in complex geographic inference. iii) The methodology involves constructing a high-quality geo-localization reasoning dataset, GRE30K, and developing a GRE model using multi-stage reasoning and reinforcement learning training. iv) Experimental results demonstrate that GRE significantly outperforms existing methods, achieving a 11.3% accuracy within 1km on the Im2GPS3k dataset; the Geo Reason Evaluation Benchmark (GREval-Bench) further assesses VLMs. v) For AI practitioners, the GRE Suite offers a novel reasoning-augmented VLM framework and dataset for improving geo-localization tasks, facilitating applications requiring precise geographic inference from images.  |
| Just as Humans Need Vaccines, So Do Models: Model Immunization to Combat
  Falsehoods (Read more on [arXiv](https://arxiv.org/abs/2505.17870) or [HuggingFace](https://huggingface.co/papers/2505.17870))| Deval Pandya, Marcelo Lotif, Rizwan Qureshi, amanchadha, Shainarazavi | i) The paper introduces "model immunization," a training framework using curated falsehoods as a supervised "vaccine" to enhance AI model truthfulness. ii) The research aims to improve model resistance to misinformation by fine-tuning on explicitly labeled false data. iii) The methodology involves periodically injecting small, quarantined sets of labeled falsehoods during fine-tuning. iv) An illustrative case study showed an increase in model truthfulness from approximately 60% to 78% after immunization with a 5% micro-dose of falsehoods during fine-tuning. v) The principal implication for AI practitioners is a proactive approach to align AI systems with factuality, reducing the generation of misinformation without significantly degrading general performance.  |
| Meta-Learning an In-Context Transformer Model of Human Higher Visual
  Cortex (Read more on [arXiv](https://arxiv.org/abs/2505.15813) or [HuggingFace](https://huggingface.co/papers/2505.15813))| Jacob S. Prince, Hossein Adeli, Mu Nan, Muquan Yu, aluo-x | i) This paper introduces BraInCoRL, a meta-learning framework for predicting voxelwise neural responses in human higher visual cortex using in-context learning. ii) The research aims to develop a generalizable model of visual cortex that adapts to subject-specific neural organization from few-shot examples. iii) A transformer architecture is leveraged to learn an inductive bias over multiple subjects by jointly conditioning on image features and voxel activations, optimizing for in-context learning. iv) Results demonstrate that BraInCoRL outperforms existing voxelwise encoder designs in a low-data regime, generalizing to new visual fMRI datasets and exhibiting test-time scaling behavior; for instance, BraInCoRL with 100 in-context images achieves significantly higher explained variance compared to a ridge regression baseline with the same data. v) BraInCoRL provides AI practitioners with a more data-efficient and generalizable approach to modeling human visual cortex, potentially enabling better interpretability of neural signals and query-driven functional mapping in AI systems interacting with human perception.  |
| One-Way Ticket:Time-Independent Unified Encoder for Distilling
  Text-to-Image Diffusion Models (Read more on [arXiv](https://arxiv.org/abs/2505.21960) or [HuggingFace](https://huggingface.co/papers/2505.21960))| Jiehang Xie, Tao Liu, Kai Wang, Lei Wang, senmaonk | i) The paper introduces a Time-independent Unified Encoder (TiUE) for efficient text-to-image diffusion model distillation. ii) The objective is to reduce inference time and improve image quality/diversity by unifying the encoder across different decoder time steps in diffusion models. iii) A one-pass scheme is proposed where encoder features are shared across multiple decoder time steps, combined with a KL divergence regularization term to improve noise prediction. iv) Results show that TiUE achieves a FID of 23.11 on COCO2017-5K and outperforms state-of-the-art methods such as LCM and SD-Turbo while maintaining computational efficiency. v) TiUE offers AI practitioners a more computationally efficient approach to deploy text-to-image diffusion models with improved image quality and diversity compared to existing distillation techniques.  |
| Unveiling Instruction-Specific Neurons & Experts: An Analytical
  Framework for LLM's Instruction-Following Capabilities (Read more on [arXiv](https://arxiv.org/abs/2505.21191) or [HuggingFace](https://huggingface.co/papers/2505.21191))| Zhaorui Hou, Jungang Li, Yibo Yan, Yubo Gao, Junyan Zhang | i) This paper introduces HEXAINST, a balanced instructional dataset, and SPARCOM, a framework for analyzing sparse components in LLMs to understand instruction following. ii) The research aims to systematically examine how fine-tuning reconfigures LLM computations by isolating and analyzing instruction-specific sparse components. iii) The methodology involves identifying instruction-specific neurons (ISNs) and experts (ISEs), evaluating their generality and uniqueness, and comparing their alterations during fine-tuning. iv) Results show that after fine-tuning, LLMs exhibit an increase in the number of more capable and specialized ISNs, with activation patterns of specific neurons changing significantly (Jaccard similarity coefficient in ISNs is displayed in Table 1). v) The principal implication for AI practitioners is a deeper understanding of how fine-tuning alters internal mechanisms and instruction-following behavior in LLMs. |
| MUSEG: Reinforcing Video Temporal Understanding via Timestamp-Aware
  Multi-Segment Grounding (Read more on [arXiv](https://arxiv.org/abs/2505.20715) or [HuggingFace](https://huggingface.co/papers/2505.20715))| Chenliang Li, Ziyue Wang, Chi Chen, Shengfeng Lou, Fuwen Luo | MUSEG introduces a reinforcement learning method to enhance video temporal understanding in multimodal large language models (MLLMs). The research aims to improve fine-grained temporal reasoning by aligning queries with multiple video segments using timestamp-aware multi-segment grounding. The methodology involves a customized RL training recipe with phased rewards, including segment matching and timestamp rewards. Experiments show MUSEG-7B achieves improved performance on temporal grounding benchmarks, exhibiting a ~60% average score on Charades-STA compared to base models' ~50%. This suggests AI practitioners can leverage MUSEG to develop MLLMs with enhanced temporal reasoning capabilities for time-sensitive video understanding tasks.  |
| Benchmarking Recommendation, Classification, and Tracing Based on
  Hugging Face Knowledge Graph (Read more on [arXiv](https://arxiv.org/abs/2505.17507) or [HuggingFace](https://huggingface.co/papers/2505.17507))| Yuanning Cui, Weiqing Luo, Xiao Zhou, Kaijia Huang, cqsss | i) This paper introduces HuggingKG, a large-scale knowledge graph, and HuggingBench, a benchmark for IR tasks in the open-source machine learning resource domain. ii) The research aims to create structured representations for ML resources to enhance resource management tasks, such as recommendation, classification, and model tracing. iii) The methodology involves constructing a knowledge graph from Hugging Face metadata and creating three novel test collections for benchmarking IR tasks. iv) HuggingKG comprises 2.6 million nodes and 6.2 million edges; experiments show KGCL with Homo subgraph achieves +4.80% higher in Recall@5 compared to social recommendation; TransE performs best on model tracing with unique relation distribution. v) AI practitioners can leverage HuggingKG and HuggingBench for enhanced resource discovery and management, particularly in tasks requiring structured knowledge of ML models, datasets, and user interactions within the Hugging Face ecosystem.  |
| Safe-Sora: Safe Text-to-Video Generation via Graphical Watermarking (Read more on [arXiv](https://arxiv.org/abs/2505.12667) or [HuggingFace](https://huggingface.co/papers/2505.12667))| Junhao Zhuang, Tangyu Jiang, Hongbin Xu, Xuerui Qiu, Sugewud | Safe-Sora is a novel framework for embedding graphical watermarks into text-to-video generation to enhance copyright protection. The research addresses the under-explored area of graphical watermarking in video generation via diffusion models. It introduces a hierarchical coarse-to-fine adaptive matching mechanism assigning watermark patches to visually similar video regions and utilizes a 3D wavelet transform-enhanced Mamba architecture. Experiments show Safe-Sora achieves a Fréchet Video Distance of 3.77, demonstrating state-of-the-art video quality and watermark fidelity compared to existing methods. This offers AI practitioners a method for robustly embedding and extracting graphical watermarks, improving the reliability of copyright verification for AI-generated video content.  |
| Characterizing Bias: Benchmarking Large Language Models in Simplified
  versus Traditional Chinese (Read more on [arXiv](https://arxiv.org/abs/2505.22645) or [HuggingFace](https://huggingface.co/papers/2505.22645))| Allison Koenecke, Jian Kang, Jiebo Luo, Hanjia Lyu | i) The paper benchmarks Large Language Model (LLM) performance disparities when prompted in Simplified versus Traditional Chinese. ii) The research aims to investigate whether LLMs exhibit differential performance when prompted in Simplified Chinese compared to Traditional Chinese, specifically focusing on representational harms and downstream decision-making biases. iii) The study designed two benchmark tasks: regional term choice and regional name choice, auditing the performance of 11 commercial LLM services and open-source models, including those trained primarily on English, Simplified Chinese, or Traditional Chinese. iv) The analysis indicates biases in LLM responses depend on the task and prompting language; while LLMs favored Simplified Chinese in regional term choice, they favored Traditional Chinese names in regional name choice tasks. v) The finding that LLM biases are dependent on both task and prompting language indicates a need for ongoing auditing frameworks to evaluate LLM behavior across Chinese language variants.  |
| AITEE -- Agentic Tutor for Electrical Engineering (Read more on [arXiv](https://arxiv.org/abs/2505.21582) or [HuggingFace](https://huggingface.co/papers/2505.21582))| Christian Bernhardt, Alexander Bernhardt, CKnievel | i) The paper introduces AITEE, an agentic tutoring system for electrical engineering education leveraging LLMs, graph neural networks, and circuit simulation. ii) The primary research objective is to develop an agentic tutor that can provide individualized support and promote self-directed learning for electrical engineering students. iii) The methodology involves adapting circuit reconstruction processes, using graph-based similarity measures for context retrieval, Retrieval Augmented Generation (RAG), and implementing a Socratic dialogue to foster learner autonomy. iv) Experiments showed that AITEE significantly outperforms baseline approaches in domain-specific knowledge application, with medium-sized LLM models demonstrating acceptable performance; with Multi-Representation Indexing (MRI), all models except Llama 3.1 8B exhibit a performance level suggesting potential to ensure tutor-level expertise v) The results highlight the potential of agentic tutors to deliver scalable, personalized, and effective learning environments for electrical engineering education, suggesting AI practitioners can create more effective educational tools by combining LLMs with domain-specific knowledge and interactive dialogue strategies.  |
| MangaVQA and MangaLMM: A Benchmark and Specialized Model for Multimodal
  Manga Understanding (Read more on [arXiv](https://arxiv.org/abs/2505.20298) or [HuggingFace](https://huggingface.co/papers/2505.20298))| Yuki Imajuku, Atsuyuki Miyai, Shota Onohara, Kazuki Egashira, Jeonghun Baek | i) The paper introduces MangaVQA and MangaLMM for multimodal manga understanding, addressing OCR and visual question answering. ii) The primary research objective is to establish benchmarks and a specialized model for evaluating and advancing large multimodal models (LMMs) in the domain of manga understanding. iii) The methodology involves creating the MangaVQA benchmark with 526 manually constructed question-answer pairs and finetuning the Qwen2.5-VL model to create MangaLMM for joint MangaOCR and MangaVQA task handling. iv) MangaLMM achieves over 70% on the MangaOCR task and outperforms GPT-4o on MangaVQA (6.57 vs 5.76 on a scale of 1-10), while GPT-4o exhibited near-zero OCR performance. v) MangaLMM provides AI practitioners a specialized model and benchmarks for evaluating and improving LMMs' abilities in understanding multimodal content, specifically in the stylized and context-rich domain of manga.  |
| Styl3R: Instant 3D Stylized Reconstruction for Arbitrary Scenes and
  Styles (Read more on [arXiv](https://arxiv.org/abs/2505.21060) or [HuggingFace](https://huggingface.co/papers/2505.21060))| Peidong Liu, Xiang Liu, Peng Wang | Styl3R is a feed-forward network for instant 3D stylization from sparse, unposed images and a style image. The research question is how to achieve fast, multi-view consistent 3D stylization without test-time optimization. The methodology involves a dual-branch network separating structure and appearance modeling, with an identity loss adaptation for pre-training via novel view synthesis. The primary result is high-quality stylized 3D content in 0.15 seconds, achieving superior style blend and multi-view consistency. AI practitioners can leverage this efficient method for interactive applications requiring fast 3D stylization without dense inputs or per-scene optimization.  |
| Efficient Data Selection at Scale via Influence Distillation (Read more on [arXiv](https://arxiv.org/abs/2505.19051) or [HuggingFace](https://huggingface.co/papers/2505.19051))| Vahab Mirrokni, Dan Alistarh, Vincent Cohen-Addad, Mahdi Nikdan | i) The paper introduces Influence Distillation, a data selection framework leveraging second-order information to optimize training sample weighting for Large Language Models (LLMs). ii) The research aims to develop a scalable and mathematically-justified data selection method that directly optimizes for performance on a target distribution. iii) Influence Distillation uses a landmark-based approximation to efficiently compute and propagate influence scores, assigning model-specific weights to training samples for LLM fine-tuning. iv) Experiments on instruction tuning of the Tulu V2 dataset using Llama and Qwen models demonstrate that Influence Distillation matches or outperforms state-of-the-art performance while achieving up to 3.5x faster selection runtime. v) Influence Distillation provides AI/ML practitioners with an efficient method for curating training datasets, improving downstream task accuracy while reducing computational costs associated with LLM fine-tuning.  |
| First Finish Search: Efficient Test-Time Scaling in Large Language
  Models (Read more on [arXiv](https://arxiv.org/abs/2505.18149) or [HuggingFace](https://huggingface.co/papers/2505.18149))| Tanmoy Chakraborty, Ayan Sengupta, aradhye | First Finish Search (FFS) is introduced as a training-free parallel decoding strategy to improve reasoning in large language models. The research aims to enhance test-time scaling (TTS) efficiency by dynamically allocating compute during inference. FFS launches n independent samples and selects the output trace that completes first, leveraging the observed correlation between shorter trace length and correctness in reasoning tasks. Experiments with DeepSeek-R1 on the AIME datasets show FFS achieves 82.23% accuracy, a 15% improvement over its standalone accuracy. This indicates that simple TTS strategies, such as FFS, can yield remarkable performance improvements with minimal overhead at inference time by dynamically scaling the number of decoding samples based on the task to optimize for lower token usage and reduced latency. Some parts of the paper and its methodology were unclear.  |
