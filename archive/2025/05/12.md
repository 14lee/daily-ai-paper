

## Papers for 2025-05-12

| Title | Authors | Summary |
|-------|---------|---------|
| Bielik v3 Small: Technical Report (Read more on [arXiv](https://arxiv.org/abs/2505.02550) or [HuggingFace](https://huggingface.co/papers/2505.02550))| Adrian Gwoździej, Łukasz Flis, djstrong, Remek, chrisociepa | This paper introduces Bielik v3, a series of parameter-efficient (1.5B, 4.5B) generative text models optimized for the Polish language. The main objective was to demonstrate that smaller, well-optimized models can achieve performance comparable to much larger counterparts for a less-resourced language using substantially fewer computational resources. Key methodologies included depth up-scaling Qwen2.5 base models, implementing a custom Polish tokenizer (APT4) for improved token efficiency, utilizing Adaptive Learning Rate, and training on a curated 292 billion token Polish-centric corpus. The primary result shows the 4.5B parameter Bielik v3 Instruct model achieved a competitive score of 56.13 on the Open PL LLM Leaderboard (5-shot), outperforming several models 2-3 times its size. For AI practitioners, this work implies that targeted optimization, including custom tokenization and architecture scaling techniques, allows for the development of high-performing, resource-efficient models for specific languages, potentially reducing computational costs for deployment. |
| Bielik 11B v2 Technical Report (Read more on [arXiv](https://arxiv.org/abs/2505.02410) or [HuggingFace](https://huggingface.co/papers/2505.02410))| Adrian Gwoździej, Łukasz Flis, Remek, djstrong, chrisociepa | This report details Bielik 11B v2, an 11-billion parameter language model optimized for Polish, derived from Mistral 7B v0.2 using depth up-scaling and novel training methods. The primary objective was to create a state-of-the-art, computationally efficient model for Polish text processing with strong cross-lingual transferability. Methodology involved continued pre-training on a 198 billion token Polish-centric corpus, followed by Supervised Fine-Tuning and DPO-Positive alignment using custom techniques like Weighted Instruction Cross-Entropy Loss and Adaptive Learning Rate. Bielik-11B-v2 models achieve leading performance on Polish benchmarks, with v2.3-Instruct scoring 65.71 on the Open PL LLM Leaderboard, significantly outperforming its 7B predecessor and many larger models, while demonstrating robustness to quantization down to IQ2_XXS (61.34 score). For AI practitioners, Bielik 11B v2 offers a parameter-efficient (11B) model for high-quality Polish language tasks, deployable on constrained hardware due to effective quantization, serving as a benchmark for less-resourced language model development. |
| Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health
  Information (Read more on [arXiv](https://arxiv.org/abs/2505.06046) or [HuggingFace](https://huggingface.co/papers/2505.06046))| Toby Nonnenmacher, Timothy Laurence, Felix Feldman, Fan Grayson, Joshua-Harris | This paper introduces PubHealthBench to benchmark Large Language Model (LLM) knowledge of UK Government public health information. The primary objective was to assess the accuracy and potential risks of using LLMs for retrieving public health guidance. An automated pipeline generated over 8000 Multiple Choice Question Answering (MCQA) questions and a free-form response set from government documents, which were used to evaluate 24 LLMs. Key results show the best private LLMs achieve >90% accuracy in MCQA, significantly outperforming a human baseline using search engines, but no model scored above 75% in the more challenging free-form setting. For AI practitioners, this indicates that while SOTA LLMs possess strong factual recall for public health information in structured formats, deploying them for free-form response generation requires caution and potentially additional safeguards due to lower observed accuracy and hallucination risks. |
| UniVLA: Learning to Act Anywhere with Task-centric Latent Actions (Read more on [arXiv](https://arxiv.org/abs/2505.06111) or [HuggingFace](https://huggingface.co/papers/2505.06111))| Shenyuan Gao, Jisong Cai, Yanting Yang, Qingwen Bu, sundrops | UniVLA introduces a generalist vision-language-action framework enabling policy learning across diverse embodiments by deriving task-centric latent actions unsupervisedly from videos. The primary objective is to learn a unified, transferable action representation from heterogeneous video data (robot/human, varied perspectives) without requiring ground-truth action labels, addressing scalability limitations of current VLA models. Key methodology involves a two-stage latent action learning process using inverse dynamics on DINOv2 features conditioned by language to decouple task-centric actions, followed by pretraining an auto-regressive VLM on these latent actions and deploying with lightweight action decoders. UniVLA achieves state-of-the-art results, including a 95.2% average success rate on the LIBERO benchmark, significantly outperforming prior methods like OpenVLA (+18.5%) with substantially less pretraining compute (<1/20). For AI practitioners, this work presents a scalable and efficient method to train generalist robot policies by leveraging readily available, unlabeled video data, reducing dependence on annotated datasets and extensive computation. |
| G-FOCUS: Towards a Robust Method for Assessing UI Design Persuasiveness (Read more on [arXiv](https://arxiv.org/abs/2505.05026) or [HuggingFace](https://huggingface.co/papers/2505.05026))| Yejin Choi, Sumin Shim, Min Soo Kim, Jang Han Yoon, jeochris | This paper introduces WISERUI-BENCH for pairwise UI persuasiveness evaluation and G-FOCUS, a VLM reasoning strategy to improve assessment accuracy and reduce bias. The research aims to quantitatively evaluate and enhance VLM capabilities for assessing UI design persuasiveness, addressing the cost limitations of A/B testing and inherent VLM biases. Key methodology involves the WISERUI-BENCH dataset (300 UI pairs with A/B results and rationales) and the G-FOCUS inference strategy (goal extraction, difference localization, contrastive reasoning, evaluation). Results demonstrate G-FOCUS surpasses baselines in reliability; using GPT-4o, it achieved 43.33% Consistent Accuracy, a +12.66% improvement over the prior best baseline, indicating reduced bias. For AI practitioners, G-FOCUS offers a more robust automated method for comparative UI evaluation that can complement A/B testing and provide scalable preference data for aligning models towards human-preferred UI generation. |
| Sailing AI by the Stars: A Survey of Learning from Rewards in
  Post-Training and Test-Time Scaling of Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.02686) or [HuggingFace](https://huggingface.co/papers/2505.02686))| Xiaobao Wu | This survey provides a comprehensive overview of the "Learning from Rewards" paradigm used in post-training and test-time scaling of Large Language Models (LLMs). The main objective is to categorize and analyze the diverse strategies under this paradigm, detailing how reward signals guide LLM behavior across training, inference, and post-inference stages. Methodologically, the paper presents a unified conceptual framework and taxonomy, organizing techniques based on reward sources, reward model design dimensions (architecture, format, pattern, granularity), learning timing, and learning strategies (training-based/free). Key surveyed results include the successful application of techniques like RLHF and DPO for preference alignment, and the emergence of deep reasoning capabilities through methods like GRPO with rule-based rewards, as demonstrated by models like DeepSeek-R1 acquiring long Chain-of-Thoughts abilities. For AI practitioners, this survey offers a structured understanding for selecting and implementing appropriate reward-based methods to align, enhance, and scale LLMs beyond pre-training for specific tasks and desired behaviors. |
| A Preliminary Study for GPT-4o on Image Restoration (Read more on [arXiv](https://arxiv.org/abs/2505.05621) or [HuggingFace](https://huggingface.co/papers/2505.05621))| Liyuan Pan, Ruikun Zhang, Yan Yang, Hao Yang | This paper presents the first systematic evaluation of OpenAI's GPT-4o for diverse image restoration tasks. The primary objective is to investigate GPT-4o's capabilities and limitations in restoring degraded images across various domains like dehazing, deraining, and low-light enhancement. Methodology involves quantitative analysis using PSNR and CLIP-IQA metrics across eight tasks, qualitative assessment, failure case analysis, and proposing a baseline post-processing network using GPT-4o outputs as visual priors. Results show GPT-4o generates visually appealing outputs (high CLIP-IQA) but suffers poor pixel-level fidelity (e.g., PSNR often lower than degraded input, 12.89 dB vs. 21.58 dB in one example); however, using its outputs as priors significantly boosted a baseline network's performance (e.g., O-Haze PSNR improved from 20.86 to 22.08). For AI practitioners, the key implication is that GPT-4o outputs, despite structural inaccuracies, can serve as effective visual priors when integrated into pipelines with lightweight networks to enhance existing image restoration methods' perceptual quality and structural fidelity. |
