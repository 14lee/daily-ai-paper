

## Papers for 2025-05-30

| Title | Authors | Summary |
|-------|---------|---------|
| Table-R1: Inference-Time Scaling for Table Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.23621) or [HuggingFace](https://huggingface.co/papers/2505.23621))| Arman Cohan, Lyuhao Chen, Zheyuan Yang, yilunzhao | i) This paper explores inference-time scaling for table reasoning tasks using post-training methods. ii) The research question focuses on enabling inference-time scaling for table reasoning by evaluating distillation from frontier model reasoning traces and reinforcement learning with verifiable rewards (RLVR). iii) The methodology involves fine-tuning LLMs on a created dataset of reasoning traces generated by DeepSeek-R1 and applying the GRPO algorithm with task-specific verifiable reward functions. iv) Table-R1-Zero models match or exceed the performance of GPT-4.1 and DeepSeek-R1 using only a 7B-parameter LLM and also generalize well to out-of-domain datasets. v) The principal implication for AI practitioners is the demonstration that RLVR offers improved performance and generalization compared to distillation for table reasoning, suggesting a viable approach to enhancing LLMs for structured data tasks with inference-time scaling. |
| VF-Eval: Evaluating Multimodal LLMs for Generating Feedback on AIGC
  Videos (Read more on [arXiv](https://arxiv.org/abs/2505.23693) or [HuggingFace](https://huggingface.co/papers/2505.23693))| Yilun Zhao, Guo Gan, entropyhu, songtingyu | i) The paper introduces VF-EVAL, a new benchmark for evaluating multimodal large language models (MLLMs) in their ability to generate reliable feedback on AI-generated content (AIGC) videos. ii) The research aims to comprehensively assess MLLMs' capabilities in tasks such as coherence validation, error awareness, error type detection, and reasoning evaluation when applied to AIGC videos. iii) The methodology involves evaluating 13 frontier MLLMs, including GPT-4.1, on the newly proposed VF-EVAL benchmark, which includes four tasks designed to assess alignment, feedback quality, and commonsense reasoning. iv) Results show that even the best-performing model, GPT-4.1, struggles to achieve consistently high performance across all tasks, and REPROMPT experiments indicate potential quality enhancements through aligning MLLM feedback with human preferences, while overall accuracy metrics are found in Table 3. v) The primary implication for AI practitioners is the identification of current limitations in MLLMs' ability to accurately interpret and provide feedback on AIGC videos, suggesting a need for incorporating auxiliary methods like computer vision techniques to improve feedback generation pipelines.  |
| The Climb Carves Wisdom Deeper Than the Summit: On the Noisy Rewards in
  Learning to Reason (Read more on [arXiv](https://arxiv.org/abs/2505.22653) or [HuggingFace](https://huggingface.co/papers/2505.22653))| Rui Yan, Zhanhui Kang, Xingwu Sun, Ang Lv, Ruobing-Xie | i) This paper investigates the impact of noisy rewards on post-training large language models (LLMs) for reasoning tasks using reinforcement learning (RL). ii) The research question explores the LLMs' robustness to reward noise in scenarios involving reward models. iii) The methodology involves introducing reward noise by randomly flipping the reward function's outputs in math tasks and using Reasoning Pattern Reward (RPR) without verifying the correctness of answers. iv) A Qwen-2.5-7B model, when trained with a 40% reward flip rate on math tasks, achieved a peak accuracy of 72%, close to the 75.85% achieved with noiseless rewards. v) The principal implication for AI practitioners is that LLMs exhibit robustness to reward noise, and rewarding reasoning patterns can calibrate noisy reward models, suggesting avenues for improving pre-training and post-training techniques.  |
| Spatial-MLLM: Boosting MLLM Capabilities in Visual-based Spatial
  Intelligence (Read more on [arXiv](https://arxiv.org/abs/2505.23747) or [HuggingFace](https://huggingface.co/papers/2505.23747))| Yueqi Duan, Yi-Hsin Hung, Fangfu Liu, Diankun Wu | i) The paper introduces Spatial-MLLM, a novel framework enhancing visual-based spatial intelligence in video Multimodal Large Language Models (MLLMs) through dual-encoder architecture and space-aware frame sampling. ii) The research objective is to improve the spatial reasoning capabilities of video MLLMs from purely 2D observations without relying on additional 3D or 2.5D data. iii) The methodology involves a dual-encoder architecture comprising a 2D visual encoder for semantic features and a spatial encoder initialized from a feed-forward visual geometry model for 3D structure features, combined with a space-aware frame sampling strategy. iv) The Spatial-MLLM achieves state-of-the-art performance on VSI-Bench, outperforming other open-source and proprietary models including Gemini-1.5 Pro on average accuracy. v) AI practitioners can leverage the Spatial-MLLM architecture and space-aware frame sampling strategy to improve the performance of video MLLMs on spatial reasoning tasks, enabling more effective scene understanding and potentially reducing the reliance on computationally expensive 3D data inputs.  |
| ZeroGUI: Automating Online GUI Learning at Zero Human Cost (Read more on [arXiv](https://arxiv.org/abs/2505.23762) or [HuggingFace](https://huggingface.co/papers/2505.23762))| Yue Yu, Xuan Dong, Shi Liu, Shiqian Su, cyyang822 | ZeroGUI introduces an online learning framework for GUI agents, automating task generation and reward estimation. The paper addresses the limitations of offline GUI agent training by using VLMs for task generation and reward assignment. ZeroGUI employs a two-stage online reinforcement learning approach for continuous interaction and learning in GUI environments. Experiments show ZeroGUI improves performance on OSWorld and AndroidLab, with ZeroGUI-Aguvis-7B achieving a 63% relative improvement on OSWorld. The primary implication is that scalable GUI agent training can be automated without human annotation, reducing development costs.  |
| D-AR: Diffusion via Autoregressive Models (Read more on [arXiv](https://arxiv.org/abs/2505.23660) or [HuggingFace](https://huggingface.co/papers/2505.23660))| mikeshou, sebgao | i) This paper introduces D-AR, a framework recasting image diffusion as autoregressive next-token prediction. ii) The main research objective is to bridge the gap between diffusion models and autoregressive models for visual generation while adhering to the standard next-token prediction paradigm. iii) The key methodology involves a coarse-to-fine sequential diffusion tokenizer to convert images into discrete tokens, enabling autoregressive modeling without modifying underlying designs. iv) On ImageNet, D-AR achieves 2.09 FID using a 775M Llama backbone with 256 discrete tokens. v) D-AR enables fast inference with KV cache, provides consistent previews during generation, and supports zero-shot layout-controlled synthesis, offering AI practitioners a unified autoregressive architecture for visual synthesis compatible with large language models.  |
| Satori-SWE: Evolutionary Test-Time Scaling for Sample-Efficient Software
  Engineering (Read more on [arXiv](https://arxiv.org/abs/2505.23604) or [HuggingFace](https://huggingface.co/papers/2505.23604))| Subhro Das, Zhenting Qi, Delin Chen, Guangtao Zeng, maohaos2 | i) The paper introduces Evolutionary Test-Time Scaling (EvoScale), a sample-efficient method to improve language model performance on software engineering tasks by iteratively refining code generation. ii) The research aims to address the challenge of sample inefficiency in test-time scaling for software engineering, particularly with smaller language models. iii) EvoScale uses an evolutionary approach with iterative selection and mutation of code patches, incorporating reinforcement learning to enable self-evolution without external verifiers at inference. iv) Evaluated on SWE-Bench-Verified, a 32B model (Satori-SWE-32B) using EvoScale achieved performance comparable to models exceeding 100B parameters using significantly fewer samples. v) This technique offers AI practitioners a method to improve the performance of smaller, more computationally efficient language models for complex software engineering tasks, potentially reducing reliance on large-scale models.  |
| VideoReasonBench: Can MLLMs Perform Vision-Centric Complex Video
  Reasoning? (Read more on [arXiv](https://arxiv.org/abs/2505.23359) or [HuggingFace](https://huggingface.co/papers/2505.23359))| Lin Sui, Yi Liu, Haoning Wu, Yuanxin Liu, RUBBISHLIKE | i) The paper introduces VIDEOREASONBENCH, a new benchmark for evaluating vision-centric complex video reasoning capabilities in multimodal large language models (MLLMs). ii) The primary objective is to assess if MLLMs can effectively perform vision-centric complex video reasoning, particularly recalling visual information, inferring latent states, and predicting future states. iii) The methodology involves constructing a dataset of videos depicting fine-grained operations on latent states, creating corresponding questions with varying reasoning skills, and comprehensively evaluating 18 state-of-the-art MLLMs. iv) Results show that most MLLMs perform poorly, with GPT-4o achieving only 6.9% accuracy, while the thinking-enhanced Gemini-2.5-Pro achieves 56.0% accuracy, indicating significant disparity in video reasoning skills. v) For AI practitioners, the concerning deficiency of most SOTA MLLMs and higher reasoning depth and visual content reliance indicates a need to improve MLLM architectures to address the requirements of vision-centric complex video reasoning to improve performance in complex tasks.  |
| AnySplat: Feed-forward 3D Gaussian Splatting from Unconstrained Views (Read more on [arXiv](https://arxiv.org/abs/2505.23716) or [HuggingFace](https://huggingface.co/papers/2505.23716))| Kerui Ren, Tao Lu, Linning Xu, Lihan Jiang, matthewmao | AnySplat is a feed-forward network for novel-view synthesis from uncalibrated multi-view image collections by predicting 3D Gaussian primitives and camera parameters. The research aims to develop a feed-forward model for 3D scene reconstruction and novel view synthesis from uncalibrated multi-view images without pose annotations or per-scene optimization. The methodology involves a geometry transformer to encode images, a differentiable voxelization module for efficient Gaussian primitive processing, and self-supervised knowledge distillation from a pre-trained VGGT model. Experiments show AnySplat achieves comparable or superior novel view synthesis quality to pose-aware baselines and surpasses pose-free methods, demonstrated by achieving 23.09 dB PSNR with 32 input views on the VRNeRF dataset while significantly reducing rendering latency. The unified, compute-efficient model presents a practical approach for AI practitioners seeking real-time novel-view synthesis in unconstrained capture settings by eliminating the need for precise camera calibration and computationally intensive optimization.  |
| Are Reasoning Models More Prone to Hallucination? (Read more on [arXiv](https://arxiv.org/abs/2505.23646) or [HuggingFace](https://huggingface.co/papers/2505.23646))| Junfeng Fang, Jianhui Chen, Yanxu Chen, Yantao Liu, Zijun Yao | i) This paper investigates the hallucination propensities of Large Reasoning Models (LRMs) compared to base models. ii) The primary research question addresses whether incorporating reasoning capabilities in LRMs leads to increased or decreased hallucination in fact-seeking tasks. iii) The methodology includes evaluating LRMs across factuality benchmarks (SimpleQA, TriviaQA) and analyzing cognitive behaviors like flaw repetition and think-answer mismatch, alongside probing internal model uncertainty. iv) Results indicate that SFT+RL trained LRMs reduce hallucination (e.g., DeepSeek-R1 achieved 28.5% accuracy on SimpleQA), while RL-only and SFT-only trained LRMs are more prone to hallucination and exhibit mis-calibrated uncertainty. v) AI practitioners should consider the post-training pipeline, specifically employing both supervised fine-tuning and verifiable reward reinforcement learning to develop factual and reliable LRMs, and to be aware of potential uncertainty corruption in RL-only or SFT-only training.  |
| cadrille: Multi-modal CAD Reconstruction with Online Reinforcement
  Learning (Read more on [arXiv](https://arxiv.org/abs/2505.22914) or [HuggingFace](https://huggingface.co/papers/2505.22914))| Ilya Zisman, Alexander Nikulin, Denis Tarasov, Maksim Kolodiazhnyi, zhemchuzhnikov | cadrille introduces a multi-modal CAD reconstruction model leveraging vision-language models and reinforcement learning. The research aims to improve CAD reconstruction by processing point clouds, images, and text simultaneously. The methodology involves supervised fine-tuning (SFT) on procedurally generated data followed by reinforcement learning (RL) fine-tuning using online feedback via Group Relative Preference Optimization (GRPO). Results show that cadrille outperforms existing methods, achieving state-of-the-art on multiple CAD datasets; specifically, RL fine-tuning reduces the invalidity ratio to below 0.2% on real-world CC3D datasets. This suggests AI practitioners can leverage online RL with VLMs to enhance CAD reconstruction and improve the robustness and validity of generated models.  |
| Multi-Domain Explainability of Preferences (Read more on [arXiv](https://arxiv.org/abs/2505.20088) or [HuggingFace](https://huggingface.co/papers/2505.20088))| Roi Reichart, Liat Ein-Dor, Nitay Calderon | i) The paper introduces an automated method for concept-based explainability of preferences across multiple domains using Large Language Models (LLMs). ii) The research aims to generate local and global concept-based explanations for preference mechanisms, including human preference, LLM-as-a-Judge, and reward models. iii) The methodology involves using an LLM for concept discovery, representing examples as concept vectors, and modeling relationships between concepts and preferences with a hierarchical multi-domain regression (HMDR) model. iv) The method achieves strong preference prediction performance and explanation quality across eight datasets and twelve mechanisms; prompting LLMs with concepts from LaaJ explanations yields responses that those judges consistently prefer. v) The principal implication for AI practitioners is a new paradigm for explainability in the era of LLMs, providing tools to better understand and guide preference mechanisms in AI alignment and evaluation.  |
| UniRL: Self-Improving Unified Multimodal Models via Supervised and
  Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2505.23380) or [HuggingFace](https://huggingface.co/papers/2505.23380))| Mike Zheng Shou, Zhenheng Yang, Weijia Mao | i) UniRL introduces a self-improving post-training method for unified multimodal models using supervised fine-tuning (SFT) and Group Relative Policy Optimization (GRPO). ii) The research aims to enhance both image generation and understanding capabilities of unified multimodal models without relying on external image data. iii) The methodology involves constructing prompts and QA pairs, using the model to generate images, and then using these images for training in each iteration via SFT and GRPO. iv) Evaluated on Show-o and Janus, UniRL achieves a GenEval score of 0.77 for Show-o and 0.65 for Janus after post-training, improving both generation and understanding. v) UniRL offers AI practitioners a method to improve unified multimodal models with reduced data requirements, focusing on balancing generation and understanding tasks, potentially reducing task imbalance and facilitating efficient model optimization.  |
| SWE-bench Goes Live! (Read more on [arXiv](https://arxiv.org/abs/2505.23419) or [HuggingFace](https://huggingface.co/papers/2505.23419))| Bowen Li, Yu Kang, Chaoyun Zhang, Shilin He, Linghao Zhang | i) SWE-bench-Live is introduced as a continuously updated benchmark for evaluating large language models (LLMs) on real-world software issue resolution tasks. ii) The research objective is to address the limitations of static software engineering benchmarks, such as data staleness, limited repository diversity, and manual environment setup. iii) The methodology involves an automated curation pipeline, REPOLAUNCH, for creating Docker-based execution environments and validating issue-pull request pairs. iv) Evaluation of agent frameworks on SWE-bench-Live reveals a resolved rate of 19.25% achieved by OpenHands with Claude 3.7 Sonnet, contrasting with higher performance on SWE-bench Verified (43.20%) under identical conditions. v) SWE-bench-Live facilitates rigorous and contamination-resistant evaluation of LLMs and agents in dynamic, real-world software development settings, underscoring the importance of up-to-date benchmarks for measuring true model generalization for AI practitioners.  |
| Train Sparse Autoencoders Efficiently by Utilizing Features Correlation (Read more on [arXiv](https://arxiv.org/abs/2505.22255) or [HuggingFace](https://huggingface.co/papers/2505.22255))| Nikita Balagansky, Daniil Gavrilov, Daniil Laptev, Yaroslav Aksenov, Vadim Kurochkin | i) This paper introduces KronSAE, an efficient sparse autoencoder (SAE) architecture leveraging Kronecker factorization and a differentiable AND-like gating mechanism (mAND) to reduce computational overhead. ii) The research aims to address the scalability bottleneck in training SAEs, specifically the computationally intensive encoder projection. iii) KronSAE factorizes the latent representation via Kronecker product decomposition and employs a novel mAND activation function. iv) Experiments on Qwen-1.5B show that KronSAE improves explained variance by up to 4.3% with 54.7% fewer parameters under a 100M token budget compared to TopK SAE, while matching or exceeding TopK baseline reconstruction quality with 46.1% fewer parameters at 1000M tokens. v) KronSAE offers AI practitioners a more scalable approach to training SAEs for interpretability by reducing encoder cost and improving feature disentanglement, enabling efficient analysis of large language model activations.  |
| Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV
  Cache and Parallel Decoding (Read more on [arXiv](https://arxiv.org/abs/2505.22618) or [HuggingFace](https://huggingface.co/papers/2505.22618))| Shizhe Diao, Hao Zhang, Chengyue Wu, zhijianliu, Cauthyyy | i) The paper introduces Fast-dLLM, a method for accelerating diffusion-based language models (dLLMs) without retraining by incorporating KV Cache and parallel decoding. ii) The research aims to improve the inference speed of open-sourced dLLMs, which typically lag behind autoregressive models due to the absence of KV Cache and quality degradation during parallel token generation. iii) The methodology involves a block-wise approximate KV Cache mechanism and a confidence-aware parallel decoding strategy to mitigate token dependency violations. iv) Experimental results demonstrate up to 27.6x throughput improvement on LLaDA and Dream models across multiple benchmarks, closing the performance gap with autoregressive models. v) The implementation of Fast-dLLM provides AI practitioners with a practical, training-free solution to accelerate dLLM inference, enhancing their applicability in real-world deployments.  |
| Muddit: Liberating Generation Beyond Text-to-Image with a Unified
  Discrete Diffusion Model (Read more on [arXiv](https://arxiv.org/abs/2505.23606) or [HuggingFace](https://huggingface.co/papers/2505.23606))| Kaidong Yu, Wenhao Chai, Zhuoran Zhao, BryanW, QingyuShi | i) Muddit introduces a unified discrete diffusion transformer for fast, parallel generation across text and image modalities. ii) The paper aims to develop a unified generative model capable of handling diverse tasks across modalities within a single architecture. iii) The methodology involves integrating visual priors from a pretrained text-to-image backbone with a lightweight text decoder in a MaskGIT-style discrete diffusion transformer. iv) Muddit achieves a strong overall accuracy of 0.61 on the GenEval benchmark, outperforming previous discrete diffusion models, while utilizing only 1B parameters. v) This work suggests that purely discrete diffusion, when equipped with strong visual priors, can serve as a scalable and effective backbone for unified generation, offering AI practitioners an alternative to autoregressive models for multimodal tasks.  |
| LoRAShop: Training-Free Multi-Concept Image Generation and Editing with
  Rectified Flow Transformers (Read more on [arXiv](https://arxiv.org/abs/2505.23758) or [HuggingFace](https://huggingface.co/papers/2505.23758))| Pinar Yanardag, Hidir Yesiltepe, ydalva | LoRAShop introduces a training-free framework for multi-concept image generation and editing using rectified flow transformers. The research aims to enable the simultaneous use of multiple LoRA adapters for image synthesis and manipulation without additional training or auxiliary inputs. LoRAShop extracts subject priors by analyzing feature interaction patterns in rectified flow models and blends LoRA weights within concept-specific regions. Experiments demonstrate that LoRAShop delivers improved identity preservation compared to baselines and blends multiple concepts directly into the diffusion latent without retraining. LoRAShop enables region-controlled personalized image editing, enhancing creative workflows and facilitating visual storytelling for AI practitioners.  |
| On-Policy RL with Optimal Reward Baseline (Read more on [arXiv](https://arxiv.org/abs/2505.23585) or [HuggingFace](https://huggingface.co/papers/2505.23585))| Zewen Chi, Shaohan Huang, Xun Wu, Li Dong, Yaru Hao | The paper introduces On-Policy RL with Optimal reward baseline (OPO), a novel reinforcement learning algorithm. The research aims to improve training stability and exploration in RL for large language model alignment by minimizing gradient variance. OPO employs exact on-policy training and derives an optimal reward baseline that theoretically minimizes gradient variance. Experiments on mathematical reasoning benchmarks show OPO achieves superior performance and training stability without additional models or regularization, demonstrating lower policy shifts and higher output entropy. OPO consistently achieves higher performance with more stable training dynamics compared to GRPO. These results suggest AI practitioners can leverage OPO for more stable and effective reinforcement learning in tasks such as large language model alignment and reasoning.  |
| GeoDrive: 3D Geometry-Informed Driving World Model with Precise Action
  Control (Read more on [arXiv](https://arxiv.org/abs/2505.22421) or [HuggingFace](https://huggingface.co/papers/2505.22421))| Kun Zhan, Xueyang Zhang, Wenzhao Zheng, wangyida, antonio-c | i) The paper introduces GeoDrive, a driving world model that integrates 3D geometry to enhance action controllability and spatial understanding. ii) The research aims to develop a controllable driving world model that maintains 3D geometric consistency and allows for precise ego-vehicle trajectory control. iii) The methodology involves extracting a 3D representation from monocular input, rendering 2D views along specified trajectories, and using a dynamic editing module for enhanced dynamic modeling. iv) Experiments show GeoDrive reduces trajectory following errors by 42% compared to the Vista model, while also achieving improvements in video quality metrics such as LPIPS, PSNR, SSIM, FID, and FVD. v) The principal implication for AI practitioners is a new approach to building driving world models with improved action controllability and spatial awareness, leading to more realistic and reliable scene modeling for autonomous driving systems.  |
| ATLAS: Learning to Optimally Memorize the Context at Test Time (Read more on [arXiv](https://arxiv.org/abs/2505.23735) or [HuggingFace](https://huggingface.co/papers/2505.23735))| Yuan Deng, Majid Daliri, Praneeth Kacham, Zeman Li, Ali Behrouz | i) The paper introduces ATLAS, a new long-term memory module for improving context memorization in recurrent neural networks. ii) The research aims to address limitations in existing recurrent models related to memory capacity, online update strategies, and memory management expressiveness. iii) The methodology involves developing a sliding window update rule (Omega rule) and architectures utilizing polynomial feature mappings and a Muon optimizer. iv) ATLAS achieves +80% accuracy in the 10M context length of BABILong benchmark and outperforms Transformers and linear recurrent models on language modeling and common-sense reasoning tasks. v) The ATLAS architecture provides AI practitioners with a scalable approach for enhancing long-context understanding in tasks such as language modeling and reasoning, by addressing memory limitations and optimization challenges in recurrent networks.  |
| KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction (Read more on [arXiv](https://arxiv.org/abs/2505.23416) or [HuggingFace](https://huggingface.co/papers/2505.23416))| Sangdoo Yun, Jae W. Lee, Sangwoo Kwon, jusjinuk, Jang-Hyun | KVzip introduces a query-agnostic KV cache eviction method for transformer-based LLMs to improve inference efficiency. The research objective is to optimize a reusable compressed KV cache by quantifying the importance of KV pairs based on their contribution to context reconstruction via an LLM forward pass and attention scores. The methodology involves teacher-forced decoding to simulate context reconstruction, assigning importance scores to KV pairs based on maximum attention scores, and evicting lower-importance pairs. Experiments show KVzip reduces KV cache size by 3-4× and FlashAttention decoding latency by approximately 2×, with negligible performance loss across various tasks including models like LLaMA3.1-8B and context lengths up to 170K tokens. KVzip's ability to reduce KV cache size significantly while maintaining performance offers AI practitioners a practical approach to alleviate memory constraints and improve the efficiency of deploying long-context LLMs.  |
| SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents (Read more on [arXiv](https://arxiv.org/abs/2505.23559) or [HuggingFace](https://huggingface.co/papers/2505.23559))| Ziheng Qi, Jiaxun Zhang, HakHan, m-serious, Leozkl | i) The paper introduces SafeScientist, an AI scientist framework designed to enhance safety and ethical responsibility in AI-driven scientific exploration. ii) The main objective is to address ethical and safety concerns raised by large language model (LLM) agents in scientific discovery automation. iii) The methodology involves integrating multiple defensive mechanisms including prompt monitoring, agent-collaboration monitoring, tool-use monitoring, and an ethical reviewer component. iv) Experiments demonstrate that SafeScientist improves safety performance by 35% compared to traditional AI scientist frameworks. v) The principal implication is a framework and benchmark to address and mitigate ethical and safety risks when deploying LLM agents in scientific research workflows.  |
| ToMAP: Training Opponent-Aware LLM Persuaders with Theory of Mind (Read more on [arXiv](https://arxiv.org/abs/2505.22961) or [HuggingFace](https://huggingface.co/papers/2505.22961))| Jiaxuan You, m-serious, HakHan | i) The paper introduces ToMAP, a framework for training more effective LLM persuaders by integrating theory of mind (ToM) modules. ii) The research aims to improve LLM persuaders by enabling them to better model and reason about their opponent's mental state during conversations. iii) The methodology incorporates a counterclaim predictor and an opponent attitude predictor, leveraging reinforcement learning to train the LLM persuader. iv) Experiments show that the ToMAP persuader, with only 3B parameters, outperforms larger models like GPT-4o, achieving a 39.4% relative gain in persuasiveness across diverse corpora. v) ToMAP allows AI practitioners to create more sophisticated and adaptable dialogue agents that can dynamically respond to opponent's viewpoints, demonstrating the potential of incorporating ToM in persuasive language agents.  |
| Uni-Instruct: One-step Diffusion Model through Unified Diffusion
  Divergence Instruction (Read more on [arXiv](https://arxiv.org/abs/2505.20755) or [HuggingFace](https://huggingface.co/papers/2505.20755))| Weijian Luo, Debing Zhang, Colin Zhang, Weimin Bai, smallAI | i) The paper introduces Uni-Instruct, a novel framework for one-step diffusion model distillation. ii) The research aims to unify existing one-step diffusion distillation methods within a theoretical framework based on f-divergence minimization and improve generation performance. iii) The methodology involves a diffusion expansion theory for f-divergences and derivation of a tractable loss function with equivalent parameter gradients. iv) Uni-Instruct achieves a new SoTA on ImageNet64 × 64 conditional generation with an FID of 1.02, outperforming its 79-step teacher diffusion model, and attains an FID of 1.46 for unconditional CIFAR10 generation. v) AI practitioners can use Uni-Instruct to achieve improved performance in one-step diffusion models for image generation tasks due to the method's unified framework and state-of-the-art results.  |
| PatientSim: A Persona-Driven Simulator for Realistic Doctor-Patient
  Interactions (Read more on [arXiv](https://arxiv.org/abs/2505.17818) or [HuggingFace](https://huggingface.co/papers/2505.17818))| Jae Ho Sohn, Jiho Kim, Seongsu Bae, Hyunseung Chung, Daeun Kyung | i) PatientSim introduces a persona-driven patient simulator for evaluating doctor LLMs in realistic, multi-turn interactions. ii) The primary objective is to create a patient simulator capable of generating diverse patient personas grounded in clinical scenarios, thereby addressing limitations of existing simulators. iii) The methodology involves constructing clinical profiles from MIMIC-ED and MIMIC-IV datasets and defining patient personas along four axes: personality, language proficiency, medical history recall, and cognitive confusion. iv) Evaluation across eight LLMs revealed that Llama 3.3 demonstrated the best factual accuracy and persona consistency, validated by clinicians with an average quality score of 3.89 out of 4. v) PatientSim offers AI practitioners a customizable, open-source platform for reproducible and scalable evaluation of medical dialogue systems, facilitating privacy-compliant testing and educational applications.  |
| DeepTheorem: Advancing LLM Reasoning for Theorem Proving Through Natural
  Language and Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2505.23754) or [HuggingFace](https://huggingface.co/papers/2505.23754))| Qiuzhi Liu, Tian Liang, Zhiwei He, Jiahao Xu, Ziyin Zhang | DeepTheorem introduces a new framework for informal theorem proving using natural language and reinforcement learning. The research aims to improve LLM's mathematical reasoning abilities by creating a large-scale benchmark dataset. The methodology uses a novel reinforcement learning strategy (RL-Zero) and a dataset of 121K high-quality informal mathematical theorems and proofs. Experiments show DeepTheorem significantly improves LLM theorem-proving performance, achieving state-of-the-art results; specifically, RL-Zero training on a 7B model with the DeepTheorem dataset achieves strong performance. The findings imply that DeepTheorem has potential to advance automated informal theorem proving and mathematical exploration for AI practitioners by fundamentally transforming automated informal theorem proving and mathematical exploration.  |
| MAGREF: Masked Guidance for Any-Reference Video Generation (Read more on [arXiv](https://arxiv.org/abs/2505.23742) or [HuggingFace](https://huggingface.co/papers/2505.23742))| Jacob Zhiyuan Fang, Yuanyang Yin, Xun Guo, Yufan Deng, BestWishYsh | i) MAGREF is a novel video generation framework utilizing masked guidance for coherent multi-subject video synthesis from reference images and text prompts. ii) The main objective is to achieve stable and high-quality video generation that preserves multi-subject consistency and adheres to detailed textual instructions, addressing challenges in existing multi-subject video generation methods. iii) The methodology introduces a region-aware dynamic masking mechanism for flexible subject inference and pixel-wise channel concatenation for improved appearance feature preservation, trained on a self-curated video dataset. iv) MAGREF achieves state-of-the-art performance, establishing a new state-of-the-art in Face Similarity (FaceSim) at 0.567 for single-ID and 0.581 for multi-subject test cases. v) MAGREF offers AI practitioners a scalable and controllable method for high-fidelity multi-subject video synthesis, demonstrating effective domain adaptation and accelerated training convergence without substantial architectural modifications to pre-trained models.  |
| FAMA: The First Large-Scale Open-Science Speech Foundation Model for
  English and Italian (Read more on [arXiv](https://arxiv.org/abs/2505.22759) or [HuggingFace](https://huggingface.co/papers/2505.22759))| Mauro Cettolo, Alessio Brutti, Luisa Bentivogli, Marco Gaido, Sara Papi | FAMA introduces open-science speech foundation models for English and Italian. The paper addresses the limited accessibility of training data and codebases in existing SFMs.  It trains models on 150k+ hours of open-source speech data, including a new 16k-hour dataset of cleaned and pseudo-labeled speech.  FAMA achieves competitive performance compared to existing SFMs while being up to 8 times faster. This allows AI practitioners to have fully accessible resources, to enable better reproducibility.  |
| Afterburner: Reinforcement Learning Facilitates Self-Improving Code
  Efficiency Optimization (Read more on [arXiv](https://arxiv.org/abs/2505.23387) or [HuggingFace](https://huggingface.co/papers/2505.23387))| Dong Huang, Yuhao Qing, Yue Liu, Luu Tuan Tuan, Mingzhe Du | i) The paper introduces Afterburner, an iterative optimization framework leveraging reinforcement learning to improve code efficiency generated by LLMs. ii) The research aims to enhance the computational efficiency of LLM-generated code through test-time iterative refinement. iii) The methodology involves a closed-loop system with Afterburner iteratively refining code based on performance feedback from the Monolith execution sandbox, explored using Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Group Relative Policy Optimization (GRPO). iv) Experiments show that GRPO boosts PASS @1 from 47% to 62% and increases the likelihood of outperforming human submissions in efficiency from 31% to 45% on Venus. v) Reinforcement learning, specifically GRPO, is revealed as a powerful approach for training LLMs to self-improve code efficiency, enabling effective test-time code optimization for AI practitioners.  |
| Differentiable Solver Search for Fast Diffusion Sampling (Read more on [arXiv](https://arxiv.org/abs/2505.21114) or [HuggingFace](https://huggingface.co/papers/2505.21114))| Xubin Li, Qipeng zhang, Zexian Li, sthuihui, wangsssssss | i) This paper introduces a differentiable solver search algorithm to optimize sampling efficiency in diffusion models. ii) The main objective is to identify optimal timesteps and solver coefficients for accelerating reverse-diffusion solving without retraining. iii) The methodology involves defining a compact search space of time steps and solver coefficients and then using a differentiable search algorithm to optimize these parameters. iv) The proposed method achieves a FID score of 2.33 on the DDPM model, DiT-XL/2, with only 10 steps, which beats the performance of traditional solvers. v) AI practitioners can leverage this method to enhance the efficiency of pre-trained diffusion models for faster image generation.  |
| To Trust Or Not To Trust Your Vision-Language Model's Prediction (Read more on [arXiv](https://arxiv.org/abs/2505.23745) or [HuggingFace](https://huggingface.co/papers/2505.23745))| Olga Fink, Eleni Chatzi, Jian Liang, Moru Liu, hdong51 | Vision-Language Models (VLMs) often yield confident yet incorrect predictions, especially in safety-critical domains. The research addresses the critical challenge of estimating when VLM predictions can be trusted without retraining. TrustVLM, a training-free framework, is introduced, leveraging image embedding space and a novel confidence-scoring function based on image-to-text and image-to-image similarity. The framework was evaluated across 17 datasets, 4 architectures, and 2 VLMs and demonstrated state-of-the-art performance, with improvements of up to 51.87% in AURC, 9.14% in AUROC, and 32.42% in FPR95 compared to existing baselines. TrustVLM enables safer deployment of VLMs by providing a more reliable method for assessing prediction confidence.  |
| UniTEX: Universal High Fidelity Generative Texturing for 3D Shapes (Read more on [arXiv](https://arxiv.org/abs/2505.23253) or [HuggingFace](https://huggingface.co/papers/2505.23253))| Hongyu Yan, Rui Chen, Xiao Chen, Kunming Luo, Yixun Liang | i) UniTEX introduces a two-stage framework for generating high-quality 3D textures by directly operating in a 3D functional space via Texture Functions (TFs). ii) The research aims to bypass UV mapping limitations in 3D texture generation by predicting TFs from images and geometry using a transformer-based Large Texturing Model (LTM). iii) The methodology involves lifting texture generation into 3D space using TFs, predicting these TFs with a transformer-based LTM, and employing a LoRA-based strategy to adapt large-scale Diffusion Transformers (DiTs). iv) Experiments show UniTEX achieves superior visual quality and texture integrity compared to existing approaches, reflected in a 65.91% user preference score, demonstrating a generalizable solution for automated 3D texture generation. v) UniTEX offers AI practitioners a scalable solution for automated 3D texture generation by eliminating UV mapping dependencies, enabling more robust and consistent texture creation across diverse mesh topologies.  |
| CXReasonBench: A Benchmark for Evaluating Structured Diagnostic
  Reasoning in Chest X-rays (Read more on [arXiv](https://arxiv.org/abs/2505.18087) or [HuggingFace](https://huggingface.co/papers/2505.18087))| Hyuk Gi Hong, Hangyul Yoon, Jung-Oh Lee, Geon Choi, ttumyche | i) CXReasonBench, consisting of CheXStruct and CXReasonBench, is introduced to evaluate structured diagnostic reasoning in chest X-rays using MIMIC-CXR-JPG. ii) The objective is to assess the ability of Large Vision-Language Models (LVLMs) to perform clinically valid reasoning steps in chest X-ray diagnosis. iii) CheXStruct automatically derives intermediate reasoning steps from chest X-rays, including anatomical segmentation, landmark identification, diagnostic measurements, index computation, and clinical threshold application; CXReasonBench utilizes this pipeline for model evaluation. iv) CXReasonBench, comprising 18,988 QA pairs across 12 diagnostic tasks and 1,200 cases, reveals that current LVLMs struggle with structured reasoning and generalization in tasks requiring both abstract knowledge and visual grounding, with the strongest models rarely reaching beyond Stage 2 reasoning. v) The primary implication for AI practitioners is the identification of a critical gap in the ability of current LVLMs to integrate abstract diagnostic knowledge with anatomically grounded visual interpretation, highlighting a need for research focusing on improved visual grounding and structured reasoning for medical image analysis.  |
| Breaking Down Video LLM Benchmarks: Knowledge, Spatial Perception, or
  True Temporal Understanding? (Read more on [arXiv](https://arxiv.org/abs/2505.14321) or [HuggingFace](https://huggingface.co/papers/2505.14321))| Simon Wang, Zizhen Wang, Shiyu Li, Zhengfeng Lai, Bo Feng | i) This paper presents VBenchComp, a framework to dissect video Large Language Model (LLM) benchmarks. ii) The primary objective is to categorize video QA benchmark questions to isolate temporal reasoning ability from language priors and static visual understanding. iii) The methodology involves an automated pipeline that classifies questions into LLM-Answerable, Semantic, and Temporal categories based on model performance with/without video and after frame shuffling. iv) Analysis reveals models can achieve up to 50% accuracy on VideoMME and NEXT-QA without video input using GPT-4o, and shuffling frames often does not significantly affect performance; this suggests reliance on language priors or static semantic content. v) The key implication is that AI practitioners should use VBenchComp to refine video LLM benchmarks, focusing on temporal questions to better evaluate models' true video understanding capabilities.  |
| Differential Information: An Information-Theoretic Perspective on
  Preference Optimization (Read more on [arXiv](https://arxiv.org/abs/2505.23761) or [HuggingFace](https://huggingface.co/papers/2505.23761))| Minjoon Seo, Hyeonbin Hwang, Hyunji Lee, yunjae-won | i) The paper presents an information-theoretic analysis of Direct Preference Optimization (DPO) through a novel concept called Differential Information Distribution (DID). ii) The research aims to establish the theoretical conditions under which the log-ratio reward parameterization in DPO is optimal for aligning language models. iii) The methodology involves formalizing DID to characterize information gain in policy updates and analyzing the entropy of DID to understand policy dynamics. iv) The study proves that DPO's log-ratio reward is uniquely optimal when preferences encode differential information and finds this condition is linked to log-margin ordered policies; experiments indicate that learning high-entropy differential information is crucial for general instruction-following. v) This analysis provides AI practitioners with a framework for understanding and potentially improving DPO by considering the information-theoretic properties of preference data and its impact on policy behavior, guiding the development of more effective alignment strategies.  |
| REOrdering Patches Improves Vision Models (Read more on [arXiv](https://arxiv.org/abs/2505.23751) or [HuggingFace](https://huggingface.co/papers/2505.23751))| Trevor Darrell, Yutong Bai, David M. Chan, RitwikGupta, d3tk | i) This paper introduces REOrder, a framework that learns task-optimal patch orderings to improve vision model performance. ii) The research investigates how patch order affects the performance of long-sequence vision models, aiming to discover optimal orderings. iii) The methodology involves an information-theoretic prior based on patch sequence compressibility, combined with reinforcement learning using a Plackett-Luce policy and REINFORCE to optimize patch permutations. iv) REOrder improves top-1 accuracy over row-major ordering on ImageNet-1K by up to 3.01% and Functional Map of the World by 13.35%. v) The principal implication is that AI practitioners can leverage REOrder to enhance the performance of long-sequence vision models by optimizing patch orderings, particularly in scenarios where architectural approximations introduce sensitivity to patch sequence.  |
| ZeroSep: Separate Anything in Audio with Zero Training (Read more on [arXiv](https://arxiv.org/abs/2505.23625) or [HuggingFace](https://huggingface.co/papers/2505.23625))| Yunlong Tang, Susan Liang, Junxuan Huang, Yuesheng Ma, Chao Huang | ZeroSep is a zero-shot audio source separation framework leveraging pre-trained text-guided audio diffusion models. The research investigates whether generative foundation models can achieve source separation without task-specific training. ZeroSep inverts mixed audio into a diffusion model's latent space and uses text conditioning to guide the denoising process for individual source recovery. Without training, ZeroSep surpasses supervised methods on separation benchmarks, for example, achieving a FAD score of 0.377 on the MUSIC dataset. This demonstrates the potential of repurposing generative models for discriminative tasks, offering a training-free approach to open-set audio separation for AI practitioners.  |
| Re-ttention: Ultra Sparse Visual Generation via Attention Statistical
  Reshape (Read more on [arXiv](https://arxiv.org/abs/2505.22918) or [HuggingFace](https://huggingface.co/papers/2505.22918))| Di Niu, Chao Gao, LiyaoJiang, kgmills, crc5577 | i) The paper introduces Re-ttention, a novel sparse attention mechanism for Diffusion Transformers (DiTs) aimed at improving the efficiency of visual generation. ii) The main objective is to develop a high-sparsity attention mechanism that minimizes visual quality degradation in text-to-video (T2V) and text-to-image (T2I) models without requiring model retraining. iii) The methodology involves statistically reshaping attention distributions distorted by sparse attention, leveraging the temporal redundancy in Diffusion Models and caching/reusing softmax statistics from previous denoising steps. iv) Experimental results on CogVideoX and PixArt DiTs demonstrate that Re-ttention achieves up to 96.9% sparsity, leading to over 92% self-attention latency reduction on an H100 GPU and over 45% end-to-end latency reduction. v) The primary implication for AI practitioners is a training-free method to significantly accelerate DiT inference while maintaining visual quality, enabling more efficient deployment of these models.  |
| StressTest: Can YOUR Speech LM Handle the Stress? (Read more on [arXiv](https://arxiv.org/abs/2505.22765) or [HuggingFace](https://huggingface.co/papers/2505.22765))| Yossi Adi, gallilmaimon, iyosha | i) The paper introduces StressTest, a benchmark for evaluating sentence stress understanding in speech-aware language models (SLMs). ii) The research investigates the ability of SLMs to distinguish spoken sentence meanings based on varying stress patterns. iii) The study utilizes a novel synthetic data generation pipeline to create Stress-17k for finetuning SLMs. iv) Evaluations show that the finetuned model, StresSLM, achieves 81.6% accuracy on the sentence stress reasoning task, outperforming existing SLMs. v) The improved performance on stress understanding, without significantly impacting original SLM tasks, suggests that AI/ML engineers can enhance spoken language understanding by explicitly incorporating stress pattern analysis in model training and evaluation.  |
| One-shot Entropy Minimization (Read more on [arXiv](https://arxiv.org/abs/2505.20282) or [HuggingFace](https://huggingface.co/papers/2505.20282))| Bryan Dai, Joey Zhou, Lynx Chen, zgao3186 | i) This paper introduces One-shot Entropy Minimization (EM), a novel unsupervised post-training technique for large language models. ii) The primary objective is to demonstrate that entropy minimization with minimal data can significantly improve LLM performance. iii) The methodology involves training 13,440 LLMs using a single unlabeled data point and optimizing for 10 steps based on an entropy minimization loss. iv) Results indicate that One-shot EM achieves a 24.7 point average performance gain across multiple math reasoning benchmarks compared to the original Qwen2.5-Math-7B model; specifically, it increases the score on MATH500 by 25.8 points, going from 53.0 to 78.8. v) This implies that AI practitioners can use EM as a computationally efficient method for enhancing LLM performance, potentially rivalling or surpassing RL-based fine-tuning, and calls for reconsidering post-training paradigms.  |
| ChartLens: Fine-grained Visual Attribution in Charts (Read more on [arXiv](https://arxiv.org/abs/2505.19360) or [HuggingFace](https://huggingface.co/papers/2505.19360))| Ryan A. Rossi, Nedim Lipka, Manan Suri, Franck-Dernoncourt, puneetm | i) The paper introduces ChartLens, a novel chart attribution algorithm, and ChartVA-Eval, a benchmark for fine-grained visual attribution in charts, to address hallucinations in multimodal large language models (MLLMs). ii) The main objective is to develop a post-hoc visual attribution method for charts that identifies specific chart elements validating a given response. iii) ChartLens uses segmentation-based techniques to identify chart objects and set-of-marks prompting with MLLMs for fine-grained visual attribution; ChartVA-Eval comprises real-world and synthetic charts with attribution annotations. iv) Evaluations show that ChartLens improves fine-grained attributions by 26-66% compared to baselines. v) ChartLens enables AI practitioners to improve the transparency and reliability of MLLMs in chart understanding tasks by grounding model responses in verifiable visual elements.  |
| A Graph Perspective to Probe Structural Patterns of Knowledge in Large
  Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.19286) or [HuggingFace](https://huggingface.co/papers/2505.19286))| Yongjia Lei, Zhisheng Qi, Utkarsh Sahu, mhalappa, Franck-Dernoncourt | A graph-based approach is proposed to analyze structural patterns of knowledge in LLMs by quantifying knowledgeability at the triplet and entity levels. The research investigates how LLM knowledge relates to graph structural properties such as node degree and homophily. LLM knowledgeability scores are estimated using graph-based regression models leveraging local neighborhood context in knowledge graphs, and these models are trained with message-passing GNNs. It was found that LLMs exhibit knowledge homophily, where topologically proximate entities show similar knowledgeability, and that node degree correlates with knowledgeability, with regression achieving absolute errors between 0.15 and 0.25. These models can be utilized to prioritize high-value triplet facts for more effective LLM fine-tuning. It is unclear from the paper what are the computational cost of implementing the proposed GNN for predicting knowledgeability scores, or the generalizability to other LLMs and Knowledge Graphs.  |
| Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of
  Pre-trained Multimodal Representation via Text Updates (Read more on [arXiv](https://arxiv.org/abs/2505.22943) or [HuggingFace](https://huggingface.co/papers/2505.22943))| Gunhee Kim, Dayoon Ko, Heeseung Yun, ahnpersie | i) The paper introduces Multimodal Adversarial Compositionality (MAC), a benchmark for evaluating the compositional vulnerability of pre-trained multimodal representations. ii) The research aims to benchmark how effectively large language models can generate deceptive text to exploit compositional vulnerabilities in multimodal representations like CLIP across images, videos, and audio. iii) The methodology involves using LLMs for generating deceptive captions, filtering them through sample-wise and group-wise evaluations, and self-training the LLMs using rejection sampling fine-tuning. iv) Experiments demonstrate superior performance with the Llama-3.1-8B model, improving attack success rates by over 68% and diversity without sacrificing attack performance, across tested representations; the method achieves over 93% with GPT-4 during verification. v) AI practitioners can use the MAC benchmark and the proposed self-training approach to evaluate and improve the robustness of multimodal systems against adversarial compositional attacks across different modalities.  |
| When Models Reason in Your Language: Controlling Thinking Trace Language
  Comes at the Cost of Accuracy (Read more on [arXiv](https://arxiv.org/abs/2505.22888) or [HuggingFace](https://huggingface.co/papers/2505.22888))| Danielle S. Bitterman, Raquel Fernández, Zidi Xiong, Shan Chen, Jirui Qi | i) This paper investigates the trade-off between language matching in reasoning traces and answer accuracy in Large Reasoning Models (LRMs) across multiple languages. ii) The research question is to what extent LRMs can reason in a user's native language and how this affects reasoning accuracy. iii) The methodology involves evaluating six open-sourced LRMs using a new benchmark, XReasoning, which includes translated math and science questions, and applying prompt-hacking and post-training techniques. iv) Results show prompt hacking increases the language matching rate from 45-50% to above 90%, but reduces average accuracy on AIME questions from 26% to 17% for Distilled-R1-32B. v) AI practitioners should be aware that forcing LRMs to generate reasoning traces in a specific language through techniques like prompt hacking comes at a cost to the model's answer accuracy.  |
| CLIPGaussian: Universal and Multimodal Style Transfer Based on Gaussian
  Splatting (Read more on [arXiv](https://arxiv.org/abs/2505.22854) or [HuggingFace](https://huggingface.co/papers/2505.22854))| Marcin Mazur, Tadeusz Dziarmaga, Piotr Borycki, Joanna Waczyńska, Kornel Howil | CLIPGaussian presents a universal style transfer model applicable across diverse data modalities using Gaussian Splatting. The research investigates how to achieve text- and image-guided stylization across 2D images, videos, 3D objects, and 4D scenes. The methodology involves operating directly on Gaussian primitives and integrating into existing GS pipelines, optimizing color and geometry. Experimental results demonstrate that CLIPGaussian attains superior style fidelity and consistency; user studies show CLIPGaussian achieves scores comparable to G-Style with image conditioning. The research offers AI practitioners a universal and efficient solution for multimodal style transfer without requiring retraining from scratch, particularly for tasks involving diverse data types. The quantitative results and method's plug-in nature hold substantial implication for easing style transfer in various modalities.  |
| VidText: Towards Comprehensive Evaluation for Video Text Understanding (Read more on [arXiv](https://arxiv.org/abs/2505.22810) or [HuggingFace](https://huggingface.co/papers/2505.22810))| Yu Li, Yan Zhang, Zhifei Yang, Yan Shu, Zhoufaran Yang | VidText introduces a new benchmark for evaluating video text understanding capabilities of Large Multimodal Models (LMMs). The research aims to provide a comprehensive evaluation of LMMs in dynamic visual environments containing textual information. VidText employs a hierarchical evaluation framework across video, clip, and instance levels, paired with perception-reasoning tasks, covering a diverse range of real-world scenarios and multilingual content. Experiments on 18 state-of-the-art LMMs demonstrate current models' limitations, with the best model, Gemini 1.5 Pro, achieving only 46.8% average performance. This highlights the need for advancements in model architecture, OCR capability, and reasoning strategies for AI practitioners working with video understanding tasks. The primary findings underscored the challenge of multi-granularity tasks in videos and the impact of OCR capability on overall performance.  |
| SridBench: Benchmark of Scientific Research Illustration Drawing of
  Image Generation Model (Read more on [arXiv](https://arxiv.org/abs/2505.22126) or [HuggingFace](https://huggingface.co/papers/2505.22126))| Chuanhao Li, Jiaxin Ai, Jianwen Sun, Yukang Feng, Yifan Chang | i) SridBench is introduced as a new benchmark for evaluating multimodal models in generating scientific research illustrations. ii) The primary objective is to assess the capability of AI models, particularly multimodal large language models, in accurately interpreting technical descriptions and creating standardized visual representations of scientific concepts. iii) The methodology involves compiling a dataset of 1,120 instances of illustrations and associated text from scientific papers across 13 disciplines, annotated and evaluated along six dimensions including semantic fidelity and structural accuracy, using both human experts and large language models. iv) Experiments indicate that current state-of-the-art models like GPT-4o-image underperform compared to human-level performance, with GPT-4o-image achieving an average score of "fair" and open-source models scoring near 1, while Gemini-2.0-Flash reaching approximately 1.0. v) The principal implication for AI practitioners is the identification of critical bottlenecks, specifically a lack of text and visual information understanding and the presence of scientific errors, underscoring the need for further advancements in reasoning-driven visual generation for scientific applications.  |
| Adaptive Classifier-Free Guidance via Dynamic Low-Confidence Masking (Read more on [arXiv](https://arxiv.org/abs/2505.20199) or [HuggingFace](https://huggingface.co/papers/2505.20199))| Ruichuan An, Renrui Zhang, Joey Tsai, Shilin Yan, Pengxiang Li | i) This paper introduces Adaptive Classifier-Free Guidance (A-CFG) to improve controllability in iterative masked language models. ii) The research addresses the limitation of standard CFG's static unconditioning input by dynamically tailoring it based on model confidence. iii) A-CFG re-masks low-confidence tokens during each denoising step to construct a localized unconditional input. iv) Experiments on various language generation benchmarks show A-CFG achieves a 3.9 point improvement on GPQA compared to standard CFG. v) AI practitioners can use A-CFG to enhance conditional text generation in iterative diffusion models by dynamically adjusting guidance based on predictive confidence.  |
| Evaluating Text Creativity across Diverse Domains: A Dataset and Large
  Language Model Evaluator (Read more on [arXiv](https://arxiv.org/abs/2505.19236) or [HuggingFace](https://huggingface.co/papers/2505.19236))| Fang Luo, Yahui Liu, Yuzhuo Yuan, Xiting Wang, Aman | i) This paper introduces CreataSet, a dataset and LLM-based evaluator for assessing textual creativity across diverse domains. ii) The main objective is to develop an effective, automated methodology for evaluating text creativity that addresses limitations of cross-domain applicability, granularity, and human effort. iii) The methodology involves a pairwise-comparison framework with shared contextual instructions, a large-scale dataset of human and synthetic creative instruction-response pairs, and an LLM-based evaluator (CrEval) trained on the dataset. iv) CrEval demonstrates superior alignment with human judgments, outperforming GPT-4o by 18.7% in agreement with human judges; even state-of-the-art LLMs still perform poorly on the meta-evaluation benchmark test set. v) AI practitioners should integrate human-generated and synthetic data when training evaluators, leveraging CrEval as a practical tool to assess and boost the creativity of LLMs in generation pipelines, given its domain generalization capabilities.  |
