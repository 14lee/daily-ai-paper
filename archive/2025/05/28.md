

## Papers for 2025-05-28

| Title | Authors | Summary |
|-------|---------|---------|
| OmniConsistency: Learning Style-Agnostic Consistency from Paired
  Stylization Data (Read more on [arXiv](https://arxiv.org/abs/2505.18445) or [HuggingFace](https://huggingface.co/papers/2505.18445))| Cheng Liu, mikeshou, yiren98 | i) OmniConsistency is presented as a universal consistency plugin for image stylization, trained on paired data. ii) The research aims to achieve style-agnostic consistency in image stylization tasks using diffusion models, while preserving structure and semantics. iii) The methodology involves a two-stage decoupled training strategy and a rolling LoRA Bank loader mechanism with a lightweight Consistency LoRA Module and Conditional Token Mapping. iv) The method achieves state-of-the-art performance comparable to GPT-4o, enhancing visual coherence and aesthetic quality in stylization. It also achieves a 4.6% increase in GPU memory usage and a 5.3% increase in inference time at 1024x1024 resolution with 24 sampling steps compared to the base Flux Text-to-Image pipeline. v) OmniConsistency offers AI practitioners a modular, plug-and-play component that can be seamlessly integrated with arbitrary style LoRAs without retraining for image-to-image stylization tasks.  |
| MME-Reasoning: A Comprehensive Benchmark for Logical Reasoning in MLLMs (Read more on [arXiv](https://arxiv.org/abs/2505.21327) or [HuggingFace](https://huggingface.co/papers/2505.21327))| BoZhang, KaituoFeng, Yilei-Jiang, Potentialts, JiakangYuan | i) MME-Reasoning is introduced as a new benchmark for evaluating logical reasoning in multimodal large language models (MLLMs). ii) The primary objective is to comprehensively assess the inductive, deductive, and abductive reasoning capabilities of MLLMs. iii) The methodology involves curating a dataset of 1,188 multimodal questions, categorizing them by reasoning type and difficulty, and evaluating MLLM performance using multiple-choice, free-form, and rule-based question formats. iv) Evaluation of state-of-the-art MLLMs reveals limitations in comprehensive logical reasoning, with Gemini-Pro-2.5-Thinking achieving a score of 60.19%. v) The principal implication is that current MLLMs exhibit performance imbalances across reasoning types, especially in abductive reasoning, highlighting the need for improved reasoning architectures and training methodologies.  |
| Paper2Poster: Towards Multimodal Poster Automation from Scientific
  Papers (Read more on [arXiv](https://arxiv.org/abs/2505.21497) or [HuggingFace](https://huggingface.co/papers/2505.21497))| Xi He, philiptorr, HideOnBush, KevinQHLin, weipang142857 | Paper2Poster introduces a benchmark and metric suite for academic poster generation from scientific papers. The research aims to address the challenge of condensing long-context documents into a coherent visual page. It uses a top-down, visual-in-the-loop multi-agent pipeline called PosterAgent consisting of a Parser, Planner, and Painter-Commenter loop. Evaluations show that PosterAgent, based on open-source models like Qwen-2.5, outperforms GPT-40-driven systems, while also reducing token consumption by 87%, and finalizing a 22 page paper into an editable ".pptx" poster for only $0.005. The primary implication is it provides a framework for AI practitioners to streamline scientific communication through automated poster generation.  |
| VerIPO: Cultivating Long Reasoning in Video-LLMs via Verifier-Gudied
  Iterative Policy Optimization (Read more on [arXiv](https://arxiv.org/abs/2505.19000) or [HuggingFace](https://huggingface.co/papers/2505.19000))| Xinyu Chen, whluo, longyuewang, TerenceL-TL, YunxinLi | i) VerIPO is introduced as a Verifier-guided Iterative Policy Optimization method for video Large Language Models (Video-LLMs). ii) The research aims to improve the long reasoning capacity of Video-LLMs. iii) The methodology involves a GRPO-Verifier-DPO training loop, using a Rollout-Aware Verifier to assess reasoning logic and generate high-quality contrastive data. iv) Experimental results show VerIPO achieves significantly faster and more effective optimization compared to standard GRPO, yielding superior performance, also the model with one iteration outperforms powerful LMMs (e.g., Kimi-VL) and long reasoning models (e.g., Video-R1), and DPO stage is 7x faster than GRPO. v) VerIPO offers AI practitioners a method to enhance the deep reasoning capabilities of Video-LLMs through verifier-guided iterative policy optimization and high-quality data curation.  |
| Exploring the Latent Capacity of LLMs for One-Step Text Generation (Read more on [arXiv](https://arxiv.org/abs/2505.21189) or [HuggingFace](https://huggingface.co/papers/2505.21189))| oseledets, glebzok | i) This paper explores the possibility of generating accurate multi-token sequences from compressed representations in LLMs without autoregression. ii) The research investigates whether frozen LLMs can reconstruct accurate multi-token sequences in a single forward pass using a small number of learned embeddings, and explores the information encoded in these embeddings. iii) The methodology involves training two "proto-tokens" to optimize cross-entropy loss between the target sequence and the LLM's output in a single forward pass, varying model size, text source, and token arrangement. iv) The results show that LLMs can reconstruct arbitrary sequences from as few as two learned input embeddings, achieving near-perfect reconstruction (0.99 token-level accuracy) of sequences up to 256 tokens. v) This reveals LLMs' parallel generation capabilities and indicates potential for fast context compression and decompression, achieving up to 279x greater generation throughput compared to autoregressive methods, thus allowing for accelerated inference especially on-device.  |
| SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning
  Logical Reasoning and Beyond (Read more on [arXiv](https://arxiv.org/abs/2505.19641) or [HuggingFace](https://huggingface.co/papers/2505.19641))| zhangmozhi, YN83, ShiqiChen, ShiroFFF, Junteng | SynLogic introduces a data synthesis framework and dataset for generating verifiable logical reasoning data to enhance large language models. This research aims to address the lack of diverse, verifiable reasoning data for reinforcement learning in LLMs. The study employs a data synthesis pipeline to generate a dataset, SYNLOGIC, comprising 35 diverse logical reasoning tasks with adjustable difficulty and verifiable solutions. Experiments using Qwen2.5-Base models trained with SYNLOGIC demonstrate state-of-the-art logical reasoning performance, exceeding DeepSeek-R1-Distill-Qwen-32B by 6 points on BBEH. Mixing SYNLOGIC data with mathematical and coding tasks improves training efficiency and reasoning generalization, offering AI practitioners a valuable resource for enhancing LLM reasoning capabilities.  |
| Don't Overthink it. Preferring Shorter Thinking Chains for Improved LLM
  Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.17813) or [HuggingFace](https://huggingface.co/papers/2505.17813))| Roy Schwartz, adiyoss, gsynnaeve, hassid | i) This paper challenges the conventional wisdom that longer thinking chains in LLMs lead to better reasoning, finding that shorter chains are often more accurate and efficient. ii) The primary objective is to investigate the relationship between reasoning chain length and correctness in LLMs, and to develop a more efficient inference method based on this relationship. iii) The methodology involves generating multiple reasoning chains for the same question using leading LLMs, comparing the accuracy of shortest, longest, and randomly selected chains, and proposing a novel inference method called short-m@k, which halts computation after a predetermined number of short chains are generated. iv) Results show that shortest reasoning chains can be up to 34.5% more accurate than the longest chains for the same question, and the short-m@k method can reduce compute by up to 40% while maintaining or improving performance. v) The principal implication for AI practitioners is that prioritizing shorter reasoning chains and using inference methods like short-m@k can significantly improve the efficiency and accuracy of reasoning LLMs, suggesting a potential shift in strategies for test-time compute allocation.  |
| UI-Genie: A Self-Improving Approach for Iteratively Boosting MLLM-based
  Mobile GUI Agents (Read more on [arXiv](https://arxiv.org/abs/2505.21496) or [HuggingFace](https://huggingface.co/papers/2505.21496))| Afeng-x, luzimu, Yuxiang007, juice-wang, HanXiao1999 | i) UI-Genie is a self-improving framework for mobile GUI agents utilizing a reward model and iterative pipeline. ii) The research addresses the challenges of trajectory outcome verification and scalable high-quality training data for GUI agents. iii) The methodology involves a reward model (UI-Genie-RM) with an image-text interleaved architecture, rule-based verification, controlled trajectory corruption, hard negative mining, and a self-improvement pipeline with reward-guided exploration. iv) UI-Genie achieves state-of-the-art performance across multiple GUI agent benchmarks and creates UI-Genie-RM-517k and UI-Genie-Agent-16k datasets; the 72B model reaches 77.0% success rate on AndroidControl high-level tasks. v) The framework's iterative self-improvement and reward-specific dataset provide AI practitioners with a methodology for training and improving GUI agents without manual annotation.  |
| Sparse VideoGen2: Accelerate Video Generation with Sparse Attention via
  Semantic-Aware Permutation (Read more on [arXiv](https://arxiv.org/abs/2505.18875) or [HuggingFace](https://huggingface.co/papers/2505.18875))| han-cai, jt-zhang, ylzhao, xihc-ucb, andy-yang | Sparse VideoGen2 (SVG2) accelerates video generation by optimizing sparse attention mechanisms. The research aims to improve the trade-off between generation quality and computational efficiency in Diffusion Transformers (DiTs) for video generation. The proposed method, SVG2, employs semantic-aware permutation using k-means clustering to identify and densify critical tokens, alongside a top-p selection strategy and custom kernel implementations. Experiments show that SVG2 achieves up to 2.30x speedup on Hunyuan-Video with a PSNR of up to 30 and 1.89x speedup on Wan 2.1 with a PSNR of up to 26 compared to dense attention. SVG2 offers AI practitioners a more efficient framework for video generation by maximizing critical token identification accuracy and minimizing wasted computation.  |
| MMMR: Benchmarking Massive Multi-Modal Reasoning Tasks (Read more on [arXiv](https://arxiv.org/abs/2505.16459) or [HuggingFace](https://huggingface.co/papers/2505.16459))| Guiyao Tie, sunlichao137, MengquSun, Cpmores, zhouxueyang | MMMR introduces a benchmark for evaluating multi-modal reasoning with explicit thinking traces. The research aims to rigorously evaluate multi-modal reasoning with explicit thinking traces in MLLMs. The methodology involves a high-difficulty dataset spanning six reasoning types and a Reasoning Trace Evaluation Pipeline (RTEP) assessing reasoning quality via relevance, consistency, and error annotations. Empirical results indicate that even top MLLMs-T models like Claude-3.7-Sonnet and Gemini-2.5 Pro exhibit inconsistencies and overthinking despite outperforming non-thinking counterparts, while Gemini-2.5 Pro achieves 42.45% accuracy against human expert levels of 52.85%. This benchmark provides an actionable evaluation pipeline to diagnose reasoning failures and improve the next generation of multi-modal reasoning systems.  |
| MME-VideoOCR: Evaluating OCR-Based Capabilities of Multimodal LLMs in
  Video Scenarios (Read more on [arXiv](https://arxiv.org/abs/2505.21333) or [HuggingFace](https://huggingface.co/papers/2505.21333))| Huanyao Zhang, Wulin Xie, Huanqian Wang, xinfeng1i, DogNeverSleep | i) This paper introduces MME-VideoOCR, a new benchmark for evaluating video OCR capabilities of Multimodal Large Language Models (MLLMs). ii) The main objective is to assess the ability of MLLMs to perform OCR and related reasoning tasks in video scenarios, overcoming challenges like motion blur and temporal variations. iii) The methodology involves curating a dataset of 1,464 videos with 2,000 question-answer pairs, categorized into 10 task types and 25 individual tasks, followed by evaluating 18 state-of-the-art MLLMs. iv) Evaluation revealed that even the best-performing model, Gemini-2.5 Pro, achieved an accuracy of only 73.7% on the benchmark, indicating limitations in tasks requiring holistic video comprehension. v) The findings imply AI practitioners must address the deficiencies of current MLLMs in spatio-temporal reasoning and cross-frame information integration to improve OCR performance in dynamic video settings, and that high-resolution visual inputs and sufficient temporal coverage are crucial.  |
| OpenS2V-Nexus: A Detailed Benchmark and Million-Scale Dataset for
  Subject-to-Video Generation (Read more on [arXiv](https://arxiv.org/abs/2505.20292) or [HuggingFace](https://huggingface.co/papers/2505.20292))| chongyangma, Jinfa, dyf, pkuhexianyi, BestWishYsh | i) The paper introduces OpenS2V-Nexus, comprising OpenS2V-Eval, a benchmark, and OpenS2V-5M, a million-scale dataset, for subject-to-video (S2V) generation. ii) The research aims to provide infrastructure for evaluating S2V models, focusing on subject consistency, naturalness, and text relevance. iii) The methodology involves curating a dataset of subject-text-video triples and developing three automatic metrics: NexusScore, NaturalScore, and GmeScore. iv) The study evaluates 16 S2V models and creates OpenS2V-5M, which contains 5 million subject-text-video triples. v) The infrastructure supports researchers evaluating S2V models and developing S2V models. |
| GraLoRA: Granular Low-Rank Adaptation for Parameter-Efficient
  Fine-Tuning (Read more on [arXiv](https://arxiv.org/abs/2505.20355) or [HuggingFace](https://huggingface.co/papers/2505.20355))| hyek90, tae-su-kim, HyungjunKim, daehyunahn, yeonjoon-jung | i) GraLoRA introduces a novel granular low-rank adaptation method for parameter-efficient fine-tuning of large language models. ii) The research aims to address the limitations of LoRA concerning rank limitations due to gradient entanglement. iii) The method partitions weight matrices into sub-blocks, each with its own low-rank adapter, mitigating channel dominance. iv) Experiments show GraLoRA achieves up to +8.5% absolute gain in Pass@1 on HumanEval+ compared to LoRA and other baselines. v) AI practitioners can use GraLoRA as a scalable PEFT method to improve fine-tuning performance, particularly in scenarios requiring nuanced representations and complex reasoning.  |
| Video-Holmes: Can MLLM Think Like Holmes for Complex Video Reasoning? (Read more on [arXiv](https://arxiv.org/abs/2505.21374) or [HuggingFace](https://huggingface.co/papers/2505.21374))| Teng Wang, CeciliaJL, yxgeee, tttoaster, Howe666 | i) This paper introduces Video-Holmes, a new benchmark for evaluating complex video reasoning in multimodal large language models (MLLMs). ii) The research aims to assess whether MLLMs can perform complex video reasoning akin to human experts by locating and connecting multiple relevant visual clues. iii) The methodology involves creating a dataset of 1,837 questions derived from 270 manually annotated suspense short films, designed to test active clue seeking and chain-of-clue reasoning. iv) Evaluation of state-of-the-art MLLMs, including Gemini-2.5-Pro, reveals an accuracy of only 45% on Video-Holmes, indicating substantial challenges in integrating information and identifying critical clues, even with advanced models. v) The principal implication for AI practitioners is the identified need for enhanced reasoning capabilities in MLLMs, specifically in integrating information across diverse video segments and identifying critical clues for more human-like performance, for applications involving complex video analysis.  |
| rStar-Coder: Scaling Competitive Code Reasoning with a Large-Scale
  Verified Dataset (Read more on [arXiv](https://arxiv.org/abs/2505.21297) or [HuggingFace](https://huggingface.co/papers/2505.21297))| Xudong Zhou, Bingcheng Dong, Yi Zhu, Li Lyna Zhang, YF-L | i) rStar-Coder introduces a large-scale, verified dataset and a methodology for training code reasoning LLMs. ii) The paper aims to enhance LLM code reasoning capabilities through a scalable, verifiable dataset of competition-level code problems. iii) The methodology involves curating seed problems, synthesizing new problems with a three-step input generation pipeline, and verifying solutions with a mutual verification mechanism. iv) rStar-Coder improves Qwen2.5-7B on LiveCodeBench from 17.4% to 57.3% and achieves a 16.15% average pass@1 accuracy on USACO 2025 using a 7B model, outperforming QWQ-32B. v) The work implies that a curated, verified dataset focused on problem diversity and high-quality reasoning steps can enable smaller LLMs to achieve performance competitive with larger frontier models, benefiting AI practitioners by reducing computational costs.  |
| MetaMind: Modeling Human Social Thoughts with Metacognitive Multi-Agent
  Systems (Read more on [arXiv](https://arxiv.org/abs/2505.18943) or [HuggingFace](https://huggingface.co/papers/2505.18943))| Yixuan Li, Yuxuan Chen, samuelyeh, XUANMINGZHANG | i) The paper introduces MetaMind, a multi-agent framework for enhancing social reasoning in Large Language Models (LLMs). ii) The research aims to improve LLMs' ability to infer mental states and respond appropriately in ambiguous, context-sensitive social interactions. iii) MetaMind employs three collaborative agents: a Theory-of-Mind Agent for hypothesis generation, a Domain Agent for constraint-based refinement, and a Response Agent for validated output generation. iv) The framework achieves state-of-the-art performance across ToMBench, social cognition, and social simulation benchmarks, including a 35.7% improvement in real-world social scenarios, with LLMs matching human-level performance on ToM tasks for the first time. v) AI practitioners can leverage MetaMind's architecture to build socially intelligent AI systems, enabling more empathetic dialogue and culturally sensitive interactions by incorporating metacognitive reasoning into LLMs.  |
| HoliTom: Holistic Token Merging for Fast Video Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.21334) or [HuggingFace](https://huggingface.co/papers/2505.21334))| Haoxuan You, Can Qin, Keda Tao, Huan-WhoRegisteredMyName, keleshao | i) HoliTom is introduced as a training-free method to accelerate video large language models (LLMs) through holistic token merging. ii) The primary objective is to reduce computational inefficiency in video LLMs caused by redundant video tokens, while preserving performance. iii) The key methodology involves outer-LLM pruning using global redundancy-aware temporal segmentation and spatio-temporal merging, complemented by a robust inner-LLM token similarity-based merging approach. iv) The method maintains 99.1% average performance while reducing FLOPs to 6.9% on LLaVA-OneVision-7B, achieving a 2.28× reduction in Time-To-First-Token (TTFT) and a 1.32× acceleration in decoding throughput. v) HoliTom enables AI practitioners to achieve efficient video LLM inference with a significantly reduced computational burden, facilitating the deployment of video LLMs in resource-constrained environments.  |
| ImgEdit: A Unified Image Editing Dataset and Benchmark (Read more on [arXiv](https://arxiv.org/abs/2505.20275) or [HuggingFace](https://huggingface.co/papers/2505.20275))| Zongjian Li, Xianyi He, Yang Ye, zhiyuanyan1, BestWishYsh | i) ImgEdit introduces a new large-scale image editing dataset, benchmark, and editing model. ii) The research aims to address the limitations of existing datasets by creating a high-quality, diverse dataset and a comprehensive benchmark for evaluating image editing models. iii) The study developed an automated data construction pipeline and trained an editing model, ImgEdit-E1, on the new dataset. iv) The dataset comprises 1.2 million edit pairs, and ImgEdit-E1 outperforms existing open-source models on multiple tasks, evaluated using a new benchmark. v) ImgEdit provides AI practitioners with a unified, high-quality resource for training and evaluating image editing models, enabling further advancements in the field.  |
| How does Alignment Enhance LLMs' Multilingual Capabilities? A Language
  Neurons Perspective (Read more on [arXiv](https://arxiv.org/abs/2505.21505) or [HuggingFace](https://huggingface.co/papers/2505.21505))| Xiao Liu, Shuaijie She, VincentLx, DreamW1ngs, Shimao-Zhang | Multilingual alignment enhances LLMs' capabilities, analyzed through language neuron identification. The research questions how multilingual alignment influences LLMs' multilingual proficiency, examined from a language neuron perspective. The study proposes a finer-grained neuron identification algorithm (language-specific, language-related, language-agnostic) and analyzes neuron distribution changes before and after alignment via MAPO. The results indicate that multilingual alignment increases activation of corresponding neuron types across relevant layers and promotes shared language-related neuron utilization, while deactivating language neurons leads to more pronounced effects. The study provides empirical insights for AI practitioners by detailing how multilingual alignment affects neuron activation patterns, suggesting strategies for enhancing multilingual LLMs through targeted neuron manipulation, improving task-relevant understanding in shared semantic space.  |
| Beyond Distillation: Pushing the Limits of Medical LLM Reasoning with
  Minimalist Rule-Based RL (Read more on [arXiv](https://arxiv.org/abs/2505.17952) or [HuggingFace](https://huggingface.co/papers/2505.17952))| Yong Dai, Zhongwei Wan, Jiazhen Pan, Haozhe Wang, Che Liu | AlphaMed explores minimalist rule-based reinforcement learning (RL) to enhance medical LLM reasoning. The paper investigates whether reasoning in medical LLMs can be incentivized solely through rule-based RL on multiple-choice QA data, without supervised fine-tuning (SFT) or distilled chain-of-thought (CoT) data. The study utilizes group relative policy optimization (GRPO) with rule-based rewards on medical QA datasets. AlphaMed achieves state-of-the-art results on six medical QA benchmarks, including a 22.14% accuracy on MedXpert for the 8B model. Minimalist RL with informative QA data is effective at inducing reasoning without CoT supervision, providing a scalable alternative to SFT-based approaches, though the evaluation suggests the need for more challenging, reasoning-oriented benchmarks.  |
| Active-O3: Empowering Multimodal Large Language Models with Active
  Perception via GRPO (Read more on [arXiv](https://arxiv.org/abs/2505.21457) or [HuggingFace](https://huggingface.co/papers/2505.21457))| Zongze Du, Hao Zhong, MingyuLiu, Canyu, Z-MU-Z | i) The paper introduces ACTIVE-03, a reinforcement learning framework using Group Relative Policy Optimization (GRPO) to enable Multimodal Large Language Models (MLLMs) with active perception capabilities. ii) The primary objective is to equip MLLMs with active perception skills for tasks requiring selective sensory information acquisition. iii) The methodology involves a two-stage policy separating region proposal and task execution, combined with a dual-form reward design incorporating task-aware and heuristic feedback. iv) Results show that ACTIVE-03 improves performance in small object detection and interactive segmentation, demonstrated by an APS improvement of +1.0 on LVISsmall over Qwen2.5-VL. v) The framework and benchmark provide AI practitioners with a codebase and evaluation protocol to develop and integrate active perception capabilities into MLLMs, particularly for applications in embodied intelligence and visual grounding.  |
| Frame In-N-Out: Unbounded Controllable Image-to-Video Generation (Read more on [arXiv](https://arxiv.org/abs/2505.21491) or [HuggingFace](https://huggingface.co/papers/2505.21491))| Zezhou Cheng, Matheus Gadelha, Xuweiyi Chen, HikariDawn | Frame In-N-Out introduces a new image-to-video generation task that enables controllable object entrance/exit beyond initial frame boundaries. The research aims to develop a model for Frame In and Frame Out cinematic techniques, conditioned on user-specified motion trajectories and identity references within an unbounded canvas. The methodology includes curating a semi-automatically generated dataset and developing an efficient identity-preserving motion-controllable video Diffusion Transformer architecture. Evaluation demonstrates significant outperformance against existing baselines, with the Stage2 model achieving a Traj. Err. of 17.85 compared to 41.24 for DragAnything [70] on the Frame Out task. The work implies AI practitioners can utilize the proposed architecture and training methodology to achieve more controllable and spatially unconstrained video generation capabilities.  |
| NOVA: A Benchmark for Anomaly Localization and Clinical Reasoning in
  Brain MRI (Read more on [arXiv](https://arxiv.org/abs/2505.14064) or [HuggingFace](https://huggingface.co/papers/2505.14064))| Lena Schmitzer, Evamaria O. Riedel, Philipp Raffler, RioJune, ci-ber | i) NOVA is introduced as an evaluation-only benchmark for anomaly localization, visual captioning, and diagnostic reasoning on brain MRI scans. ii) The research aims to assess the generalization capabilities of vision-language models in detecting, localizing, and reasoning about rare anomalies in clinical brain MRI under distribution shift. iii) The methodology involves curating a dataset of 906 brain MRI scans from Eurorad spanning 281 pathologies, enriching them with clinical narratives and double-blinded expert bounding box annotations, and evaluating vision-language models (GPT-4o, Gemini 2.0 Flash, Qwen2.5-VL-72B). iv) Results show substantial performance drops across tasks, with anomaly localization mAP@30 ranging from 20.16 to 37.66, indicating poor generalization. v) NOVA serves as a testbed for AI practitioners to develop models that can robustly detect, localize, and reason about truly unknown anomalies, highlighting the need for benchmarks that capture the demands of open-world clinical reasoning, and specifically quantifies the limitations of current models when confronted with real-world clinical data heterogeneity.  |
| Beyond Prompt Engineering: Robust Behavior Control in LLMs via Steering
  Target Atoms (Read more on [arXiv](https://arxiv.org/abs/2505.20322) or [HuggingFace](https://huggingface.co/papers/2505.20322))| Shumin Deng, Shengyu Mao, Ziwen Xu, Mengru Wang, Ningyu | i) The paper introduces Steering Target Atoms (STA), a novel method for precise control of LLM behaviors using sparse autoencoders. ii) The research investigates how to enhance safety and control of LLMs by isolating and manipulating disentangled knowledge components. iii) STA utilizes SAE-decoupled representations to identify and manipulate specific target atoms, enabling fine-grained interventions in LLMs. iv) Experiments show STA achieves up to 97.56% average detoxification performance on Gemma-2-9B-it, with minimal impact on general capabilities, demonstrating superior robustness and flexibility in adversarial scenarios. v) STA offers AI practitioners a more robust and precise method for controlling LLM behavior, improving safety and reliability compared to traditional prompt engineering.  |
| ViewSpatial-Bench: Evaluating Multi-perspective Spatial Localization in
  Vision-Language Models (Read more on [arXiv](https://arxiv.org/abs/2505.21500) or [HuggingFace](https://huggingface.co/papers/2505.21500))| Hang Zhang, Zixuan Wang, Hongxing Li, Dingming Li, yanyc | i) The paper introduces ViewSpatial-Bench, a new benchmark for evaluating multi-perspective spatial localization in vision-language models (VLMs). ii) The main objective is to assess and address limitations of current VLMs in understanding spatial relationships from different viewpoints, including camera and human perspectives. iii) The methodology involves creating a dataset with over 5,700 curated samples, using a 3D annotation pipeline and five distinct localization recognition tasks, followed by fine-tuning VLMs on this dataset. iv) Results show that VLMs exhibit reduced accuracy when reasoning from a human viewpoint compared to a camera viewpoint, while fine-tuning on the new dataset improves performance by 46.24% across tasks. v) The principal implication for AI practitioners is the identification of a significant limitation in spatial reasoning within existing VLMs, offering a benchmark and training data to enhance spatial comprehension for embodied AI systems. |
| Code Graph Model (CGM): A Graph-Integrated Large Language Model for
  Repository-Level Software Engineering Tasks (Read more on [arXiv](https://arxiv.org/abs/2505.16901) or [HuggingFace](https://huggingface.co/papers/2505.16901))| Hongen Peng, Zhenhao Tang, Ying Zhang, Hongyuan Tao, Geralt-Targaryen | i) This paper introduces Code Graph Models (CGMs), a novel architecture integrating code graph structures into Large Language Models (LLMs) for improved repository-level software engineering task performance. ii) The primary research question is whether open-source LLMs can effectively address repository-level tasks without agent-based approaches by incorporating code graph information. iii) The methodology involves integrating code graph structures into the LLM's attention mechanism and mapping node attributes using a specialized adapter, combined with an agentless graph RAG framework. iv) The approach achieves a 43.00% resolution rate on the SWE-bench Lite benchmark using the open-source Qwen2.5-72B model. v) CGMs offer AI practitioners a new method for leveraging open-source LLMs in repository-level software engineering tasks without proprietary agent systems, improving predictability and enabling data privacy and model customization.  |
| DetailFlow: 1D Coarse-to-Fine Autoregressive Image Generation via
  Next-Detail Prediction (Read more on [arXiv](https://arxiv.org/abs/2505.21473) or [HuggingFace](https://huggingface.co/papers/2505.21473))| Xu Wang, Huichao Zhang, Yiheng Liu, JiangYi, leo1117 | DetailFlow presents a coarse-to-fine 1D autoregressive image generation method using a next-detail prediction strategy. The paper investigates whether a coarse-to-fine 1D token sequence can efficiently model images by learning a resolution-aware token sequence supervised with progressively degraded images. DetailFlow uses a compact 1D AR model and a parallel inference mechanism with self-correction. On ImageNet 256x256, DetailFlow achieves 2.96 gFID with 128 tokens. DetailFlow provides AI practitioners with a more efficient autoregressive approach that achieves better image quality with fewer tokens and faster inference.  |
| SeePhys: Does Seeing Help Thinking? -- Benchmarking Vision-Based Physics
  Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.19099) or [HuggingFace](https://huggingface.co/papers/2505.19099))| Zirong Liu, Terry Jingchen Zhang, Kun Xiang, yinyahuang, HengLi29 | SeePhys: A new multimodal benchmark for physics reasoning is introduced to evaluate LLMs' visual understanding. The research aims to assess LLMs' capabilities in physics reasoning grounded in visual information from middle school to PhD levels. It uses a dataset of 2,000 physics questions spanning 7 domains and 21 diagram types, including a vision-essential subset that mandates visual information extraction for solutions. Evaluation of LLMs like Gemini-2.5-pro and o4-mini reveals a sub-60% accuracy, highlighting challenges in current models' visual understanding and coupling with physics reasoning. The study indicates a need for AI practitioners to improve LLMs' ability to integrate diagram interpretation with physics reasoning, overcoming reliance on textual cues, which currently limits their visual reasoning capacity.  |
| Adversarial Attacks against Closed-Source MLLMs via Feature Optimal
  Alignment (Read more on [arXiv](https://arxiv.org/abs/2505.21494) or [HuggingFace](https://huggingface.co/papers/2505.21494))| Chao Du, Tianyu Pang, Simeng Qin, Sensen Gao, jiaxiaojunQAQ | i) This paper introduces FOA-Attack, a targeted transferable adversarial attack method against Multimodal Large Language Models (MLLMs). ii) The research aims to improve adversarial transferability by optimizing the alignment of both global and local image features between adversarial and target samples. iii) FOA-Attack employs a global feature loss based on cosine similarity and a local clustering optimal transport (OT) loss, along with a dynamic ensemble model weighting strategy. iv) Experiments show FOA-Attack achieves a 70.7% attack success rate on Qwen2.5-VL-7B, surpassing existing methods, and up to 77.3% ASR on GPT-4.1, indicating a 16.5% performance improvement, specifically when transferred to closed-source models. v) AI practitioners should consider feature-level adversarial vulnerabilities in MLLMs and explore feature optimal alignment to enhance robustness against transferable attacks.  |
| Beyond Markovian: Reflective Exploration via Bayes-Adaptive RL for LLM
  Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.20561) or [HuggingFace](https://huggingface.co/papers/2505.20561))| Peter Grabowski, Tianqi Liu, Yinxiao Liu, Yaqing Wang, Shenao Zhang | i) The paper introduces Bayes-Adaptive RL (BARL), an algorithm for reflective exploration in Large Language Models (LLMs) reasoning by optimizing the expected return under a posterior distribution over Markov decision processes. ii) The research aims to address whether reflective reasoning emerges during Markovian RL training and why such behaviors may be beneficial at test time. iii) The methodology involves recasting reflective exploration within a Bayes-Adaptive RL framework, incentivizing reward-maximizing exploitation and information-gathering exploration through belief updates. iv) Empirical results show BARL outperforms standard Markovian RL approaches at test time, achieving superior token efficiency and improved exploration effectiveness, with BARL requiring up to 39% fewer average tokens than a progress baseline on reasoning tasks. v) BARL provides AI practitioners with a novel approach for training LLMs to adaptively switch strategies based on observed outcomes, improving reasoning performance through a principled mechanism for integrating and revising plausible strategies.  |
| Sci-Fi: Symmetric Constraint for Frame Inbetweening (Read more on [arXiv](https://arxiv.org/abs/2505.21205) or [HuggingFace](https://huggingface.co/papers/2505.21205))| Xianyi He, Xiaoyu Li, Xiaodong Cun, Liuhan Chen, BestWishYsh | Sci-Fi introduces a novel frame inbetweening framework leveraging symmetric constraints to generate harmonious intermediate video frames. The research aims to improve the quality of synthesized intermediate video sequences conditioned on start and end frames by addressing limitations in current Image-to-Video Diffusion Model (I2V-DM) based methods. The methodology involves a lightweight module, EF-Net, to encode the end frame and inject temporally adaptive features into a base I2V-DM. Experiments show Sci-Fi achieves superior performance with a VBench score of 0.8373 on the Pexels dataset compared to other baselines. This work implies AI practitioners can utilize the Sci-Fi framework to produce higher quality and more consistent intermediate frames in video generation tasks with improved control mechanisms.  |
| Walk Before You Run! Concise LLM Reasoning via Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2505.21178) or [HuggingFace](https://huggingface.co/papers/2505.21178))| Mao Zheng, Nickyang | i) ConciseR, a two-stage reinforcement learning framework, aims to enhance and subsequently compress the reasoning of LLMs. ii) The research question is how to achieve concise reasoning in LLMs without sacrificing accuracy. iii) The methodology involves a two-stage reinforcement learning approach: first using Group Relative Policy Optimization with clip-higher and dynamic sampling (GRPO++) and an entropy bonus, then using Length-aware Group Relative Policy Optimization (L-GRPO). iv) Experimental results show ConciseR outperforms baselines with zero RL paradigm across AIME 2024, MATH-500, AMC 2023, Minerva, and Olympiad benchmarks, achieving an average accuracy improvement and a 21-23% reduction in response length. v) ConciseR offers AI practitioners a method to train LLMs for more concise and efficient reasoning, balancing accuracy and reduced computational cost.  |
| Minute-Long Videos with Dual Parallelisms (Read more on [arXiv](https://arxiv.org/abs/2505.21070) or [HuggingFace](https://huggingface.co/papers/2505.21070))| Xinchao Wang, Yuecong Xu, Xingyi Yang, Bowen Zheng, Zeqing Wang | i) This paper introduces DualParal, a distributed inference strategy for DiT-based video diffusion models, parallelizing both temporal frames and model layers. ii) The research aims to mitigate the high processing latency and memory costs associated with generating long videos using DiT models. iii) The methodology involves a block-wise denoising scheme and asynchronous processing across GPUs, incorporating a feature cache to reduce inter-GPU communication and a coordinated noise initialization strategy. iv) Experiments show DualParal achieves up to a 6.54x reduction in latency and a 1.48x reduction in memory cost when generating 1,025-frame videos on 8×RTX 4090 GPUs. v) AI practitioners can leverage DualParal to efficiently generate high-quality, long videos with DiT-based models by mitigating memory bottlenecks and reducing inference latency using the developed parallelization strategies.  |
| VisualToolAgent (VisTA): A Reinforcement Learning Framework for Visual
  Tool Selection (Read more on [arXiv](https://arxiv.org/abs/2505.20289) or [HuggingFace](https://huggingface.co/papers/2505.20289))| Wen Xiao, Zefan Cai, Yuyang Ji, AniSundar18, ZeyiHuang1010 | i) The paper introduces VisualToolAgent (VisTA), a reinforcement learning framework for adaptive tool selection in visual reasoning tasks. ii) The research aims to develop a system that can autonomously learn to select and combine appropriate external tools for visual reasoning, improving performance over training-free and fine-tuning methods. iii) VisTA employs end-to-end reinforcement learning with Group Relative Policy Optimization (GRPO) to train an agent to select tools based on empirical performance feedback. iv) Experiments on ChartQA demonstrate that VisTA achieves 79.4% accuracy, a 3.0-point improvement over the best training-free baseline; VisTA with GPT-40 achieves 88.9% accuracy. v) The framework provides AI practitioners with a method for developing more flexible and generalizable visual reasoning systems by enabling dynamic tool selection based on task-specific characteristics.  |
| Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic
  Capabilities in LLM Compression (Read more on [arXiv](https://arxiv.org/abs/2505.19433) or [HuggingFace](https://huggingface.co/papers/2505.19433))| Xiaowen Chu, Lujun Li, Zhenheng Tang, Peijie Dong, Dominic789654 | i) The paper introduces ACBench, a benchmark to evaluate the impact of compression on agentic abilities in LLMs. ii) The primary research question is how post-training compression methods affect LLMs' performance on tasks requiring workflow generation, tool use, long-context understanding, and real-world application. iii) The methodology involves evaluating 15 models using quantization and pruning techniques across 12 tasks, with new metrics (ERank, Top-k Ranking Correlation, Energy) for systematic analysis. iv) Experiments reveal that 4-bit quantization preserves workflow generation and tool use (1%-3% drop) but degrades real-world application accuracy by 10%-15%; distilled reasoning LLMs show performance degradation in certain agent scenarios. v) The findings offer actionable insights for optimizing LLM compression strategies in agentic scenarios, indicating that while quantization can maintain certain agentic capabilities, real-world application accuracy may be significantly compromised, a critical consideration for AI practitioners deploying compressed LLMs in practical applications.  |
| R1-Searcher++: Incentivizing the Dynamic Knowledge Acquisition of LLMs
  via Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2505.17005) or [HuggingFace](https://huggingface.co/papers/2505.17005))| Zhipeng Chen, Wenqing Tian, Jinhao Jiang, Huatong Song, EliverQ | R1-Searcher++ enhances LLMs by adaptively leveraging both internal knowledge and external search. The research aims to train LLMs to dynamically acquire knowledge, balancing internal recall and external retrieval. It employs a two-stage training strategy: SFT Cold-start for format learning followed by RL for Dynamic Knowledge Acquisition, incorporating outcome-supervision and a memorization mechanism. Experiments using Qwen-2.5-7B-Instruct demonstrate the method surpasses baselines by up to 4.3% while reducing retrieval counts by 42.9%. This suggests AI practitioners can utilize the approach to more efficiently create retrieval-augmented reasoning models that have high quality internal knolwedge and make external retrievals as needed.  |
| DFIR-Metric: A Benchmark Dataset for Evaluating Large Language Models in
  Digital Forensics and Incident Response (Read more on [arXiv](https://arxiv.org/abs/2505.19973) or [HuggingFace](https://huggingface.co/papers/2505.19973))| Saeed Alshehhi, Aaesha Aldahmani, Richard A. Dubniczky, Tamas Bisztray, Bilel Cherif | i) DFIR-Metric is introduced as a benchmark for evaluating LLMs in Digital Forensics and Incident Response (DFIR). ii) The primary objective is to establish a comprehensive benchmark evaluating LLMs across theoretical and practical DFIR tasks. iii) The methodology involves a three-part dataset including multiple-choice questions, CTF-style challenges, and NIST CFTT string search cases, evaluated using accuracy, consistency, and a novel Task Understanding Score (TUS). iv) Experimental results show GPT-4.1 achieves a Confidence Index of 89.34% and a Mean Accuracy of 92.75% on multiple-choice questions, while TUS@4 reached 38.52% for the NIST forensic string search task. v) The implication for AI practitioners is the need for improved reasoning and adherence to output specifications in LLMs for reliable application in digital forensics, as current models struggle with sustained deductive reasoning and calibrated confidence.  |
| SoloSpeech: Enhancing Intelligibility and Quality in Target Speech
  Extraction through a Cascaded Generative Pipeline (Read more on [arXiv](https://arxiv.org/abs/2505.19314) or [HuggingFace](https://huggingface.co/papers/2505.19314))| Kai Li, Chen Chen, Dongchao Yang, Jiarui Hai, westbrook | SoloSpeech introduces a cascaded generative pipeline for target speech extraction. The research aims to enhance the intelligibility and quality of extracted speech by integrating compression, extraction, reconstruction, and correction processes. It employs a speaker-embedding-free target extractor using a latent diffusion model conditioned on cue audio and a T-F domain diffusion model as a corrector. Evaluated on Libri2Mix, SoloSpeech achieves a WER of 0.16, demonstrating state-of-the-art intelligibility and quality and improved generalization to out-of-domain data. The pipeline offers AI practitioners a robust and generalizable method for speech extraction tasks, with the provided source code enabling integration into existing speech processing systems.  |
| MLLMs are Deeply Affected by Modality Bias (Read more on [arXiv](https://arxiv.org/abs/2505.18657) or [HuggingFace](https://huggingface.co/papers/2505.18657))| Yuanhuiyi Lyu, Kaiyu Lei, Yuqian Fu, Xu Zheng, Chenfei-Liao | i) This paper investigates the presence and impact of modality bias in Multimodal Large Language Models (MLLMs). ii) The research aims to diagnose the current state of modality bias in MLLMs, propose a research roadmap, and identify key factors contributing to this bias. iii) The study employs empirical analysis involving missing modality evaluations on the MMMU-Pro dataset using Qwen2.5VL models, along with theoretical discussion. iv) Results show a significant reliance on textual information, with consistency between complete and text-only inputs at 56.53% compared to lower consistency with image-only inputs (27.17%), suggesting underutilization of visual modalities. v) AI practitioners should focus on balanced training strategies, optimizing multimodal integration and addressing dataset imbalances to mitigate modality bias and improve MLLM generalizability.  |
| ComfyMind: Toward General-Purpose Generation via Tree-Based Planning and
  Reactive Feedback (Read more on [arXiv](https://arxiv.org/abs/2505.17908) or [HuggingFace](https://huggingface.co/papers/2505.17908))| Jinsong Zhou, Jiantao Lin, Luozhou Wang, Xinli Xu, Litao Guo | i) ComfyMind is presented as a collaborative AI system for robust and scalable general-purpose generation based on the ComfyUI platform. ii) The research aims to address the limitations of existing open-source generative frameworks by incorporating structured workflow planning and execution-level feedback. iii) The methodology involves a Semantic Workflow Interface (SWI) that abstracts node graphs into functional modules and a Search Tree Planning mechanism with localized feedback execution. iv) ComfyMind achieves a 100% workflow pass rate on ComfyBench, improving upon the 56% of existing methods, and reaches a GPT-score of 0.906 on Reason-Edit. v) AI practitioners can utilize ComfyMind's architecture to enhance the stability and flexibility of complex generative workflows, potentially improving performance in tasks requiring modular composition and hierarchical planning.  |
| R1-ShareVL: Incentivizing Reasoning Capability of Multimodal Large
  Language Models via Share-GRPO (Read more on [arXiv](https://arxiv.org/abs/2505.16673) or [HuggingFace](https://huggingface.co/papers/2505.16673))| Yibo Wang, Min Yang, Jingyi Zhang, Qixiang Yin, Huanjin Yao | R1-ShareVL introduces Share-GRPO, a reinforcement learning approach to enhance reasoning in multimodal large language models (MLLMs). The research aims to mitigate sparse reward and advantage vanishing issues in MLLMs through reinforcement learning. Share-GRPO expands the question space using semantic transformations and shares reasoning trajectories across diverse question variants. Experiments on six reasoning benchmarks demonstrate Share-GRPO's superiority, with R1-ShareVL-7B achieving a +7.2% improvement on the MathVista benchmark compared to the baseline. AI practitioners can leverage Share-GRPO to improve MLLM reasoning by diversifying training data and stabilizing policy optimization through shared reward information.  |
| Search and Refine During Think: Autonomous Retrieval-Augmented Reasoning
  of LLMs (Read more on [arXiv](https://arxiv.org/abs/2505.11277) or [HuggingFace](https://huggingface.co/papers/2505.11277))| Junfeng Fang, Zhiyuan Liu, Chang Wu, Shihan Li, yrshi | i) AutoRefine improves retrieval-augmented reasoning in LLMs using explicit knowledge refinement and tailored rewards. ii) The research aims to enhance LLMs' reasoning capabilities by enabling iterative filtering, distilling, and organizing evidence from retrieved documents. iii) A reinforcement learning post-training framework, AutoRefine, is introduced that incorporates explicit knowledge refinement steps between search calls alongside retrieval-specific and answer correctness rewards using group relative policy optimization. iv) Experiments demonstrate AutoRefine outperforms existing approaches by 6.9% higher average accuracy, particularly in complex, multi-hop reasoning scenarios and exhibits a 20% improvement in refinement success rate. v) AI practitioners can utilize AutoRefine to improve the accuracy and robustness of LLMs in knowledge-intensive tasks by incorporating retrieval-specific rewards and explicit knowledge refinement steps, enabling more effective use of external knowledge sources.  |
| AdInject: Real-World Black-Box Attacks on Web Agents via Advertising
  Delivery (Read more on [arXiv](https://arxiv.org/abs/2505.21499) or [HuggingFace](https://huggingface.co/papers/2505.21499))| Mingyang Li, Rupeng Zhang, Xiaojun Jia, Junjie Wang, NicerWang | i) AdInject introduces a novel black-box attack vector leveraging advertising delivery to compromise Web Agents. ii) The research aims to demonstrate the vulnerability of Web Agents to environment injection attacks through advertising channels. iii) The methodology involves crafting malicious ad content and optimizing it using a VLM to infer user intents from website context. iv) Experiments show attack success rates exceeding 60% in most scenarios on VisualWebArena and approaching 100% in certain cases, demonstrating the effectiveness of the proposed attack. v) AI practitioners need to be aware of the potential for real-world advertising delivery systems to be exploited for environment injection attacks on Web Agents, necessitating the development of robust defense mechanisms.  |
| Modality Curation: Building Universal Embeddings for Advanced Multimodal
  Information Retrieval (Read more on [arXiv](https://arxiv.org/abs/2505.19650) or [HuggingFace](https://huggingface.co/papers/2505.19650))| Shi Feng, Hongzhi Zhang, Yahui Liu, Jingyuan Zhang, friedrichor | i) This paper introduces UNITE, a framework for building universal multimodal embeddings through data curation and modality-aware training configurations for multimodal information retrieval (MIR). ii) The research investigates how modality-specific data properties and training protocols influence downstream task performance in diverse MIR scenarios. iii) The methodology employs Modal-Aware Masked Contrastive Learning (MAMCL) to balance relationships among instances of different modalities, along with strategic modality curation and tailored training protocols. iv) UNITE achieves state-of-the-art results on multiple multimodal retrieval benchmarks, surpassing existing methods, including improvements of 15.7% in the temporal retrieval aspects of CaReBench. v) This work provides AI practitioners with a foundational blueprint for advancing MIR performance through strategic modality curation and tailored training protocols, particularly by addressing inter-modal interference using MAMCL.  |
| Absolute Coordinates Make Motion Generation Easy (Read more on [arXiv](https://arxiv.org/abs/2505.19377) or [HuggingFace](https://huggingface.co/papers/2505.19377))| Huaizu Jiang, Yiming Xie, Xiaogang Peng, Zeyu Han, cr8br0ze | Absolute Coordinates Make Motion Generation Easy proposes a novel motion representation for text-to-motion generation using absolute joint coordinates. The research aims to demonstrate superior performance and scalability using absolute coordinates compared to local-relative kinematic-aware representations in diffusion models. The methodology involves a diffusion model (ACMDM) with a Transformer backbone trained on absolute joint coordinates and evaluated through metrics such as FID and R-Precision. The ACMDM-XL-PS2 model achieves a FID of 0.058 and an R-Precision Top-1 score of 0.522 on the HumanML3D dataset, outperforming state-of-the-art methods. The principal implication is that employing absolute coordinates can significantly enhance motion fidelity and controllability in text-to-motion generation models, offering a more straightforward approach without complex kinematic-aware losses or auxiliary components for AI practitioners.  |
| Improving Chemical Understanding of LLMs via SMILES Parsing (Read more on [arXiv](https://arxiv.org/abs/2505.16340) or [HuggingFace](https://huggingface.co/papers/2505.16340))| Sungsoo Ahn, Jaehyung Kim, yunhuijang | i) The paper introduces CLEANMOL, a framework for enhancing Large Language Models' (LLMs) understanding of molecular structures via SMILES parsing. ii) The primary objective is to address the limitations of current LLMs in accurately interpreting SMILES strings by developing clean and deterministic parsing tasks. iii) The methodology involves pre-training LLMs on a constructed dataset with structured supervision derived from subgraph and global graph matching tasks extracted from SMILES representations, incorporating adaptive difficulty scoring and curriculum learning. iv) The results show that CLEANMOL enhances structural comprehension, achieving state-of-the-art or competitive performance on the Mol-Instructions benchmark; for instance, LLaMA3.1-8B achieved a 0.005 MAE on the Mol-Instructions molecular property regression task. v) The principal implication for AI practitioners is the demonstration that incorporating deterministic structural supervision via SMILES parsing can significantly enhance molecular generation capabilities of LLMs, even without direct exposure to generation-specific training data.  |
| Ankh3: Multi-Task Pretraining with Sequence Denoising and Completion
  Enhances Protein Representations (Read more on [arXiv](https://arxiv.org/abs/2505.20052) or [HuggingFace](https://huggingface.co/papers/2505.20052))| Ahmed Elnaggar, Mohamed Elkerdawy, Mohamed Elshaffei, hazemessam | i) Ankh3, a protein language model, leverages multi-task pretraining with sequence denoising and completion for enhanced protein representations. ii) The research investigates whether multi-task pretraining using masked language modeling with multiple masking probabilities alongside protein sequence completion improves protein representation learning. iii) Ankh3 was developed using a T5 architecture and pre-trained on UniRef50 dataset with two objectives: masked language modeling with masking probabilities of 15%, 20%, and 30% and protein sequence completion. iv) The results demonstrated improved performance in secondary structure prediction, achieving 84.4% accuracy on CASP-12, GB1 fitness, and contact prediction with Ankh3-XL. v) The multi-task pretraining strategy in Ankh3 allows for more robust and accurate protein sequence modeling, enabling AI practitioners to develop more effective downstream applications in synthetic biology and protein engineering.  |
| Beyond Simple Concatenation: Fairly Assessing PLM Architectures for
  Multi-Chain Protein-Protein Interactions Prediction (Read more on [arXiv](https://arxiv.org/abs/2505.20036) or [HuggingFace](https://huggingface.co/papers/2505.20036))| Abdallah Amr, Sara Ossman, Mohamed Soudy, Mohamed Elshaffei, hazemessam | i) This paper addresses limitations in predicting protein-protein interaction (PPI) binding affinity using protein language models (PLMs). ii) The research investigates the efficacy of various PLM architectures in sequence-based, multi-chain PPI binding affinity prediction. iii) The methodology includes curating a refined PPB-Affinity dataset, implementing stringent data splitting to mitigate leakage, and systematically evaluating four PLM architectures: embeddings concatenation (EC), sequences concatenation (SC), hierarchical pooling (HP), and pooled attention addition (PAD). iv) Results demonstrate that HP and PAD architectures outperform conventional concatenation methods, achieving up to a 12% increase in Spearman correlation (ρ); the curated PPB-Affinity dataset contains 8,207 unique PPI entries. v) The implication for AI practitioners is the necessity of sophisticated architectural designs, such as HP and PAD, to fully leverage PLMs for improved PPI binding affinity prediction, moving beyond simple concatenation strategies.  |
| An Explainable Diagnostic Framework for Neurodegenerative Dementias via
  Reinforcement-Optimized LLM Reasoning (Read more on [arXiv](https://arxiv.org/abs/2505.19954) or [HuggingFace](https://huggingface.co/papers/2505.19954))| Eloi Navet, Laurent Simon, Boris Mansencal, Nathanael Fijalkow, Andrew Zamai | i) This paper presents an explainable AI framework for the differential diagnosis of neurodegenerative dementias. ii) The research aims to improve diagnostic transparency by integrating radiology report generation from 3D brain MRIs and reinforcement learning optimized LLM reasoning. iii) The methodology involves a modular pipeline for converting 3D brain MRIs into textual reports, prompting LLMs for diagnostic reasoning, and fine-tuning with Group Relative Policy Optimization (GRPO). iv) Experiments show GRPO fine-tuning enables 8B models to match or surpass the diagnostic accuracy of larger models like GPT-40, yielding detailed reasoning grounded in neuroanatomical evidence, achieving a BACC of 84.16% and an M-F1 score of 59.55% for CN class. v) AI practitioners can leverage this framework to develop more transparent and trustworthy diagnostic systems by combining quantitative image analysis with structured language model reasoning, promoting causally grounded explanations for clinical decision-making.  |
| Tropical Attention: Neural Algorithmic Reasoning for Combinatorial
  Algorithms (Read more on [arXiv](https://arxiv.org/abs/2505.17190) or [HuggingFace](https://huggingface.co/papers/2505.17190))| Ruriko Yoshida, Chris Teska, Kurt Pasque, Baran47 | i) This paper introduces Tropical attention, a novel attention mechanism for neural algorithmic reasoning that operates in the max-plus semiring. ii) The main objective is to develop an attention mechanism that enhances out-of-distribution (OOD) generalization and robustness for dynamic programming-type combinatorial algorithms. iii) The methodology involves replacing the softmax-normalized dot-product attention with Tropical attention and proving its ability to approximate tropical circuits and enhance empirical OOD performance. iv) The primary results show that Tropical transformers achieve state-of-the-art OOD generalization in length and value scale and exhibit superior adversarial robustness across eleven combinatorial tasks, outperforming softmax baselines. v) The implication for AI practitioners is that using Tropical attention in transformers can improve OOD performance and adversarial robustness in algorithmic reasoning tasks, particularly those involving dynamic programming, without super-polynomial blow-ups.  |
| Do RAG Systems Suffer From Positional Bias? (Read more on [arXiv](https://arxiv.org/abs/2505.15561) or [HuggingFace](https://huggingface.co/papers/2505.15561))| Fabrizio Silvestri, Yoelle Maarek, Guy Horowitz, Simone Filice, florin-hf | i) This paper investigates positional bias in Retrieval Augmented Generation (RAG) systems and its impact on LLM vulnerability to distracting passages. ii) The main research question is how positional bias affects an LLM's capability to capitalize on relevant passages while also being susceptible to distracting passages in RAG systems. iii) The methodology includes experiments on three question-answering benchmarks (PopQA, Natural Questions, and TriviaQA) using BM25 and BGE for retrieval, evaluating the distracting effect of passages using a LLM-as-a-judge approach. iv) The primary result shows that current retrieval pipelines systematically bring highly distracting passages to the top ranks, with over 60% of queries containing at least one highly distracting passage among the top-10 retrieved passages. v) The principal implication for AI practitioners is that improvements in RAG systems should focus on retrieval quality and LLM distraction robustness rather than passage positioning strategies.  |
