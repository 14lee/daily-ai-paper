

## Papers for 2025-03-13

| Title | Authors | Summary |
|-------|---------|---------|
| TPDiff: Temporal Pyramid Video Diffusion Model (Read more on [arXiv](https://arxiv.org/abs/2503.09566) or [HuggingFace](https://huggingface.co/papers/2503.09566))| Mike Zheng Shou, Lingmin Ran | TPDiff is a framework that enhances video diffusion model efficiency by using progressively increasing frame rates during the diffusion process. The main research objective is to reduce the high computational demands of training and inference in video diffusion models. The key methodology is a temporal pyramid approach that divides diffusion into stages, increasing frame rate with each stage, combined with a stage-wise diffusion training framework leveraging data-noise alignment. The primary results demonstrate a 50% reduction in training cost and a 1.5x improvement in inference efficiency compared to vanilla diffusion models. For AI practitioners, TPDiff offers a method to substantially reduce computational requirements in video generation with diffusion models, enabling faster training and more efficient inference.  |
| Reangle-A-Video: 4D Video Generation as Video-to-Video Translation (Read more on [arXiv](https://arxiv.org/abs/2503.09151) or [HuggingFace](https://huggingface.co/papers/2503.09151))| Jong Chul Ye, Suhyeon Lee, hyeonho-jeong-video | Reangle-A-Video introduces a framework for generating synchronized multi-view videos from a single input video without using multi-view generative priors. The main research objective is to develop a method for synchronized multi-view video generation from a single monocular video, reframing it as a video-to-video translation task. The methodology involves two stages: (1) Multi-View Motion Learning using self-supervised fine-tuning of an image-to-video diffusion transformer on warped videos, and (2) Multi-View Consistent Image-to-Images Translation using warped and inpainted first frames guided by a multi-view stereo reconstruction network. The proposed method achieves a MEt3R score of 0.0412 for static view transport, outperforming the Vanilla CogVideoX baseline. For AI practitioners, this work provides a new approach to multi-view video generation that leverages existing image and video diffusion priors, removing the need for large-scale 4D datasets and enabling dynamic camera control and static view transport from a single video input.  |
| Block Diffusion: Interpolating Between Autoregressive and Diffusion
  Language Models (Read more on [arXiv](https://arxiv.org/abs/2503.09573) or [HuggingFace](https://huggingface.co/papers/2503.09573))| Zhixuan Qi, Zhihan Yang, Justin T Chiu, Aaron Gokaslan, Marianne Arriola | Block Diffusion Language Models (BD3-LMs) interpolate between discrete denoising diffusion and autoregressive models, enabling flexible-length generation and improved inference efficiency. The main research objective is to introduce and evaluate a class of language models that overcome limitations of both autoregressive and diffusion models, specifically addressing fixed-length generation, inference inefficiency, and perplexity gaps. The key methodology involves defining an autoregressive distribution over blocks of tokens, where the conditional probability of each block is specified by a discrete denoising diffusion model, and employing custom training algorithms and data-driven noise schedules. On the LM1B benchmark, BD3-LMs achieved a test perplexity of 28.23 with a block size of 4, outperforming previous diffusion models and closing gap with the AR perplexity of 22.88 . AI practitioners can leverage BD3-LMs for generating arbitrary-length sequences with improved likelihood modeling compared to standard diffusion models, and with parallel generation capabilities beyond autoregressive models.  |
| RewardSDS: Aligning Score Distillation via Reward-Weighted Sampling (Read more on [arXiv](https://arxiv.org/abs/2503.09601) or [HuggingFace](https://huggingface.co/papers/2503.09601))| Sagie Benaim, Guy Yariv, Itay Chachy | RewardSDS is a novel score distillation approach that aligns diffusion models with user intent using reward-weighted sampling. The main research objective is to improve the alignment of score distillation sampling (SDS) outputs with user intent in tasks such as text-to-3D generation. The key methodology is RewardSDS, which weights noise samples during score distillation based on alignment scores from a reward model, prioritizing gradients from samples yielding high-reward outputs. Primary results show that RewardSDS and RewardVSD improve over SDS and VSD on text-to-image generation, with ImageReward achieving a 7.19 LLM Grader score compared to 6.74 for the SDS baseline. AI practitioners can utilize RewardSDS as a plug-and-play module to enhance existing SDS-based methods, improving generation quality and alignment with desired reward models in various tasks, including text-to-image and text-to-3D generation.  |
| GTR: Guided Thought Reinforcement Prevents Thought Collapse in RL-based
  VLM Agent Training (Read more on [arXiv](https://arxiv.org/abs/2503.08525) or [HuggingFace](https://huggingface.co/papers/2503.08525))| Zongqing Lu, Yuanchun Shi, Junliang Xing, Yijun Yang, Tong Wei | GTR is a framework that prevents "thought collapse" in reinforcement learning-trained vision-language model (VLM) agents by integrating automated thought correction. The main research objective is to investigate and mitigate the phenomenon of "thought collapse" – a degradation of reasoning ability – observed when training VLM agents with RL in visually-grounded environments. The key methodology is Guided Thought Reinforcement (GTR), which uses an off-the-shelf VLM as a corrector to evaluate and refine the agent's chain-of-thought reasoning at each RL step, combined with SFT thought cloning and PPO updates. Primary results demonstrate that GTR significantly improves performance, achieving a 3-5x higher task success rate on the Points24 card game compared to state-of-the-art methods. Principal implication for AI practioners is that incorporating process-level guidance via automated thought correction during RL training can substantially enhance the decision-making capabilities and generalization of VLM agents in complex visual environments.  |
| More Documents, Same Length: Isolating the Challenge of Multiple
  Documents in RAG (Read more on [arXiv](https://arxiv.org/abs/2503.04388) or [HuggingFace](https://huggingface.co/papers/2503.04388))| Gabriel Stanovsky, Michael Hassid, Nir Mazor, Shahar Levy, LihiShalmon | Retrieval-augmented generation (RAG) performance can degrade with more documents, even with a fixed context length. The main research objective was to isolate the effect of the number of retrieved documents on LLM performance in RAG systems, while controlling for context length. Researchers used a modified multi-hop QA dataset (MuSiQue) to create inputs with varying numbers of documents, but a constant total token count, by expanding remaining documents when others were removed. Primary result was increasing documents from 2-4 to 20 can decrease performance by up to 10% on several tested models (Llama-3.1, Gemma-2). The principal implication is that AI practitioners should consider the number of retrieved documents in RAG systems, as increasing their number without also changing the context may worsen system performance.  |
| Quantizing Large Language Models for Code Generation: A Differentiated
  Replication (Read more on [arXiv](https://arxiv.org/abs/2503.07103) or [HuggingFace](https://huggingface.co/papers/2503.07103))| Gabriele Bavota, Saima Afrin, Antonio Mastropaolo, mdiipenta, Devy1 | This paper investigates the impact of quantizing large language models (LLMs) on code generation performance, focusing on extreme quantization levels and code-specific calibration datasets. The main research question is how low-bit quantization, different calibration datasets, and model size affect the code generation ability of LLMs. The key methodology involves quantizing CodeLlama and DeepSeek-Coder models to 8, 4, 3, and 2 bits using AQLM, with various calibration datasets, and evaluating performance on MultiPL-E and McEval benchmarks using the pass@1 metric. A primary result is that 4-bit quantization reduces model memory footprint by 70% with no significant performance decrease, while code-specific calibration datasets improve performance at more extreme (3 and 2-bit) quantization levels. AI practitioners can deploy larger code generation models on resource-constrained devices by safely quantizing LLMs down to 4 bits without sacrificing significant performance.  |
| WildIFEval: Instruction Following in the Wild (Read more on [arXiv](https://arxiv.org/abs/2503.06573) or [HuggingFace](https://huggingface.co/papers/2503.06573))| Liat Ein-Dor, Ariel Gera, Asaf Yehudai, Gili Lior | WILDIFEVAL introduces a large-scale dataset of real user instructions with multiple constraints to evaluate LLMs' instruction-following capabilities.  i)  WILDIFEVAL, a new benchmark of 12K real-world, multi-constrained user instructions, is introduced to evaluate instruction following in LLMs. ii)  The main research objective is to assess how well leading LLMs can follow complex, real-world instructions with multiple constraints. iii)  Key methodology involved collecting and curating real user instructions from Chatbot Arena, decomposing them into individual constraints, and evaluating LLM performance based on the fraction of fulfilled constraints. iv)  The best-performing model achieved a score of 0.65, and all models experienced performance degradation with an increasing number of constraints. v)  AI practitioners should focus on improving LLMs' ability to handle multiple, diverse constraints, particularly length-related constraints, to better align with realistic user needs and expectations in complex text generation tasks.  |
| VLog: Video-Language Models by Generative Retrieval of Narration
  Vocabulary (Read more on [arXiv](https://arxiv.org/abs/2503.09402) or [HuggingFace](https://huggingface.co/papers/2503.09402))| Mike Zheng Shou, KevinQHLin | VLog is a video understanding framework that defines video narrations as vocabulary and uses a generative retrieval model for efficient indexing. The main research objective is to develop a video understanding model that generates concise, contextually accurate, and efficient narrations. The key methodology involves a generative retrieval model, a hierarchical vocabulary derived from video narrations using Narration Pair Encoding, and a vocabulary update strategy leveraging generative models. VLog achieves a 20x speedup over generative models on the Vidcab-Eval dataset while maintaining comparable accuracy to retrieval models. AI practitioners can use VLog's generative retrieval approach to create more efficient video-language models, achieving faster processing speeds with accuracy, especially when handling long videos or requiring real-time responses.  |
| Cost-Optimal Grouped-Query Attention for Long-Context LLMs (Read more on [arXiv](https://arxiv.org/abs/2503.09579) or [HuggingFace](https://huggingface.co/papers/2503.09579))| Maosong Sun, Zhiyuan Liu, Xu Han, Yutong Wu, chen-yingfa | The paper investigates cost-optimal configurations for Grouped-Query Attention (GQA) in Transformer-based large language models (LLMs), focusing on trade-offs between performance, computational cost, and memory usage. The main research question is how to optimize the number of attention heads and groups in GQA to minimize computational and memory costs of LLMs while maximizing language modeling capabilities, particularly in long-context scenarios. The key methodology involves systematically comparing LLMs with varying parameter sizes, context lengths, and attention head configurations, extending existing scaling laws to account for context length and attention head configuration. A primary result is that for Llama-3.2-1B at 128K context length, using a head configuration of H=(8,1) and increasing the model size can achieve the same loss while reducing inference memory and FLOPs usage by 48.4% and 49.6% respectively, relative to the standard GQA configuration. The principal implication for AI practitioners is that commonly used GQA configurations can be significantly suboptimal, and carefully selecting the attention head configuration, based on expected inference context length, can substantially reduce computational and memory costs, enabling more efficient deployment of long-context LLMs.  |
| Alias-Free Latent Diffusion Models:Improving Fractional Shift
  Equivariance of Diffusion Latent Space (Read more on [arXiv](https://arxiv.org/abs/2503.09419) or [HuggingFace](https://huggingface.co/papers/2503.09419))| Xingang Pan, Shuai Yang, Zeqi Xiao, SingleZombie | Alias-Free Latent Diffusion Models (AF-LDM) improve the shift-equivariance of diffusion models for more consistent image generation. The main research objective is to enhance the fractional shift-equivariance of Latent Diffusion Models (LDMs) to improve consistency in applications like video editing and image-to-image translation. The key methodology involves redesigning attention modules to be shift-equivariant, proposing an equivariance loss to suppress feature bandwidth, and using cross-frame attention in both training and inference. The primary results show that AF-LDM achieves a Latent SPSNR of 40.94 and an Image SPSNR of 28.06 on the FFHQ dataset, demonstrating significantly improved shift-equivariance compared to vanilla LDM. The principal implication for AI practitioners is that they can use AF-LDM to achieve greater consistency and stability in image and video generation tasks requiring shift-equivariance, enabling improved performance in applications like video editing and image-to-image translation.  |
| Self-Taught Self-Correction for Small Language Models (Read more on [arXiv](https://arxiv.org/abs/2503.08681) or [HuggingFace](https://huggingface.co/papers/2503.08681))| Irina Nikishina, Chris Biemann, VityaVitalich | The paper introduces the Self-Taught Self-Correction (STaSC) algorithm, enabling small language models (SLMs) to improve their outputs through iterative fine-tuning on self-generated data. The main research objective is to investigate if SLMs can learn self-correction without external information or evaluators, relying solely on intrinsic knowledge. The key methodology is iterative fine-tuning of SLMs using self-generated trajectories, incorporating flexible design choices for initial answer generation, correction filtering, and fine-tuning strategy. Primary results show that on the Natural Questions dataset, the Phi3-Mini model achieved a maximum reward of 0.394 (correction, Improving filter) with Evolving Fine-tuning, with a general observation is that both models' initial answer's accuracy also increased by training to improve. The STaSC algorithm allows AI practitioners to develop and deploy more accurate and efficient SLMs, enhancing their reasoning and output quality even with limited external resources.  |
| MoC: Mixtures of Text Chunking Learners for Retrieval-Augmented
  Generation System (Read more on [arXiv](https://arxiv.org/abs/2503.09600) or [HuggingFace](https://huggingface.co/papers/2503.09600))| Simin Niu, Hanyu Wang, Zhaoxin Fan, Zhiyuan Ji, Robot2050 | This paper introduces a framework called Mixture-of-Chunkers (MoC) to improve text chunking in Retrieval-Augmented Generation (RAG) systems. The main research objective is to optimize text chunking, a commonly overlooked component of RAG, to improve the quality of retrieved content and subsequently enhance the accuracy of generated answers. The key methodology involves a three-stage process: a multi-granularity-aware router, specialized meta-chunkers, and a post-processing algorithm, using regex-guided chunking and edit-distance rectification. Primary results show that the Meta-chunker-1.5B achieved a BLEU-1 score of 0.3754, and F1 score of 0.2387 on the DuReader dataset, outperforming several baseline methods. For AI practitioners, the proposed MoC framework and evaluation metrics offer a way to enhance RAG system performance by optimizing the text chunking process, a critical yet often under-optimized component of the architecture.  |
| Multimodal Language Modeling for High-Accuracy Single Cell
  Transcriptomics Analysis and Generation (Read more on [arXiv](https://arxiv.org/abs/2503.09427) or [HuggingFace](https://huggingface.co/papers/2503.09427))| Xiang Wang, Junfeng Fang, Sihang Li, Jiaqi Yang, Yaorui Shi | scMMGPT is a multimodal pre-trained language model for joint cell and text modeling in single-cell transcriptomics. The main research objective is to develop a unified model that effectively integrates scRNA-seq data and textual descriptions to improve performance on single-cell analysis tasks. The key methodology involves integrating pre-trained cell (scGPT) and text (Llama-2) PLMs using cross-modal projectors, and pre-training on 27 million cells with tasks including cell-text representation alignment, cell description generation, and pseudo-cell generation. Primary results include an 84% relative improvement in textual discrepancy for cell description generation compared to existing methods. The principal implication for AI practitioners is that scMMGPT provides a powerful tool for single-cell analysis and generation, demonstrating superior ability to bridge the modality gap between transcriptomic data and free text descriptions.  |
| When Large Vision-Language Model Meets Large Remote Sensing Imagery:
  Coarse-to-Fine Text-Guided Token Pruning (Read more on [arXiv](https://arxiv.org/abs/2503.07588) or [HuggingFace](https://huggingface.co/papers/2503.07588))| Qi Zhu, Kang Wu, Xue Yang, Yingying Zhang, Junwei Luo | This paper introduces a text-guided token pruning method for efficient processing of large remote sensing images (RSIs) by Large Vision-Language Models (LVLMs). The main research objective is to balance image detail and computational cost when LVLMs process large RSIs. The key methodology involves a Region Focus Module (RFM) for text-aware region localization and a Dynamic Image Pyramid (DIP) for coarse-to-fine image tile selection and vision token pruning. The method achieved a 32.16% average accuracy on the new LRS-VQA benchmark, outperforming existing high-resolution strategies. AI practitioners can utilize this approach to build more efficient LVLMs for high-resolution image analysis, particularly beneficial when dealing with limited computing resources or large images.  |
| Multi Agent based Medical Assistant for Edge Devices (Read more on [arXiv](https://arxiv.org/abs/2503.05397) or [HuggingFace](https://huggingface.co/papers/2503.05397))| Pragya Sahu, Jagdish Samant, Chinmay Kulkarni, Shivam Akhouri, Sakharam Gawade | This paper introduces an on-device, multi-agent healthcare assistant that leverages task-specific agents for optimized resource utilization, privacy, and scalability. The main research objective is to develop a healthcare assistant for edge devices that addresses privacy, latency, and internet dependency challenges associated with cloud-based systems. The key methodology involves a multi-agent architecture utilizing specialized, smaller models (based on Qwen Code Instruct 2.5 7B) for tasks like intelligent diagnosis, appointment booking, emergency services, vital tracking, and reminder scheduling, combined with a data creation pipeline for synthetic data generation. The fine-tuned planner and caller agents achieved an average RougeL score of 85.5 for planning and 96.5 for calling, respectively, for appointment scheduling. This architecture enables AI practitioners to deploy robust and efficient healthcare solutions on resource-constrained edge devices, enhancing user privacy and responsiveness without relying on continuous internet access.  |
| Monte Carlo Diffusion for Generalizable Learning-Based RANSAC (Read more on [arXiv](https://arxiv.org/abs/2503.09410) or [HuggingFace](https://huggingface.co/papers/2503.09410))| Tong Zhang, Wei Ke, Chen Zhao, Jiale Wang | This paper introduces a Monte Carlo diffusion mechanism to improve the generalization of learning-based RANSAC for robust model estimation. The main research objective is to address the limited generalization of existing learning-based RANSAC methods to out-of-distribution data. The key methodology involves a diffusion-based training paradigm that progressively injects noise into ground-truth data and uses Monte Carlo sampling to approximate diverse data distributions. Primary results show that on ScanNet, the proposed method improves AUC @20° by 12% on LoFTR compared to a model trained only on SIFT. For AI practitioners, this provides a training strategy to enhance the generalization ability of learning-based RANSAC estimators across various input data distributions without retraining.  |
