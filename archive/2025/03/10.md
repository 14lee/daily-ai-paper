

## Papers for 2025-03-10

| Title | Authors | Summary |
|-------|---------|---------|
| Unified Reward Model for Multimodal Understanding and Generation (Read more on [arXiv](https://arxiv.org/abs/2503.05236) or [HuggingFace](https://huggingface.co/papers/2503.05236))| Cheng Jin, Hao Li, Jiaqiwang, yuhangzang, CodeGoat24 | This paper proposes UNIFIEDREWARD, a unified reward model for assessing both multimodal understanding and generation, enabling pairwise ranking and pointwise scoring for vision model preference alignment. The main research objective is to develop a single reward model adaptable across diverse visual tasks (image/video generation and understanding) and to demonstrate its effectiveness in aligning vision models with human preferences. The key methodology involves training a Vision Language Model (VLM) on a newly constructed, large-scale human preference dataset, then using the trained model to curate preference data for Direct Preference Optimization (DPO) of VLMs and diffusion models. Primary results show that UNIFIEDREWARD achieves 66.5% macro accuracy on VLRewardBench for image understanding assessment, outperforming existing methods. The principal implication for AI practitioners is that they can leverage this unified reward model and associated training pipeline to improve the alignment of vision models with human preferences across a range of generation and understanding tasks, leading to better output quality and overall better evaluation.  |
| EuroBERT: Scaling Multilingual Encoders for European Languages (Read more on [arXiv](https://arxiv.org/abs/2503.05500) or [HuggingFace](https://huggingface.co/papers/2503.05500))| caiocorro, ayoubhammal, DuarteMRAlves, hgissbkh, Nicolas-BZRD | EuroBERT, a family of multilingual encoder models, outperforms existing alternatives on various tasks, spanning multiple languages, mathematics, and coding. The main research objective is to revisit the development of multilingual encoders by leveraging recent advances from decoder models and examining design choices in data composition and training. Methodology includes building a 5T-token multilingual dataset, using a masked language modeling objective, and employing a two-phase training pipeline (pre-training and annealing). EuroBERT-2.1B achieves the highest performance among all systems, ranking first on 7 of 12 multilingual benchmarks, outperforming XLM-ROBERTa-XL. This implies that AI practitioners can use EuroBERT models for improved performance in NLP tasks, especially retrieval, classification and evaluation tasks across European and other widely spoken languages, even with models smaller than pre-existing state-of-the-art.  |
| Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching (Read more on [arXiv](https://arxiv.org/abs/2503.05179) or [HuggingFace](https://huggingface.co/papers/2503.05179))| Sung Ju Hwang, jinheon, saytes | Sketch-of-Thought (SoT) is a prompting framework that improves large language model (LLM) reasoning efficiency by using concise, structured intermediate steps inspired by human cognitive processes. The main research objective is to reduce the computational cost of LLM reasoning while maintaining or improving accuracy compared to verbose methods like Chain-of-Thought (CoT). The key methodology involves three cognitive-inspired paradigms (Conceptual Chaining, Chunked Symbolism, and Expert Lexicons) dynamically selected by a lightweight router model based on query characteristics. Primary results show that SoT reduces token usage by up to 76% across 15 reasoning datasets with negligible accuracy impact, and in some cases, even improved accuracy. Principal implication for AI practitioners: SoT offers a practical method to reduce computational costs and latency in LLM-based reasoning applications without significant performance degradation, enabling deployment in resource-constrained environments.  |
| Forgetting Transformer: Softmax Attention with a Forget Gate (Read more on [arXiv](https://arxiv.org/abs/2503.02130) or [HuggingFace](https://huggingface.co/papers/2503.02130))| Aaron Courville, littleowen, nikishin, zhixuan-lin | Forgetting Transformer (FoX) introduces a forget gate into the softmax attention mechanism of Transformers to improve performance, particularly in length extrapolation and short-context tasks. The main research objective is to determine if incorporating a data-dependent forget gate into Transformers can improve their performance on both long and short-context tasks. The key methodology involves modifying the softmax attention mechanism by down-weighting unnormalized attention scores based on a learned, data-dependent forget gate, implemented efficiently using a modification of the FlashAttention algorithm. Primary results show that FoX outperforms the standard Transformer in long-context language modeling, achieving a per-token loss of approximately 1.53 compared to Transformer's ~1.58 at the 32,000 token index (Figure 2, left) in a configuration with a 760M parameter. Principal implication for AI practitioners is that the FoX architecture could improve performance in some sequential tasks and serves as a strong baseline, especially in tasks needing to balance long- and short-context information, with the Pro architecture being the most promising.  |
| VideoPainter: Any-length Video Inpainting and Editing with Plug-and-Play Context Control (Read more on [arXiv](https://arxiv.org/abs/2503.05639) or [HuggingFace](https://huggingface.co/papers/2503.05639))| Zhaoyang Zhang, yshan2u, Ljzycmd, juxuan27, BianYx | VideoPainter introduces a dual-branch framework for text-guided video inpainting and editing that maintains ID consistency in long videos. The research objective is to develop a method for video inpainting that addresses challenges such as generating fully masked objects, balancing background preservation with foreground generation, and maintaining identity consistency over long videos. The key methodology involves a lightweight context encoder within a dual-branch Diffusion Transformer architecture, and a novel inpainting region ID resampling technique. Primary results include achieving a FVID score of 0.09 on the VPBench dataset for standard video inpainting surpassing competing methods. The principal implication is that AI practitioners can leverage this framework for more effective and controllable video inpainting and editing, with robust performance in generating long videos and maintaining object identity due to its sampling technique.  |
| R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2503.05592) or [HuggingFace](https://huggingface.co/papers/2503.05592))| jrwen, TimothyCzp, EliverQ, Boru, XXsongLALA | R1-Searcher is a two-stage outcome-based reinforcement learning (RL) framework to enhance search capabilities in large language models (LLMs). The main research objective is to enable LLMs to autonomously invoke external search systems for accessing additional knowledge during reasoning. The key methodology is a two-stage RL approach: first incentivizing retrieval invocation, then rewarding accurate answer generation using retrieved information, with RAG-based rollout and retrieval mask-based loss calculation. The primary results are, using Qwen-2.5-7B-Base, R1-Searcher outperforms ReARTeR by 48.22% on HotpotQA and by 21.72% on 2Wiki. The principal implication is that AI practitioners can use this RL method to train LLMs to effectively integrate external search, improving reasoning and generalization, even in out-of-domain and online search scenarios.  |
| R1-Omni: Explainable Omni-Multimodal Emotion Recognition with Reinforcing Learning (Read more on [arXiv](https://arxiv.org/abs/2503.05379) or [HuggingFace](https://huggingface.co/papers/2503.05379))| Xihan Wei, Liefeng, StarJiaxing | The paper introduces R1-Omni, an omni-multimodal model for emotion recognition using Reinforcement Learning with Verifiable Reward (RLVR). The main research objective is to investigate the potential of RLVR in enhancing emotion recognition performance in a video-based, omni-multimodal setting (incorporating both visual and audio data). Key methodology involves applying RLVR with Group Relative Policy Optimization (GRPO) to a HumanOmni model, using a verifiable reward function that combines accuracy and format rewards, after a cold start using the EMER dataset. Primary results show that R1-Omni achieves a UAR of 65.83% and a WAR of 56.27% on the DFEW dataset, outperforming Supervised Fine-Tuning (SFT) models. For AI practitioners, the principal implication is that RLVR can significantly improve the reasoning capability, emotion recognition accuracy, and generalization ability of multimodal large language models in tasks such as emotion recognition, without explicit reasoning-process supervision.  |
| TrajectoryCrafter: Redirecting Camera Trajectory for Monocular Videos via Diffusion Models (Read more on [arXiv](https://arxiv.org/abs/2503.05638) or [HuggingFace](https://huggingface.co/papers/2503.05638))| Mark YU, yshan2u, Doubiiu, wbhu-tc | TrajectoryCrafter redirects camera trajectories in monocular videos using diffusion models. The research objective is to generate high-fidelity videos from monocular inputs with user-defined camera trajectories, ensuring 4D consistency. The methodology uses a dual-stream conditional video diffusion model that integrates point cloud renders and source videos, trained on a hybrid dataset of monocular and multi-view data using a double-reprojection strategy. The method achieved a PSNR of 14.24 on the iPhone multi-view dataset, outperforming existing methods. AI practitioners can use this framework to generate videos with controlled camera movements from single-camera footage, enhancing video content creation and editing capabilities.  |
| BEHAVIOR Robot Suite: Streamlining Real-World Whole-Body Manipulation for Everyday Household Activities (Read more on [arXiv](https://arxiv.org/abs/2503.05652) or [HuggingFace](https://huggingface.co/papers/2503.05652))| Ruohan Zhang, jiajunwu, cgokmen, yjze, yunfanj | BEHAVIOR ROBOT SUITE (BRS) is a framework for learning whole-body manipulation for household tasks. The main research objective is to identify and address the key capabilities required for robots to perform everyday household activities successfully. The key methodology used is a combination of a cost-effective whole-body teleoperation interface (JoyLo) for data collection, and a novel imitation learning algorithm (Whole-Body VisuoMotor Attention policy, WB-VIMA) for modeling coordinated whole-body actions. The trained WB-VIMA policies achieved an average success rate of 58% and a peak success rate of 93% across five challenging household tasks. For AI practitioners, BRS provides an integrated framework for whole-body manipulation, offering open-source hardware and software to facilitate data collection and policy learning for real-world robotic applications, streamlining the development of robots capable of diverse household tasks.  |
| RuCCoD: Towards Automated ICD Coding in Russian (Read more on [arXiv](https://arxiv.org/abs/2502.21263) or [HuggingFace](https://huggingface.co/papers/2502.21263))| Vladimir Makharev, Airat Valiev, Ivan Sviridov, Andrey Sakhovskiy, Aleksandr Nesterov | This paper introduces RuCCoD, a new Russian-language dataset for automated ICD coding, and benchmarks several state-of-the-art models for this task. The main research objective is to investigate the feasibility of automating clinical coding in Russian, a language with limited biomedical resources. The key methodology involves training and evaluating BERT-based, LLaMA-based (with LoRA and RAG), models on the RuCCoD dataset, and applying the best model to a larger EHR dataset for diagnosis prediction. Primary results show that pre-training a Longformer model on automatically assigned ICD codes (using the new proposed dataset) yields a 28% higher macro-averaged F1-score for diagnosis prediction compared to using physician-assigned codes. For AI practitioners, using an automated pipeline to generate ICD codes for model training can significantly improve diagnosis prediction accuracy in resource-limited languages like Russian.  |
| TinyR1-32B-Preview: Boosting Accuracy with Branch-Merge Distillation (Read more on [arXiv](https://arxiv.org/abs/2503.04872) or [HuggingFace](https://huggingface.co/papers/2503.04872))| lwher1996, yuhanwuuu, xiaoqijiang, zhaoguangxiang, lincharliesun | TinyR1-32B-Preview is a new language model that improves accuracy on reasoning tasks using a branch-merge distillation approach. The main objective is to create a smaller, high-performing Large Language Model (LLM) with reduced computational cost and time, compared to traditional distillation methods. The key methodology involves a two-phase distillation: (1) "Branch Phase," where a large teacher model's knowledge is selectively distilled into specialized student models via domain-specific supervised fine-tuning, and (2) "Merge Phase," where specialized models are combined using Arcee Fusion. The primary result is that TinyR1-32B-Preview outperforms DeepSeek-R1-Distill-Qwen-32B by 5.5 points in Mathematics on the AIME 2024 benchmark. The principal implication is to provide AI practioners, a scalable solution for creating smaller, more efficient LLMs, and a means of achieving high accuracy on specific benchmarks, while potentially reducing the computational and time resources needed.  |
| ProReflow: Progressive Reflow with Decomposed Velocity (Read more on [arXiv](https://arxiv.org/abs/2503.04824) or [HuggingFace](https://huggingface.co/papers/2503.04824))| Yu Li, Xuefei Ning, Haohang Xu, Lei Ke, Ringo1110 | ProReflow improves flow matching in diffusion models for faster image and video generation by progressively refining the diffusion process and emphasizing directional alignment in velocity prediction. The main research objective is to address the high computational cost of diffusion models by optimizing the flow matching training process. The key methodology involves progressive reflow (refining diffusion models in stages with decreasing timesteps) and aligned v-prediction (prioritizing velocity direction matching over magnitude). Primary results show that on the MSCOCO2014 validation set, ProReflow-II achieves an FID of 10.70 with only 4 sampling steps. For AI practitioners, ProReflow offers a more efficient training framework for flow-based diffusion models, achieving state-of-the-art performance with reduced sampling steps, directly benefiting applications requiring fast image/video synthesis.  |
| Linear-MoE: Linear Sequence Modeling Meets Mixture-of-Experts (Read more on [arXiv](https://arxiv.org/abs/2503.05447) or [HuggingFace](https://huggingface.co/papers/2503.05447))| Yu Cheng, Tong Zhu, Xiaoye08, landisen, weigao266 | Linear-MoE integrates linear sequence modeling (LSM) with Mixture-of-Experts (MoE) for efficient large-scale model training. The paper explores the objective of combining the benefits of LSM and MoE to improve performance and training efficiency in large models. The methodology involves developing a system with modeling and training subsystems, including sequence parallelism tailored for LSM and hybrid models with standard Transformer-MoE layers. Evaluations on A0.3B-2B and A1B-7B models show Linear-MoE achieves efficiency gains while maintaining competitive performance across various benchmarks. Linear-MoE offers AI practitioners a potential next-generation foundational model architecture by enhancing efficiency and scalability in large language models.  |
| Learning from Failures in Multi-Attempt Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2503.04808) or [HuggingFace](https://huggingface.co/papers/2503.04808))| Jie Fu, Stephen Chung, wydu | i) The paper introduces a multi-attempt reinforcement learning task to enhance reasoning in large language models (LLMs) by providing feedback on incorrect responses. ii) The research aims to improve LLMs' reasoning capabilities by training them to refine responses based on feedback in a multi-attempt setting. iii) The methodology involves training an LLM with standard Proximal Policy Optimization (PPO) on a math problem dataset, modifying the task to allow multiple attempts with feedback after each incorrect answer. iv) The primary result shows that an LLM trained on the multi-attempt task improves accuracy on math benchmarks from 45.6% to 52.5% with two attempts, compared to a marginal improvement from 42.3% to 43.2% for the same LLM trained on a standard single-turn task. v) The principal implication for AI practitioners is that training LLMs with multi-attempt tasks can lead to better self-refinement capabilities and improved performance in reasoning tasks, offering a more effective approach compared to single-turn training.  |
| An Empirical Study on Eliciting and Improving R1-like Reasoning Models (Read more on [arXiv](https://arxiv.org/abs/2503.04548) or [HuggingFace](https://huggingface.co/papers/2503.04548))| daixuancheng, Boru, ToheartZhang, EliverQ, TimothyCzp | i) This paper presents an empirical study on improving reasoning capabilities in Large Language Models (LLMs) through Reinforcement Learning (RL) and tool manipulation. ii) The main objective is to investigate methods for eliciting and enhancing R1-like reasoning in LLMs, focusing on scaling RL training and using tool manipulation techniques. iii) The study employs RL training with various hyperparameter settings and reward designs, alongside supervised fine-tuning to enable tool manipulation. iv) The primary result is that RL training improves QWEN2.5-32B base models, achieving 39.33% accuracy on AIME 2024 for a fine-tuned model; furthermore, tool manipulation achieved 86.67% accuracy with greedy search on AIME 2024. v) The findings suggest that scaling RL training and incorporating tool manipulation are effective strategies for AI practitioners to enhance reasoning performance in LLMs, offering a path to improve model capabilities in complex tasks.  |
| SAGE: A Framework of Precise Retrieval for RAG (Read more on [arXiv](https://arxiv.org/abs/2503.01713) or [HuggingFace](https://huggingface.co/papers/2503.01713))| Jinyang Su, Guoliang Li, jt-zhang | i) The paper introduces SAGE, a RAG framework enhancing retrieval precision through semantic segmentation, gradient-based chunk selection, and LLM self-feedback. ii) The primary objective is to improve the accuracy and cost-efficiency of RAG systems by addressing limitations in corpus segmentation and context retrieval. iii) The methodology involves training a semantic segmentation model, developing a gradient-based chunk selection algorithm, and implementing an LLM-based self-feedback mechanism for context adjustment. iv) Experiments show SAGE outperforms baselines by 61.25% in QA quality on average and achieves a 49.41% enhancement in cost efficiency. v) SAGE offers AI practitioners a more effective and cost-efficient RAG system by improving the precision of retrieved context, which reduces LLM token consumption and increases QA accuracy.  |
| LONGCODEU: Benchmarking Long-Context Language Models on Long Code Understanding (Read more on [arXiv](https://arxiv.org/abs/2503.04359) or [HuggingFace](https://huggingface.co/papers/2503.04359))| Ge Li, Kechi Zhang, Lei Li, Xuyuan Guo, Jia Li | LONGCODEU is introduced as a new benchmark to evaluate long code understanding in LLMs. The primary objective is to assess LLMs' abilities in code unit perception, intra-code unit understanding, inter-code unit relation understanding, and long code documentation understanding. The methodology involves curating a dataset from real-world code repositories with varying code lengths and evaluating LLMs on eight different tasks spanning the four understanding aspects. Experimental results showed that LLMs’ performance significantly degrades when processing code longer than 32K tokens, and the inter-code unit relation understanding is the most challenging aspect; for example, DeepSeek-V2.5 achieves 11.75% average improvements on the benchmarks tasks. This benchmark provides AI practitioners with a means to identify limitations and guide development of LLMs for software engineering tasks requiring long code context.  |
| LoRACode: LoRA Adapters for Code Embeddings (Read more on [arXiv](https://arxiv.org/abs/2503.05315) or [HuggingFace](https://huggingface.co/papers/2503.05315))| bindsch, amanchadha, shollercoaster | LoRACode introduces a parameter-efficient fine-tuning method for code embeddings using Low-Rank Adaptation (LoRA). The research investigates whether LoRA adapters can improve code retrieval accuracy while minimizing computational costs. The methodology involves fine-tuning CodeBERT, GraphCodeBERT, and UniXcoder with LoRA on code corpora, creating task-specific and language-specific adapters. Experiments showed an increase of up to 9.1% in Mean Reciprocal Rank (MRR) for Code2Code search and up to 86.69% for Text2Code search tasks. LoRA's efficient fine-tuning, utilizing only 1.83%-1.85% of base model parameters, allows AI practitioners to rapidly adapt code embedding models for improved semantic code search with reduced computational resources.  |
| R1-Zero's "Aha Moment" in Visual Reasoning on a 2B Non-SFT Model (Read more on [arXiv](https://arxiv.org/abs/2503.05132) or [HuggingFace](https://huggingface.co/papers/2503.05132))| Minhao Cheng, Ruochen Wang, zhoutianyi, AIcell, Dolphin42 | This paper demonstrates emergent visual reasoning capabilities in a 2B parameter language model through reinforcement learning, without supervised fine-tuning. The main research objective was to replicate the "aha moment" and increased response length observed in DeepSeek-R1 in a multimodal setting, specifically for visual reasoning. The key methodology involved applying the GRPO algorithm, a variant of PPO, directly to a non-SFT Qwen2-VL-2B base model, using a rule-based reward function based on response format and correctness on the SAT dataset. The primary result was that the model achieved 59.47% accuracy on CVBench, outperforming the base model by approximately 30% and the SFT model by about 2%. Principal implication for AI practioners is that reinforcement learning can induce sophisticated reasoning in multimodal models without requiring extensive supervised data, offering a more scalable approach to training.  |
| AnyAnomaly: Zero-Shot Customizable Video Anomaly Detection with LVLM (Read more on [arXiv](https://arxiv.org/abs/2503.04504) or [HuggingFace](https://huggingface.co/papers/2503.04504))| Inpyo Hong, Sein Kwon, Kijung Lee, jyy1551, SkiddieAhn | AnyAnomaly is a zero-shot customizable video anomaly detection (C-VAD) method that leverages Large Vision-Language Models (LVLMs). The main research objective is to develop a VAD system that can detect user-defined anomalies in diverse environments without requiring retraining or environment-specific data. The key methodology involves a segment-level approach using a Key frames Selection Module, a context-aware Visual Question Answering (VQA) with position and temporal contexts, and a prompt designed specifically for anomaly scoring. The proposed model, AnyAnomaly, achieved a 9.88% performance improvement over the baseline on the Customizable-ShT (C-ShT) dataset and state-of-the-art on the UBnormal dataset. AI practitioners can deploy VAD in new scenarios without additional training or data collection by providing user-defined text descriptions of anomalies.  |
