

## Papers for 2025-02-14

| Title | Authors | Summary |
|-------|---------|---------|
| InfiniteHiP: Extending Language Model Context Up to 3 Million Tokens on a Single GPU (Read more on [arXiv](https://arxiv.org/abs/2502.08910) or [HuggingFace](https://huggingface.co/papers/2502.08910))| Sung Ju Hwang, Losif63, geonp, gmlwns5176 | InfiniteHiP enables extremely long-context language model inference on a single GPU without significant performance loss. The main research objective is to develop a training-free framework that allows large language models (LLMs) to handle context lengths significantly exceeding their pre-trained limits on a single GPU. The key methodology involves a hierarchical pruning algorithm to optimize key-value (KV) cache, combined with a novel block sparse attention mechanism and dynamic RoPE adjustments. The primary result is that InfiniteHiP achieves a 7.24x speedup in the SGLang framework with only 0.34% of the VRAM used by FlashAttention2, while extending context to 3 million tokens on a single GPU. A Principal implication for AI practitioners, is that it can be a framework of efficient, long context inference that utilizes modularized pruning algorithm.  |
| Skrr: Skip and Re-use Text Encoder Layers for Memory Efficient Text-to-Image Generation (Read more on [arXiv](https://arxiv.org/abs/2502.08690) or [HuggingFace](https://huggingface.co/papers/2502.08690))| Se Young Chun, Jae-sun Seo, Wongi Jeong, Agorium | Skrr is a method for reducing text encoder memory usage in text-to-image diffusion models by selectively skipping or reusing layers. The main research question is how to reduce the memory footprint of text encoders in text-to-image (T2I) diffusion models without significantly impacting image quality or text alignment. The key methodology, Skrr, involves two phases: "Skip" identifies and prunes redundant transformer sub-blocks using a T2I diffusion-tailored discrepancy metric and beam search, and "Re-use" recycles remaining layers to mitigate performance loss. Skrr maintains image quality comparable to the original model, and achieves up to 20.4% improvement in GenEval scores at over 40% sparsity. The principal implication for AI practitioners is that Skrr offers an effective strategy for constructing memory-efficient T2I models, which could also help the development and deployment of text-to-image diffusion models, especially in resource-constrained environments.  |
| SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2502.09604) or [HuggingFace](https://huggingface.co/papers/2502.09604))| Hu Xu, Shannon Zejiang Shen, ZhaofengWu, bencw, voidism | SelfCite is a self-supervised framework that aligns large language models (LLMs) to generate accurate, fine-grained citations by leveraging their own probabilities for necessity and sufficiency rewards through context ablation. The main research objective is to improve the accuracy and quality of citations generated by LLMs without relying on annotation processes. The key methodology involves using context ablation to calculate a reward signal based on two metrics, necessity score (probability drop) and sufficiency score (probability hold), and best-of-N sampling to generate better citations. The primary result is that SelfCite significantly improves citation correctness on the LongBench-Cite benchmark, increasing citation F1 up to 5.3 points on the LongBench-Cite benchmark across five long-form question answering tasks. For AI practitioners, SelfCite offers a method to improve citation quality in LLM-generated text without requiring human annotation, potentially leading to more reliable and trustworthy LLM applications.  |
| An Open Recipe: Adapting Language-Specific LLMs to a Reasoning Model in One Day via Model Merging (Read more on [arXiv](https://arxiv.org/abs/2502.09056) or [HuggingFace](https://huggingface.co/papers/2502.09056))| Kasima Tharnpipitchai, potsawee, pittawat, kunato | This paper demonstrates a method for enhancing reasoning capabilities in language-specific large language models (LLMs) using model merging and data selection within a limited computational budget. The main research objective is to incorporate the advanced reasoning abilities of a model like DeepSeek R1 into a Thai language-specific LLM while preserving its target language performance. The key methodology involves supervised fine-tuning of the language-specific LLM on a curated dataset, followed by ability-aware model merging with a reasoning-focused LLM, optimizing the merge ratio across layers. A primary result is that the merged model, Typhoon2-R1-70B, achieved 76.5% average performance across all evaluation metrics, 41.6% above Typhoon2 70B Instruct and 12.8% above DeepSeek R1 70B Distill. This approach allows AI practitioners to improve reasoning in low-resource language LLMs efficiently, using publicly available datasets and modest computational resources.  |
| Exploring the Potential of Encoder-free Architectures in 3D LMMs (Read more on [arXiv](https://arxiv.org/abs/2502.09620) or [HuggingFace](https://huggingface.co/papers/2502.09620))| delinqu, Tavish9, zhuhaow, Purple1288, IvanTang | This paper investigates encoder-free architectures for 3D Large Multimodal Models (LMMs), demonstrating comparable performance to encoder-based models. The main research objective is to determine if 3D LMMs can effectively function without dedicated 3D encoders, directly integrating 3D understanding capabilities within the Large Language Model (LLM). The key methodology involves proposing LLM-embedded Semantic Encoding during pre-training and Hierarchical Geometry Aggregation during instruction tuning, replacing the traditional 3D encoder with learnable LLM layers and self-supervised losses. The primary result is that the proposed ENEL model, without a 3D encoder, achieved a GPT-4 score of 50.92% on 3D object captioning, which is similar with the state-of-the-art ShapeLLM-13B. The principal implication is that AI practitioners can explore encoder-free 3D LMMs as a potentially more efficient and scalable alternative to encoder-based architectures, potentially simplifying model design and reducing computational overhead.  |
| Can this Model Also Recognize Dogs? Zero-Shot Model Search from Weights (Read more on [arXiv](https://arxiv.org/abs/2502.09619) or [HuggingFace](https://huggingface.co/papers/2502.09619))| Yedid Hoshen, Or Nathan, Jonathan Kahana, Eliahu | This paper introduces ProbeLog, a method for retrieving classification models capable of recognizing a specific target concept based on model weights, without access to training data or metadata. The main research question is how to efficiently and accurately search for models in large repositories that can recognize a given concept (e.g., "Dog") in a zero-shot manner. ProbeLog uses a probing-based approach, computing logit-level descriptors by observing model responses to a fixed set of input probes, and extends this to zero-shot search via text alignment models. The method achieved a top-1 retrieval accuracy of 43.8% on the INet-Hub dataset when searching for models recognizing ImageNet concepts from text prompts. AI practitioners can use ProbeLog to search for suitable pre-trained models based on specific concept recognition capabilities, potentially reducing the need for training or fine-tuning.  |
| CoSER: Coordinating LLM-Based Persona Simulation of Established Roles (Read more on [arXiv](https://arxiv.org/abs/2502.09082) or [HuggingFace](https://huggingface.co/papers/2502.09082))| Rui Xu, Xinfeng Yuan, Yifei Zhang, Heng Wang, Xintao Wang | CoSER is a framework for simulating established characters using large language models (LLMs), including a dataset, models, and an evaluation protocol. The main research objective is to address the lack of authentic character datasets and nuanced evaluation methods for simulating established characters with LLMs. The key methodology is given-circumstance acting (GCA), where LLMs sequentially portray multiple characters in book scenes, used for both training and evaluation. Primary results show that CoSER 70B achieves 75.80% and 93.47% accuracy on the InCharacter and LifeChoice benchmarks, respectively, surpassing or matching GPT-4o. The principal implication for AI practitioners is that they can leverage the CoSER dataset and GCA framework to train and evaluate LLMs for more faithful and nuanced role-playing of established characters, improving applications like character chatbots and agents in games.  |
| TripoSG: High-Fidelity 3D Shape Synthesis using Large-Scale Rectified Flow Models (Read more on [arXiv](https://arxiv.org/abs/2502.06608) or [HuggingFace](https://huggingface.co/papers/2502.06608))| Yuan Liang, Dehu Wang, Zexiang Liu, Zi-Xin Zou, Yangguang Li | TripoSG is a new image-to-3D generation model that leverages large-scale rectified flow transformers to achieve high-fidelity 3D shape synthesis. The main research objective is to determine the optimal paradigm for generating high-fidelity 3D models with precise alignment to input images. The key methodology involves a large-scale rectified flow transformer trained on 2 million high-quality 3D samples, a hybrid supervised 3D VAE training strategy, and a dedicated data processing pipeline. Primary results show that TripoSG achieves a Normal-FID score of 3.36 when trained on a large-scale dataset with 4096 tokens and a mixture-of-experts model. The model demonstrates that AI practitioners can now utilize large-scale generative techniques to effectively generate detailed, high-fidelity and accurate 3D models from single input images which are consistent with the input.  |
| EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents (Read more on [arXiv](https://arxiv.org/abs/2502.09560) or [HuggingFace](https://huggingface.co/papers/2502.09560))| Cheng Qian, Mark Zhao, Junyu Zhang, Rui Yang, Hanyang81 | EmbodiedBench is a benchmark for evaluating vision-driven embodied agents based on multi-modal large language models (MLLMs).  Main research question or objective: How do existing MLLMs perform as vision-driven embodied agents across a variety of tasks and capabilities, and what are their limitations?  Key methodology used: Developed a benchmark (EMBODIEDBENCH) with 1,128 testing instances across four environments, hierarchical action levels (high-level and low-level), and six capability-oriented subsets, then evaluated 13 proprietary and open-source MLLMs using a unified agent framework.  Primary results: MLLMs excel at high-level tasks but struggle with low-level manipulation; the best model, GPT-4o, scored only 28.9% on average across all tasks in the benchmark, and performance degrades by 40%-70% when vision input is removed in low-level tasks.  Principal implication for AI practitioners: AI practitioners should focus on improving MLLMs' low-level manipulation, long-horizon planning and use additional approaches for leveraging visual input for high-level embodied tasks since the best model performs poorly in low-level tasks.  |
| Typhoon T1: An Open Thai Reasoning Model (Read more on [arXiv](https://arxiv.org/abs/2502.09042) or [HuggingFace](https://huggingface.co/papers/2502.09042))| Kunat Pipatanakul, Kasima Tharnpipitchai, Potsawee Manakul, pittawat | Typhoon T1 is an open-source Thai reasoning model built on a large language model, demonstrating a method for developing reasoning capabilities in low-resource languages. The primary research objective was to develop a Thai reasoning model and investigate effective strategies for its creation, including thinking formats and data composition. The key methodology involved supervised fine-tuning of a pre-trained language model (Typhoon 2 3B Instruct) using synthetically generated datasets with structured, semi-structured, and unstructured reasoning chains. A primary result was that the structured thinking format achieved a GSM8K score of 62.02, outperforming unstructured and semi-structured formats. The principal implication for AI practitioners is that supervised fine-tuning with structured synthetic data can effectively create reasoning models, particularly in low-resource languages, providing a viable alternative to reinforcement learning.  |
| Logical Reasoning in Large Language Models: A Survey (Read more on [arXiv](https://arxiv.org/abs/2502.09100) or [HuggingFace](https://huggingface.co/papers/2502.09100))| Chaoli Zhang, Mengru Ding, Hanmeng Liu, ruoxining, HarryFu | This survey synthesizes advancements in logical reasoning within large language models (LLMs), covering paradigms, benchmarks, enhancement methods, and future directions. The main research objective is to provide a comprehensive overview of logical reasoning capabilities in LLMs, focusing on formal symbolic logic rather than general heuristic approaches. The key methodology involves a literature review analyzing existing capabilities across deductive, inductive, abductive, and analogical reasoning, as well as assessing strategies like data-centric tuning, reinforcement learning, and neuro-symbolic approaches. A primary result is that while GPT-4 outperforms ChatGPT on benchmarks like LogiQA and ReClor, both models struggle with out-of-distribution tasks. The principal implication for AI practitioners is the need for hybrid architectures and improved evaluation frameworks that stress-test robustness and generalization in logical reasoning, moving beyond simple accuracy metrics to assess consistency and explainability.  |
| MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency (Read more on [arXiv](https://arxiv.org/abs/2502.09621) or [HuggingFace](https://huggingface.co/papers/2502.09621))| Yu Qi, Yanwei Li, Ziyu Guo, Renrui Zhang, CaraJ | MME-CoT is a benchmark for evaluating Chain-of-Thought (CoT) reasoning in Large Multimodal Models (LMMs), assessing quality, robustness, and efficiency. The main research objective is to investigate to what extent and how CoT reasoning benefits multimodal challenges in LMMs. Researchers curated a dataset with six domains and proposed novel metrics that meticulously examines LMMs reasoning quality, robustness and efficiency at a fine-grained level. The evaluation reveals that Kimi k1.5 achieved the best CoT quality with 64.2 F1-score, surpassing GPT-4o, and CoT prompting often degrades LMM performance on perception-heavy tasks. For AI practitioners, the results provide insights into the strengths and weaknesses of applying CoT to LMMs, especially highlighting that careful consideration is needed when employing CoT in tasks requiring strong perceptual capabilities.  |
| CoT-Valve: Length-Compressible Chain-of-Thought Tuning (Read more on [arXiv](https://arxiv.org/abs/2502.09601) or [HuggingFace](https://huggingface.co/papers/2502.09601))| Xinchao Wang, Gongfan Fang, Runpeng Yu, Guangnian Wan, Xinyin Ma | CoT-Valve introduces a method for tuning language models to generate reasoning chains of controllable lengths, improving efficiency and adaptability. The main research objective is to enable a single model to dynamically adjust the length of its Chain-of-Thought (CoT) reasoning based on task difficulty. The key methodology involves identifying and manipulating a direction in the parameter space (using LoRA) that controls CoT length, along with a "MixChain" dataset for training. A primary result is that on GSM8K, the QwQ-32B-Preview model reduced reasoning chains from 741 to 225 tokens with a minor performance drop (95.07% to 94.92%). Principal implication for AI practioners is that it enables more efficient inference by allowing models to use shorter reasoning paths for simpler tasks, which can improve the cost-effectiveness of reasoning-based application.  |
| SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2502.09390) or [HuggingFace](https://huggingface.co/papers/2502.09390))| Moshe Wasserblat, Gad Markovits, Moshe Berchansky, danf | SQuARE is a prompting technique that improves large language model reasoning by generating and answering sub-questions before addressing the main query. The main research objective is to assess if decomposing queries into iterative steps via self-interrogation enhances the reasoning capabilities of LLMs. The key methodology is prompting LLMs (Llama 3 and GPT-4o) to generate and resolve multiple auxiliary question-answer pairs before answering the original question, across multiple QA datasets (TriviaQA, HotpotQA, ASQA). Primary results show that SQuARE improves performance on TriviaQA by 6.5% over Retrieval-Augmented Generation (RAG) using the Llama-3.2 3B model. For AI practitioners, SQuARE presents a method for improving response accuracy in reasoning tasks by systematically decomposing questions, particularly beneficial for smaller-scale models.  |
| mmE5: Improving Multimodal Multilingual Embeddings via High-quality Synthetic Data (Read more on [arXiv](https://arxiv.org/abs/2502.08468) or [HuggingFace](https://huggingface.co/papers/2502.08468))| Ziliang Zhao, Yutao Zhu, Nan Yang, Liang Wang, Haon-Chen | mmE5 enhances multimodal multilingual embeddings through a novel synthetic data generation framework. The research objective is to improve multimodal embedding performance by addressing the scarcity of high-quality labeled multimodal data. The methodology involves synthesizing datasets using an MLLM, guided by principles of broad scope, robust cross-modal alignment, and high fidelity, incorporating deep thinking, self-evaluation, and refinement. mmE5 achieves a state-of-the-art average score of 58.6 on the MMEB benchmark in a zero-shot setting, surpassing previous methods. AI practitioners can leverage mmE5's synthetic data generation approach to create more robust and generalizable multimodal embedding models, particularly in multilingual contexts.  |
| The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of Physical Concept Understanding (Read more on [arXiv](https://arxiv.org/abs/2502.08946) or [HuggingFace](https://huggingface.co/papers/2502.08946))| Shunchi Zhang, Tsz Ting Chung, Junjie Wu, Lemao Liu, Mo Yu | The paper introduces PHYSICO, a benchmark to evaluate large language models' (LLMs) understanding of physical concepts, revealing significant gaps compared to human performance. The primary research objective is to investigate whether LLMs truly understand physical concepts or merely act as "stochastic parrots." The key methodology is a summative assessment using grid-format inputs to represent physical phenomena, and comparing LLM performance with human performance across various subtasks. Results indicate that state-of-the-art LLMs, like GPT-4, perform perfectly on low-level tasks(>95% accuracy) but lag behind humans on high-level tasks (~40% less in accuracy) . For AI practitioners, the principal implication is that LLMs still lack robust physical concept understanding beyond memorization, suggesting a need for new methods to improve their reasoning ability.  |
| DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References (Read more on [arXiv](https://arxiv.org/abs/2502.09614) or [HuggingFace](https://huggingface.co/papers/2502.09614))| Li Yi, Yuzhe Qin, Qianwei Han, Jianibieke Adalibieke, Xueyi Liu | DexTrack is a neural tracking controller that learns to manipulate objects with a robotic hand by following human-provided kinematic references. The main research objective is to develop a generalizable neural tracking controller for dexterous manipulation that can mimic human-object interaction trajectories. The key methodology involves iteratively training the controller with reinforcement and imitation learning, using a homotopy optimization method to mine high-quality robot tracking demonstrations from human references. The primary results show that DexTrack achieves over a 10% improvement in success rates compared to leading baselines in both simulation and real-world evaluations. AI practitioners can leverage DexTrack's approach of combining imitation learning with high-quality demonstrations to create versatile and robust controllers for complex robotic manipulation tasks.  |
| 3CAD: A Large-Scale Real-World 3C Product Dataset for Unsupervised Anomaly (Read more on [arXiv](https://arxiv.org/abs/2502.05761) or [HuggingFace](https://huggingface.co/papers/2502.05761))| Yuanwei Ma, Wenbo Guo, Hanyang Sun, Peng Xing, enquan2022 | 3CAD, a large-scale real-world dataset for unsupervised anomaly detection in 3C products, is introduced along with a coarse-to-fine detection paradigm. The main research objective is to create a challenging benchmark dataset of 3C product defects and develop an effective unsupervised anomaly detection method. The key methodology, CFRG, combines knowledge distillation, recovery guidance, and a segmentation network for coarse-to-fine localization of anomalies. CFRG achieves 93.4% AUROC, 86.5% AUPRO, and 82.0% AP on the 3CAD dataset. The principal implication for practitioners is the 3CAD dataset and CFRG model provide a challenging benchmark and an effective baseline for unsupervised anomaly detection in real-world 3C product manufacturing.  |
