

## Papers for 2025-02-24

| Title | Authors | Summary |
|-------|---------|---------|
| SurveyX: Academic Survey Automation via Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2502.14776) or [HuggingFace](https://huggingface.co/papers/2502.14776))| UglyToilet, Ki-Seki, siminniu, fan2goa1, HaruTeru | SURVEYX is a system for automated academic survey generation using Large Language Models (LLMs), designed to improve content and citation quality. The main research objective is to address limitations in existing LLM-based survey generation systems, such as finite context windows, lack of in-depth content discussion, and absence of systematic evaluation frameworks. The key methodology involves a two-phase approach (Preparation and Generation) incorporating online reference retrieval, AttributeTree pre-processing, and a re-polishing process, leveraging Retrieval Augmented Generation (RAG). Experimental results showed SURVEYX achieved a 0.259 improvement in content quality and a 1.76 enhancement in citation quality, approaching human expert performance (average content quality scores: SURVEYX: 4.590, Human: 4.754). For AI practitioners, SURVEYX provides an efficient and organized system for generating high-quality academic surveys, enhancing the information density for LLMs and optimizing their context window usage, with potential applications in various fields.  |
| MaskGWM: A Generalizable Driving World Model with Video Mask Reconstruction (Read more on [arXiv](https://arxiv.org/abs/2502.11663) or [HuggingFace](https://huggingface.co/papers/2502.11663))| Rui Chen, Yuxin Guo, Jingcheng Ni, wzhgba, lyclyc52 | MaskGWM is a driving world model that combines diffusion-based generation with masked reconstruction for improved fidelity and generalization. The main research objective is to develop a more generalizable driving world model capable of long-horizon prediction and multi-view generation, surpassing existing models constrained by prediction duration and generalization. The key methodology involves a Diffusion Transformer (DiT) architecture trained with an extra mask construction task, diffusion-related mask tokens, and a row-wise cross-view module for spatial-temporal and multi-view modeling. Primary results show the model achieves a Frechet Video Distance (FVD) of 59.4 and Frechet Inception Distance (FID) of 4.0 on the nuScenes dataset without action information, outperforming the state-of-the-art. For AI practitioners, the proposed MaskGWM framework offers a more robust and scalable approach to building driving world models, enabling improved video prediction and generalization capabilities for autonomous driving applications.  |
| Mol-LLaMA: Towards General Understanding of Molecules in Large Molecular Language Model (Read more on [arXiv](https://arxiv.org/abs/2502.13449) or [HuggingFace](https://huggingface.co/papers/2502.13449))| Sung Ju Hwang, Wonbin Lee, DongkiKim | i) Mol-LLaMA, a large molecular language model, is proposed for enhanced general understanding of molecules. ii) The research aims to develop a molecular language model that grasps general molecular knowledge to function as a versatile molecular assistant. iii) The methodology includes multi-modal instruction tuning with a designed dataset encompassing structural, chemical, and biological features, along with a blending module integrating information from 2D and 3D molecular encoders. iv) Experiments show Mol-LLaMA provides more accurate, detailed, and helpful responses than baseline LLMs and molecular LLMs, as well as improved performance on molecular property prediction, achieving high accuracy while maintaining high fidelity and helpfulness scores on the PAMPA task. v) The model provides AI/ML practitioners with a new foundation for building general-purpose molecular assistants capable of explaining molecular features and rationales, enhancing molecular analysis.  |
| LLM-Microscope: Uncovering the Hidden Role of Punctuation in Context Memory of Transformers (Read more on [arXiv](https://arxiv.org/abs/2502.15007) or [HuggingFace](https://huggingface.co/papers/2502.15007))| Polina Druzhinina, Elizaveta Goncharova, Temurbek Rahmatullaev, Matvey Mikhalchuk, Anton Razzhigaev | i) This paper introduces methods to quantify and visualize how LLMs encode contextual information, focusing on the role of punctuation. ii) The main research question is how seemingly minor tokens impact the contextual memory of transformer-based LLMs. iii) The methodology involves measuring token-level nonlinearity, contextualization through prefix reconstruction, and intermediate layer analysis via a modified Logit Lens. iv) The results show that removing stopwords, articles, and commas consistently degrades performance on MMLU and BABILong-4k and identifies a correlation between linearity and contextualization. v) AI practitioners should note the counterintuitive finding that "filler" tokens carry significant contextual information affecting performance on tasks requiring knowledge and long-context reasoning.  |
| PhotoDoodle: Learning Artistic Image Editing from Few-Shot Pairwise Data (Read more on [arXiv](https://arxiv.org/abs/2502.14397) or [HuggingFace](https://huggingface.co/papers/2502.14397))| Xueyin Wang, Hailong Guo, Yuxuan Zhang, Yiren Song, Shijie Huang | PhotoDoodle is presented as a novel image editing framework for photo doodling using few-shot learning. The research objective is to enable artists to overlay decorative elements onto photographs while maintaining background consistency and artistic style, addressing challenges in seamless integration, background preservation, and efficient style capture from limited data. The methodology employs a two-stage training strategy, initially pre-training a general image editing model (OmniEditor) and subsequently fine-tuning it with EditLoRA using artist-curated before-and-after image pairs and introducing positional encoding reuse. Experiments using the proposed PhotoDoodle dataset demonstrated advanced performance in customized image editing achieving a CLIP score of 0.279 and GPT score of 63.207. The principal implication is that the framework provides a customizable image editing approach that can learn and transfer artistic styles from limited data, offering a potential solution for high-quality, consistent image manipulation in artistic creation.  |
| VLM$^2$-Bench: A Closer Look at How Well VLMs Implicitly Link Explicit Matching Visual Cues (Read more on [arXiv](https://arxiv.org/abs/2502.12084) or [HuggingFace](https://huggingface.co/papers/2502.12084))| Yi R., Paul Pu Liang, Renjie Pi, RainJamesY, Sterzhang | i) The paper introduces VLM$^2$-Bench, a new benchmark to evaluate vision-language models' ability to visually link matching cues across multiple images or frames. ii) The research aims to assess whether VLMs can effectively associate visual cues to identify correspondences without external knowledge. iii) The methodology involves creating a dataset of over 3,000 test cases across nine subtasks categorized by general, object-centric, and person-centric cues, and then evaluating various VLMs. iv) Evaluations show a significant performance gap between even GPT-4o (60.36%) and human-level accuracy (95.16%), indicating challenges in visually linking cues. v) The benchmark and identified challenges imply the necessity for AI practitioners to develop VLMs with enhanced visual understanding and reasoning capabilities, focusing on reducing reliance on prior knowledge and improved cue association. Some parts of the paper lack clarity about the specific data creation process.  |
| SIFT: Grounding LLM Reasoning in Contexts via Stickers (Read more on [arXiv](https://arxiv.org/abs/2502.14922) or [HuggingFace](https://huggingface.co/papers/2502.14922))| Zhijie Deng, Boxiu Li, Xuyao Huang, Zihao Zeng | SIFT is a post-training approach that improves large language models' (LLMs) reasoning by grounding it in the provided context using model-generated summaries called "Stickers." The main research objective is to address the issue of "factual drift," where LLMs misinterpret or overlook key information in the input query during reasoning. The key methodology is a post-training approach called "Stick to the Facts" (SIFT), which involves generating a "Sticker" summarizing key facts, performing consensus prediction using the Sticker and the original query, and refining the Sticker via forward and inverse optimization. A primary result is that SIFT improves the pass@1 accuracy of DeepSeek-R1 on AIME2024 from 78.33% to 85.67%. The principal implication is that AI practitioners can improve model accuracy, particularly on complex reasoning tasks, using sticker-based, factual grounding.  |
| LightThinker: Thinking Step-by-Step Compression (Read more on [arXiv](https://arxiv.org/abs/2502.15589) or [HuggingFace](https://huggingface.co/papers/2502.15589))| Mengshu Sun, Yuqi Zhu, Jintian Zhang, Ningyu, GoooDte | LightThinker is a method that enables LLMs to dynamically compress intermediate thoughts during reasoning to improve efficiency. The main research objective is to reduce the memory and computational costs of LLMs during complex reasoning tasks without sacrificing performance. The key methodology involves training the model to compress verbose thought steps into compact representations using gist tokens and specialized attention masks, quantified by a new "Dependency" metric. Primary results show that with the Qwen model, LightThinker reduces peak token usage by 70% and inference time by 26% compared to the Vanilla model, while maintaining comparable accuracy (with only a 1% drop). The principal implication for AI practitioners is that LightThinker offers a new approach for improving LLM inference efficiency in complex reasoning, providing a balance between accuracy and computational cost, though there is significant performance degradation on Llama series models.  |
| StructFlowBench: A Structured Flow Benchmark for Multi-turn Instruction Following (Read more on [arXiv](https://arxiv.org/abs/2502.14494) or [HuggingFace](https://huggingface.co/papers/2502.14494))| Yuan Wu, Yi Chang, Yue Wang, Jinzhe Li, Jinnan Li | The paper introduces StructFlowBench, a new benchmark for evaluating multi-turn instruction-following capabilities of large language models (LLMs). The main research objective is to assess LLMs' ability to understand and maintain structural dependencies between dialogue turns, beyond simple constraint satisfaction. The key methodology involves defining a structural flow framework with six inter-turn relationship types and creating a dual-constraint evaluation system combining intra-turn and structural constraints. Evaluations of 13 LLMs revealed that the DeepSeek-v3 model achieved the highest Weighted Constraint Satisfaction Rate (WCSR) of 0.98. The principal implication for AI practitioners is the need to develop LLMs that better handle complex dialogue structures, particularly refinements, to improve performance in real-world multi-turn conversational applications.  |
| KITAB-Bench: A Comprehensive Multi-Domain Benchmark for Arabic OCR and Document Understanding (Read more on [arXiv](https://arxiv.org/abs/2502.14949) or [HuggingFace](https://huggingface.co/papers/2502.14949))| Ghazi Ahmed, Rania Hossam, Abdullah Sohail, mukul54, ahmedheakl | KITAB-Bench introduces a new benchmark for evaluating Arabic OCR and document understanding systems. The main research objective is to address the lack of comprehensive evaluation frameworks for Arabic OCR, which lags behind English OCR due to the script's unique challenges. The key methodology involves curating a diverse dataset of 8,809 samples across 9 domains and 36 sub-domains, including handwritten text, tables, and charts, and evaluating various OCR systems and Vision-Language Models (VLMs) on tasks like text recognition, layout detection, and PDF-to-Markdown conversion. A primary result is that modern VLMs (e.g., GPT-4, Gemini) outperform traditional OCR approaches (e.g., EasyOCR, PaddleOCR) by an average of 60% in Character Error Rate (CER), but the best model (Gemini-2.0-Flash) achieves only 65% accuracy in PDF-to-Markdown conversion. AI practitioners can use KITAB-Bench to rigorously evaluate and improve Arabic document analysis methods, and focus efforts on bridging performance gap with English OCR, particularly in complex tasks like accurate structured content extraction from PDF documents.  |
| InterFeedback: Unveiling Interactive Intelligence of Large Multimodal Models via Human Feedback (Read more on [arXiv](https://arxiv.org/abs/2502.15027) or [HuggingFace](https://huggingface.co/papers/2502.15027))| Mike Zheng Shou, Haiyang Mei, Yifei Tao, Wenqi Pei, Henry Hengyuan Zhao | InterFeedback, a framework and benchmark, is introduced to evaluate the interactive intelligence of Large Multimodal Models (LMMs) using human feedback. The main research question is: "How do Large Multimodal Models perform with human feedback?" The key methodology involves an interactive framework, InterFeedback, using leading LMMs like GPT-4o to simulate human feedback and testing on datasets like MMMU-Pro and MathVerse. Results show that state-of-the-art LMMs (e.g., OpenAI-01) can correct their results through human feedback less than 50% of the time. The principal implication for AI practitioners is the need to develop methods that enhance LMMs' capabilities to interpret and benefit from feedback, as current models demonstrate suboptimal performance in this area.  |
| Evaluating Multimodal Generative AI with Korean Educational Standards (Read more on [arXiv](https://arxiv.org/abs/2502.15422) or [HuggingFace](https://huggingface.co/papers/2502.15422))| Geewook Kim, sangheeeee | This paper introduces KoNET, a new benchmark for evaluating Multimodal Generative AI systems using Korean national educational tests. The main research objective is to assess the performance of Multimodal Generative AI systems across different educational levels in the Korean language. The methodology involves evaluating various open-source, open-access, and closed API models on four Korean educational exams (KoEGED, KoMGED, KoHGED, and KoCSAT) using a multimodal VQA format, and comparing their performance with human error rates. The primary results show that the EXAONE-3.0-7.8B-Instruct model achieved a KoNET score of 45.5, and model accuracy generally decreases with more advanced curricula; also closed-source APIs performed far superior to open-source models. The principal implication for AI practitioners is that benchmarks centered solely on English may not accurately assess AI performance in non-English language environments, highlighting a need for language-specific benchmarks and models.  |
| Superintelligent Agents Pose Catastrophic Risks: Can Scientist AI Offer a Safer Path? (Read more on [arXiv](https://arxiv.org/abs/2502.15657) or [HuggingFace](https://huggingface.co/papers/2502.15657))| Pietro Greiner, Joumana Ghosn, Damiano Fornasiere, Michael Cohen, Yoshua Bengio | This paper proposes "Scientist AI," a non-agentic AI design, as a safer alternative to increasingly capable generalist agentic AI systems that pose catastrophic risks. The main research objective is to design a non-agentic AI that is trustworthy and safe by design, minimizing risks associated with uncontrolled agentic AI. The key methodology is a Bayesian approach with a world model generating causal theories and an inference machine for probabilistic question answering, operating with explicit uncertainty quantification. The paper presents the abstract view that as training data, objectives, and models scale for agentic AI, goal misgeneralization becomes more likely. This is contrasted with the proposal that the proposed non-agentic design improves in safety and accuracy with additional computing power. For AI practitioners, the principal implication is that focusing development on non-agentic AI, specifically "Scientist AI," may enable benefits of AI innovation while avoiding risks associated with the current agent-driven trajectory.  |
| The Relationship Between Reasoning and Performance in Large Language Models -- o3 (mini) Thinks Harder, Not Longer (Read more on [arXiv](https://arxiv.org/abs/2502.15631) or [HuggingFace](https://huggingface.co/papers/2502.15631))| Vincent Ginis, Andres Algaba, Marthe Ballon | The research investigates reasoning token usage versus accuracy in different generations of OpenAI language models. The main research question is whether more capable models within a single family require a longer chain-of-thought (more reasoning tokens) to achieve higher performance, or if they reason more effectively. The key methodology involves a systematic analysis of chain-of-thought length and accuracy across o1-mini and o3-mini variants on the Omni-MATH benchmark, using logistic regression to quantify effects. The primary results are that the o3-mini (m) achieves superior accuracy without requiring longer reasoning chains than o1-mini, and accuracy generally declines as reasoning chains grow, with a diminishing rate as proficiency goes up; Specifically, accuracy decreased by 3.16% per 1000 reasoning tokens for o1-mini and 1.96% for o3-mini (m). The principal implication is that, for mathematical reasoning tasks, constraining the chain-of-thought might be beneficial for weaker models; newer models exhibit more efficient reasoning, and less is more.  |
| ReQFlow: Rectified Quaternion Flow for Efficient and High-Quality Protein Backbone Generation (Read more on [arXiv](https://arxiv.org/abs/2502.14637) or [HuggingFace](https://huggingface.co/papers/2502.14637))| Hongteng Xu, EatEatEatEat, AngxiaoYue | ReQFlow is a novel method for fast and high-quality protein backbone generation using rectified quaternion flows. The main research objective is to develop a generative model that can efficiently produce designable protein backbones, overcoming limitations of existing diffusion and flow-based models. The key methodology involves representing 3D rotations with unit quaternions, constructing a quaternion flow (QFlow) via spherical linear interpolation (SLERP) in exponential format, and rectifying the QFlow to accelerate inference and improve designability. The primary results show that ReQFlow achieves state-of-the-art performance in protein backbone generation, requiring significantly fewer sampling steps and less inference time; for example, it is 37x faster than RFDiffusion when generating a backbone of length 300. Principal implication for AI practitioners is that ReQFlow provides a more efficient and effective approach to protein backbone generation, improving upon existing methods in both speed and the quality of generated structures.  |
| MoBA: Mixture of Block Attention for Long-Context LLMs (Read more on [arXiv](https://arxiv.org/abs/2502.13189) or [HuggingFace](https://huggingface.co/papers/2502.13189))| Tao Jiang, Yulun Du, Jingyuan Liu, Zhejun Jiang, Enzhe Lu | MoBA is a novel attention mechanism for LLMs that improves efficiency and scalability for long contexts by applying Mixture-of-Experts principles to block-wise attention. The main research objective is to design a robust attention architecture that can seamlessly transition between full and sparse attention without compromising performance and allowing the model to attend autonomously. The key methodology is partitioning the context into blocks and using a gating mechanism to route query tokens to the most relevant blocks, based on a computed affinity score. Primary results show that MoBA achieves comparable performance to full attention on language modeling tasks, with a validation loss difference within 1e-3, while achieving up to a 6.5x speedup when prefilling 1M tokens. For AI practitioners, MoBA offers a practical solution for enhancing long-context capabilities in LLMs with improved computational efficiency and seamless integration with existing pre-trained models.  |
| One-step Diffusion Models with $f$-Divergence Distribution Matching (Read more on [arXiv](https://arxiv.org/abs/2502.15681) or [HuggingFace](https://huggingface.co/papers/2502.15681))| Arash Vahdat, Weili Nie, Yilun Xu | The paper introduces f-distill, a framework for distilling diffusion models into one-step generators by minimizing f-divergences between teacher and student distributions. The main research objective is to generalize distribution matching distillation with f-divergences, enabling different trade-offs between mode coverage and training variance. The key methodology involves deriving the gradient of the f-divergence between teacher and student distributions and expressing it as a weighted score difference, using a weighting function determined by density ratio and the chosen f-divergence. Primary results show that f-distill, using Jensen-Shannon divergence, achieves a state-of-the-art one-step FID score of 1.16 on ImageNet-64. The principal implication for AI practitioners is that they can leverage f-distill to create efficient one-step image generators with improved sample quality and control over mode coverage, surpassing previous variational score distillation methods.  |
| Think Inside the JSON: Reinforcement Strategy for Strict LLM Schema Adherence (Read more on [arXiv](https://arxiv.org/abs/2502.14905) or [HuggingFace](https://huggingface.co/papers/2502.14905))| Viktoria Rojkova, Ishan Joshi, Bhavik Agarwal | The paper introduces "Think Inside the JSON," a reinforcement learning framework for training LLMs to adhere strictly to predefined JSON schemas. The main research objective is to develop a method for enforcing strict schema adherence in LLM text generation, specifically for structured data output. The key methodology combines synthetic data generation, a novel reinforcement learning pipeline using Group Relative Policy Optimization (GRPO) with custom rewards, and supervised fine-tuning. This approach achieves a 62.41% mean match rate on a structured data extraction benchmark, with a 0.27% mean noise rate, outperforming distilled versions of DeepSeek R1 and Gemini 2.0 Flash. For AI practitioners, this provides a resource-efficient method to enforce schema constraints in LLM outputs, valuable for applications requiring high data integrity and compliance.  |
| CrossOver: 3D Scene Cross-Modal Alignment (Read more on [arXiv](https://arxiv.org/abs/2502.15011) or [HuggingFace](https://huggingface.co/papers/2502.15011))| Iro Armeni, Daniel Barath, Marc Pollefeys, Ondrej Miksik, sayandsarkar | CrossOver is a framework for 3D scene understanding that aligns modalities like images, point clouds, and CAD models via a modality-agnostic embedding space. The main research objective is to achieve flexible, scene-level cross-modal alignment in 3D environments without requiring complete data or rigid alignment across all modalities. The key methodology involves using dimensionality-specific encoders, a three-stage training pipeline (object-level, scene-level, unified encoders), and contrastive learning to create a unified embedding space. Results on ScanNet and 3RScan datasets show superior performance, achieving a scene-level matching recall of 99.31% (R@25) on ScanNet for the I → R modality. The principal implication is that AI practitioners can leverage CrossOver for robust 3D scene understanding and cross-modal retrieval tasks, even with incomplete or unaligned multi-modal data, removing the requirement of full data alignment.  |
| Beyond No: Quantifying AI Over-Refusal and Emotional Attachment Boundaries (Read more on [arXiv](https://arxiv.org/abs/2502.14975) or [HuggingFace](https://huggingface.co/papers/2502.14975))| Grant Rosario, David Noever | The paper introduces a benchmark and evaluation framework for assessing emotional boundary handling in Large Language Models (LLMs). The main research objective is to quantify and analyze "over-refusal" in LLMs when responding to user prompts that attempt to establish emotional connections or relationships. The key methodology involves a dataset of 1156 prompts across six languages, evaluating three LLMs (GPT-4o, Claude-3.5 Sonnet, and Mistral-large) using pattern-matched response analysis across seven key patterns. A primary result is that Claude-3.5 achieved the highest overall score (8.69/10), and a significant performance gap was found between English (average score 25.62) and non-English interactions (≤ 0.22). The principal implication for AI practitioners is the need to develop more nuanced, multilingual emotional intelligence and boundary-setting capabilities in LLMs, addressing over-refusal while maintaining ethical and safety standards.  |
| JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust Multi-Teacher Knowledge Distillation Framework (Read more on [arXiv](https://arxiv.org/abs/2502.13407) or [HuggingFace](https://huggingface.co/papers/2502.13407))| Jingyu Ma, Yuanxiu Zhou, Long Gao, Ruifei Zhu, circleLZY | JL1-CD introduces a new dataset and a multi-teacher knowledge distillation framework for remote sensing change detection. The main research objective is to address the scarcity of high-resolution, all-inclusive change detection datasets and improve model performance across varying change area ratios. The key methodology involves constructing the JL1-CD dataset, proposing an Origin-Partition (O-P) training strategy, and developing a Multi-Teacher Knowledge Distillation (MTKD) framework. Results show that the MTKD framework, when applied to the Changer-MiT-b1 model, achieves an mIoU of 76.15% on the JL1-CD dataset. The principal implication for AI practitioners is that utilizing MTKD can enhance the performance of change detection models without increasing inference cost, particularly beneficial when the data has diverse range of change area ratio.  |
| UPCORE: Utility-Preserving Coreset Selection for Balanced Unlearning (Read more on [arXiv](https://arxiv.org/abs/2502.15082) or [HuggingFace](https://huggingface.co/papers/2502.15082))| Mohit Bansal, Elias Stengel-Eskin, vaidehi99 | UPCORE is a method-agnostic data selection framework that mitigates collateral damage in machine unlearning by pruning outliers from the forget set. The main research objective is to determine how measurable attributes of the forget set drive collateral effects during unlearning and whether these attributes can be controlled to optimize the deletion effectiveness/model utility trade-off. The key methodology involves using Isolation Forests to identify and prune high-variance outlier data points in the forget set's hidden state representations, forming a lower-variance "core" forget set used for unlearning. Primary results show that UPCORE achieves a higher area-under-the-curve (AUC) score (0.387) compared to unlearning on the complete set (0.343) and random subset (0.353) using Gradient Ascent, across standard metrics, indicating improved balance between deletion and utility preservation. AI practitioners can use UPCORE to minimize negative side effects when removing data or capabilities from trained models, leading to more robust and reliable unlearning processes.  |
