

## Papers for 2025-02-11

| Title | Authors | Summary |
|-------|---------|---------|
| SynthDetoxM: Modern LLMs are Few-Shot Parallel Detoxification Data Annotators (Read more on [arXiv](https://arxiv.org/abs/2502.06394) or [HuggingFace](https://huggingface.co/papers/2502.06394))| Alexander Panchenko, tlenusik, memyprokotow, chameleon-lizard, etomoscow | This paper introduces SynthDetoxM, a multilingual synthetic parallel text detoxification dataset, and a framework for generating such data using large language models (LLMs). The main research objective is to address the scarcity of parallel multilingual datasets for training text detoxification models. The key methodology involves few-shot prompting of multiple open-source LLMs to rewrite toxic sentences sourced from existing toxicity datasets across German, French, Spanish, and Russian, followed by a filtering and ranking process. Models trained on the full SynthDetoxM achieved a J score (combining style transfer accuracy, similarity, and fluency) of 0.484, 0.521, and 0.471 on German, Russian and Spanish respectively. The principal implication is that AI practitioners can leverage the proposed framework and the SynthDetoxM dataset to train more effective multilingual text detoxification models, even with limited human-annotated parallel data.  |
| Exploring the Limit of Outcome Reward for Learning Mathematical Reasoning (Read more on [arXiv](https://arxiv.org/abs/2502.06781) or [HuggingFace](https://huggingface.co/papers/2502.06781))| Yuzhe Gu, Songyang Gao, Chengqi Lyu, zsytony, ZwwWayne | This paper introduces OREAL, a new reinforcement learning (RL) framework for enhancing mathematical reasoning in large language models (LLMs) using only binary outcome rewards. The main research objective is to push the performance limit achievable through Outcome REwArd-based reinforcement learning (OREAL) for mathematical reasoning tasks. The key methodology involves behavior cloning on positive trajectories from Best-of-N sampling, reward shaping for negative samples, and a token-level reward model for credit assignment. OREAL achieves a 95.0 pass@1 accuracy on MATH-500 with a 32B model, and a 7B model can obtain 94.0 pass@1 accuracy on MATH-500. AI practitioners can utilize OREAL's techniques to improve LLM performance on mathematical reasoning tasks using readily available binary outcome feedback, emphasizing the importance of policy model initialization and proper training data selection.  |
| Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling (Read more on [arXiv](https://arxiv.org/abs/2502.06703) or [HuggingFace](https://huggingface.co/papers/2502.06703))| Xiu Li, Jian Zhao, Junqi Gao, iseesaw, RyanLiu112 | This paper investigates compute-optimal test-time scaling (TTS) strategies for Large Language Models (LLMs), demonstrating that smaller LLMs can outperform larger ones with appropriate scaling. The main research question is what is the optimal approach to scaling test-time computation across different policy models, Process Reward Models (PRMs), and problem difficulty levels, and to what extent can it improve performance. The key methodology involves comprehensive experiments on MATH-500 and AIME24 tasks using various LLMs (0.5B to 72B) and PRMs (1.5B to 72B), evaluating different TTS methods like Best-of-N, beam search, and Diverse Verifier Tree Search. The primary results show that a 3B LLM with compute-optimal TTS can surpass a 405B LLM, achieving 75.6% on MATH-500 and 30.0% on AIME24, compared to 71.4% and 23.3% for the 405B model with Chain-of-Thought prompting. The principal implication for AI practitioners is that applying compute-optimal, reward-aware TTS strategies can significantly enhance the reasoning abilities of smaller LLMs, potentially leading to more efficient and effective deployment compared to using much larger models.  |
| Lossless Acceleration of Large Language Models with Hierarchical Drafting based on Temporal Locality in Speculative Decoding (Read more on [arXiv](https://arxiv.org/abs/2502.05609) or [HuggingFace](https://huggingface.co/papers/2502.05609))| Soyeong Jeong, Jeongyeon Seo, Sangjin Choi, doubleyyh, zomss | Hierarchy Drafting (HD) accelerates large language model (LLM) inference by organizing token sources into hierarchical databases based on temporal locality and accessing them sequentially during speculative decoding.  Main research question or objective: To address the limitations of existing speculative decoding methods, which rely on a single database, require additional fine-tuning or deliver inconsistent acceleration gains.  Key methodology used: The proposed method, Hierarchy Drafting (HD), organizes diverse token sources into three databases (context-dependent, model-dependent, and statistics-dependent) based on temporal locality and accesses them sequentially during speculative decoding, starting from the smallest to largest.  Primary results: Experiments on Spec-Bench using LLMs with 7B and 13B parameters demonstrate that HD outperforms existing lossless drafting methods, achieving over 1.5x faster inference speed compared to autoregressive decoding when the temperature is 0.0.  Principal implication for AI practitioners: AI practitioners can achieve significant and consistent lossless inference acceleration in LLMs without model retraining or modification, using readily accessible data sources, by employing HD, making it suitable for real-world deployment.  |
| Show-o Turbo: Towards Accelerated Unified Multimodal Understanding and Generation (Read more on [arXiv](https://arxiv.org/abs/2502.05415) or [HuggingFace](https://huggingface.co/papers/2502.05415))| Yishun Li, Zhenyi Liao, zhijie3, asunalove, UnhurriedDawn | Show-o Turbo accelerates the unified multimodal understanding and generation model Show-o by extending consistency distillation to its multimodal denoising trajectories. The main research question is whether a unified approach exists to enhance the efficiency of Show-o's inference, which involves denoising image tokens and autoregressively decoding text tokens. The key methodology involves viewing text generation as a denoising process using Jacobi decoding, extending consistency distillation (CD) to multimodal discrete sampling trajectories, and employing trajectory segmentation and curriculum learning. Show-o Turbo achieves a GenEval score of 0.625 at 4 sampling steps without classifier-free guidance (CFG), outperforming the original Show-o with 8 steps and CFG, in text-to-image generation and 1.5 speedup on image-to-text task. AI practitioners can leverage this approach to deploy more efficient multimodal models that achieve significant speedups in both image and text generation tasks with minimal performance trade-offs.  |
| Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning (Read more on [arXiv](https://arxiv.org/abs/2502.06060) or [HuggingFace](https://huggingface.co/papers/2502.06060))| Dorsa Sadigh, C. Karen Liu, Warren Xia, bidiptas | Language models are trained to communicate effectively in a multi-agent social deduction game without human demonstrations, enhancing their ability to reason and strategize. The main research objective is to train language models to have productive natural language discussions about their environment, leveraging the agent's goal for predicting useful information. The methodology decomposes communication into listening and speaking, using a dense reward signal based on imposter prediction and influence on other agents' beliefs to guide multi-agent reinforcement learning. Crewmate agents trained with the proposed technique achieve double the win rate compared to standard reinforcement learning, illustrating the value of the communication strategy. AI practitioners can utilize the described approach to enable self-improving discussions in multi-agent settings without requiring task-specific human data, potentially broadening the application of language models in cooperative AI.  |
| ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates (Read more on [arXiv](https://arxiv.org/abs/2502.06772) or [HuggingFace](https://huggingface.co/papers/2502.06772))| Mengdi Wang, Bin Cui, Zhaochen Yu, Ling Yang | ReasonFlux is a hierarchical LLM reasoning framework that optimizes mathematical reasoning by scaling thought templates. The main research objective is to improve LLMs' mathematical reasoning capabilities beyond existing models like OpenAI's o1-preview and DeepSeek V3. The key methodology involves a structured thought template library, hierarchical reinforcement learning on template sequences, and an inference scaling system that adaptively retrieves and applies templates. On the MATH benchmark, ReasonFlux-32B achieves an accuracy of 91.2%, surpassing o1-preview by 6.7%. AI practitioners can leverage ReasonFlux's hierarchical template-based approach for more efficient and generalizable reasoning in complex problem-solving applications, requiring less computational resources.  |
| The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering (Read more on [arXiv](https://arxiv.org/abs/2502.03628) or [HuggingFace](https://huggingface.co/papers/2502.03628))| Zhenting Wang, Di Liu, Yunhe Gao, Haizhou Shi, Zhuowei Li | This paper introduces VISTA, a training-free framework to reduce hallucination in Large Vision-Language Models (LVLMs) by steering token generation with visual information. The main research objective is to investigate and mitigate the phenomenon of LVLMs generating syntactically coherent but visually ungrounded content. The key methodology, VISTA, combines a Visual Steering Vector (VSV) to reinforce visual cues in activation space and Self-Logits Augmentation (SLA) to leverage early-layer activations for semantically meaningful decoding. Primary results show that VISTA reduces hallucination by about 40% on average in open-ended generation tasks, outperforming existing methods across multiple architectures and decoding strategies. The principal implication for AI practitioners is that VISTA provides an efficient, inference-time intervention to improve the visual grounding and reliability of LVLMs without requiring additional training or model modification.  |
| Matryoshka Quantization (Read more on [arXiv](https://arxiv.org/abs/2502.06786) or [HuggingFace](https://huggingface.co/papers/2502.06786))| Aditya Kusupati, Prateek Jain, Jeff Dean, Puranjay Datta, Pranav Nair | Matryoshka Quantization (MatQuant) is a multi-scale quantization technique that trains a single model capable of operating at various integer bit-widths. The main research question is whether a single model can be trained to extract multiple accurate lower-precision models, addressing the challenges of accuracy loss in low-precision quantization and the need for maintaining multiple models. The key methodology is Matryoshka Quantization, which jointly optimizes model weights across multiple precision levels (e.g., int8, int4, int2) using shared most significant bits and leveraging the inherent nested structure of integer data types. Primary results show that MatQuant-derived int2 models outperform standard int2 quantization techniques by up to 10% in accuracy, and an int2 FFN-quantized Gemma-2 9B model is more accurate than an int8 FFN-quantized Gemma-2 2B model. The principal implication is that AI practitioners can train and maintain a single quantized model that can be served at different precision levels, offering a spectrum of accuracy-versus-cost options and improving accuracy, especially in very low precision regimes like int2.  |
| EVEv2: Improved Baselines for Encoder-Free Vision-Language Models (Read more on [arXiv](https://arxiv.org/abs/2502.06788) or [HuggingFace](https://huggingface.co/papers/2502.06788))| Yueze Wang, Yufeng Cui, Xiaotong Li, Haiwen Diao, PhyscalX | EVEv2.0 is a new family of encoder-free vision-language models (VLMs) that improve upon existing baselines through architectural and training enhancements. The main research objective is to systematically investigate and improve the performance of encoder-free VLMs, addressing challenges like cross-modal interference and visual perception learning from scratch. The key methodology involves a "Divide-and-Conquer" architecture that decomposes the model into modality-specific components within a unified decoder-only framework, along with a progressive training strategy utilizing an enhanced captioning engine. Primary results show that EVEv2.0 achieves 71.4% accuracy on ScienceQA-IMG, outperforming prior encoder-free models, while approaching the performance of encoder-based counterparts with similar capacity, using only 100M publicly available data. The principal implication for AI practitioners is that properly decomposing and associating modalities, combined with a well-designed training strategy, allows for effective optimization of decoder-only VLMs, providing superior data efficiency and strong visual-reasoning capability, and thereby improving performance of large language models.  |
| LM2: Large Memory Models (Read more on [arXiv](https://arxiv.org/abs/2502.06049) or [HuggingFace](https://huggingface.co/papers/2502.06049))| Fraser Greenlee, Alex J. Chan, Filippos Christianos, Wenqi Wu, Jikun Kang | LM2 is a memory-augmented Transformer architecture designed to improve long-context reasoning in language models. The main research objective is to address the limitations of standard Transformers in processing long contexts with distributed information, particularly for tasks involving multi-step reasoning and relational argumentation. The key methodology involves integrating a dynamic memory module into the decoder-only Transformer, using cross-attention and gating mechanisms to update and retrieve contextual representations. Experimental results on the BABILong benchmark show LM2 outperforms the memory-augmented RMT model by 37.1% and the baseline Llama-3.2 model by 86.3% on average across tasks. The principal implication for AI practitioners is that incorporating explicit memory modules, as done in LM2, can enhance a Transformer's ability to handle long-context reasoning tasks without sacrificing performance on general tasks, which has significance for NLP applications.  |
| Lumina-Video: Efficient and Flexible Video Generation with Multi-scale Next-DiT (Read more on [arXiv](https://arxiv.org/abs/2502.06782) or [HuggingFace](https://huggingface.co/papers/2502.06782))| Kai Wang, Zhen Li, Yutong Liu, Shicheng Li, Dongyang Liu | Lumina-Video is a novel framework for efficient and flexible video generation based on an enhanced Diffusion Transformer architecture. The main research objective is to address the spatiotemporal complexity and computational challenges of video generation using Diffusion Transformers (DiTs). The key methodology involves a Multi-scale Next-DiT architecture with multiple patch sizes, motion score conditioning, progressive training, and multi-source training. Lumina-Video achieves a total score of 82.94% on the VBench benchmark, demonstrating competitive performance in generating high-quality videos. AI practitioners can leverage Lumina-Video's Multi-Scale Next-DiT and training strategies to build efficient and flexible video generation models with controllable dynamics.  |
| History-Guided Video Diffusion (Read more on [arXiv](https://arxiv.org/abs/2502.06764) or [HuggingFace](https://huggingface.co/papers/2502.06764))| Russ Tedrake, Yilun Du, Max Simchowitz, Boyuan Chen, Kiwhan Song | The paper introduces a video diffusion model, DFoT, and a family of guidance methods, History Guidance (HG), that improve video generation quality and consistency by leveraging variable-length historical frames. The main research question is how to effectively use different portions of video history as a form of guidance for improved video generation. The key methodology involves the Diffusion Forcing Transformer (DFoT), which allows conditioning on flexible history lengths, and History Guidance methods, which combine scores from different history windows and noise levels. A primary result is that DFoT with history guidance achieves a Fréchet Video Distance (FVD) of 170.4 on Kinetics-600, outperforming baselines. AI practitioners can use DFoT and History Guidance to improve the quality, consistency, and length of generated videos, especially for tasks requiring long-term coherence.  |
| CustomVideoX: 3D Reference Attention Driven Dynamic Adaptation for Zero-Shot Customized Video Diffusion Transformers (Read more on [arXiv](https://arxiv.org/abs/2502.06527) or [HuggingFace](https://huggingface.co/papers/2502.06527))| Zhen Yang, Jin Wang, Jingxuan Pang, Mushui Liu, D. She | CustomVideoX is a zero-shot personalized video generation framework based on the Video Diffusion Transformer, enhancing video quality and temporal coherence. The main research objective is to develop a method for generating customized videos from a reference image and text prompt, addressing temporal inconsistencies and quality degradation issues. The key methodology involves integrating 3D Reference Attention for direct interaction between reference image and video frames, Time-Aware Attention Bias to modulate reference feature influence, and Entity Region-Aware Enhancement for focused feature injection. Primary results show that CustomVideoX achieves a CLIP-I score of 90.26 and DINO-I score of 91.49 on the VideoBench benchmark, outperforming other methods. AI practitioners can leverage CustomVideoX's architecture for improved zero-shot personalized video generation, specifically benefiting from the 3D Reference Attention and time-aware mechanisms for better fidelity and consistency.  |
| APE: Faster and Longer Context-Augmented Generation via Adaptive Parallel Encoding (Read more on [arXiv](https://arxiv.org/abs/2502.05431) or [HuggingFace](https://huggingface.co/papers/2502.05431))| Beidi Chen, Tianqi Chen, Hanyuezhuohua | APE improves context-augmented generation by enabling faster and longer context processing through adaptive parallel encoding. The main research objective is to address the computational burden and performance degradation of existing context-augmented generation (CAG) techniques when handling multiple, lengthy contexts. The key methodology, Adaptive Parallel Encoding (APE), uses a shared prefix, attention temperature, and scaling factor to align the distribution of parallel encoding with sequential encoding. Results show that APE preserves 98% of sequential encoding performance on RAG tasks while enabling an end-to-end 4.5x speedup by reducing prefilling time by 28x for a 128K-length context. The principal implication for AI practitioners is that APE enables more efficient and scalable deployment of CAG systems, particularly those dealing with long and numerous contexts, by reducing computational costs and improving response times.  |
| Efficient-vDiT: Efficient Video Diffusion Transformers With Attention Tile (Read more on [arXiv](https://arxiv.org/abs/2502.06155) or [HuggingFace](https://huggingface.co/papers/2502.06155))| Peiyuan Zhang, Runlong Su, Dacheng Li, zhijie3, foreverpiano | EFFICIENT-VDIT accelerates video diffusion transformers by sparsifying 3D attention and reducing sampling steps. The main research objective is to address the computational inefficiency of 3D full attention diffusion transformers (DiTs) during video generation. The key methodology involves identifying and leveraging a "tile-style" repetitive pattern in 3D attention maps to create sparse attention masks, combined with multi-step consistency distillation. The primary result is that EFFICIENT-VDIT achieves up to a 7.8x speedup on Open-Sora-Plan-1.2 models for 29 and 93 frame video generation with minimal performance degradation on VBench. For AI practitioners, this method provides a way to significantly speed up video generation with 3D DiTs, enabling faster inference and potentially reducing computational costs.  |
| MetaChain: A Fully-Automated and Zero-Code Framework for LLM Agents (Read more on [arXiv](https://arxiv.org/abs/2502.05957) or [HuggingFace](https://huggingface.co/papers/2502.05957))| Chao Huang, Tianyu Fan, Jiabin Tang | MetaChain is a framework enabling fully-automated, zero-code development and deployment of LLM agents through natural language alone. The main research question is: Can we enable everyone, regardless of technical background, to build their own LLM agents using natural language alone? The key methodology involves a novel LLM Agent Framework with four components: Agentic System Utilities, LLM-powered Actionable Engine, Self-Managing File System, and Self-Play Agent Customization module, enabling automated agent generation, customization, and workflow optimization. Primary results include ranking #1 among open-source solutions on the GAIA benchmark and achieving 73.51% accuracy on a MultiHop-RAG task. The principal implication for AI practitioners is that MetaChain democratizes agent development, allowing non-programmers to create and customize LLM agents and workflows, potentially accelerating the adoption of agent technology.  |
| Steel-LLM:From Scratch to Open Source -- A Personal Journey in Building a Chinese-Centric LLM (Read more on [arXiv](https://arxiv.org/abs/2502.06635) or [HuggingFace](https://huggingface.co/papers/2502.06635))| Zhaoxiang Zhang, Shu Li, Qingshui Gu, aaabiao | Steel-LLM is a fully open-source, 1-billion-parameter, Chinese-centric language model developed with limited computational resources. The main objective was to create a high-quality, transparent, and resource-efficient language model, primarily trained on Chinese data, with a small proportion of English. The methodology involved adapting a Qwen-based Transformer architecture with Soft Mixture of Experts and an enhanced Feed-Forward Network, trained using a modified TinyLlama framework on 8 A100/H800 GPUs. The model achieved a CEVAL accuracy of 41.90% and a CMMLU accuracy of 36.08% after supervised finetuning. AI practitioners can use the provided training pipeline, datasets, model architecture, and intermediate checkpoints to develop or extend similar language models with limited resources, facilitating reproducibility and further research.  |
| The Curse of Depth in Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2502.05795) or [HuggingFace](https://huggingface.co/papers/2502.05795))| Yefeng Zheng, Lu Yin, Xinyuan Song, Wenfang Sun, pengxiang | The paper introduces "Curse of Depth" in large language models (LLMs), where deeper layers contribute less than expected due to Pre-Layer Normalization (Pre-LN), and proposes LayerNorm Scaling to address it. The main research objective is to identify and rectify the phenomenon where deeper layers in LLMs are less effective, specifically investigating the role of Pre-LN in this issue. The key methodology involves theoretical analysis of Pre-LN's impact on variance and gradient flow, alongside empirical evaluations via layer pruning experiments and comparisons of different normalization techniques. A primary result is that LayerNorm Scaling reduces perplexity by 1.31 on LLaMA-1B compared to standard Pre-LN. The principal implication for AI practitioners is that applying LayerNorm Scaling, which inversely scales the output of Pre-LN by the square root of the layer depth, can improve LLM performance by enhancing the contribution of deeper layers during training, creating more resource-efficient models.  |
| DreamDPO: Aligning Text-to-3D Generation with Human Preferences via Direct Preference Optimization (Read more on [arXiv](https://arxiv.org/abs/2502.04370) or [HuggingFace](https://huggingface.co/papers/2502.04370))| Yi Yang, Hehe Fan, Fan Ma, Xiaobo Xia, Zhenglin Zhou | DreamDPO is an optimization-based framework for text-to-3D generation that aligns 3D content with human preferences through direct preference optimization. The main research objective is to improve the alignment of text-to-3D generated content with human preferences and enhance controllability. The methodology involves constructing pairwise examples, comparing their alignment with human preferences using reward or large multimodal models, and optimizing the 3D representation with a preference-driven loss function. DreamDPO achieved a GPTEval3D overall score of 1203.1, outperforming 13 state-of-the-art methods, including MVDream (1097.7). AI practitioners can utilize DreamDPO to generate higher-quality and more controllable 3D content, moving beyond pointwise quality evaluations by utilizing pairwise comparisons and preference optimization.  |
| Dual Caption Preference Optimization for Diffusion Models (Read more on [arXiv](https://arxiv.org/abs/2502.06023) or [HuggingFace](https://huggingface.co/papers/2502.06023))| Bimsara Pathiraja, Shamanthak Hegde, Agneet Chatterjee, Yiran Luo, sahsaeedi | Dual Caption Preference Optimization (DCPO) improves text-to-image diffusion models by using distinct captions for preferred and less preferred images during training. The main research objective is to address the issues of conflict distribution and irrelevant prompts in existing preference optimization methods for diffusion models. The key methodology involves generating distinct captions for preferred and less-preferred images using captioning, perturbation, or hybrid methods, and introducing a modified objective function that leverages these dual captions. Primary results show that DCPO-h outperforms Stable Diffusion 2.1, SFT, Diffusion-DPO, and MaPO, achieving a +0.21 improvement in Pickscore. The principal implication for AI practitioners is that using dual, distinct captions for preferred and less-preferred image pairs during preference optimization can significantly enhance the alignment and performance of diffusion models.  |
