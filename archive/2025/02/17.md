

## Papers for 2025-02-17

| Title | Authors | Summary |
|-------|---------|---------|
| Region-Adaptive Sampling for Diffusion Transformers (Read more on [arXiv](https://arxiv.org/abs/2502.10389) or [HuggingFace](https://huggingface.co/papers/2502.10389))| Lili Qiu, Yiqi Zhang, Chengruidong Zhang, Yifan Yang, Ziming Liu | Region-adaptive sampling (RAS) improves the efficiency of Diffusion Transformers (DiTs) by dynamically adjusting sampling ratios across image regions. The main objective is to accelerate the sampling process of DiTs without significant quality degradation by focusing computational resources on semantically meaningful regions. RAS identifies "focus" regions in each sampling step using output noise from the previous step, updating only these, and caches the rest, based on attention continuity. RAS achieves speedups of up to 2.36x and 2.51x on Stable Diffusion 3 and Lumina-Next-T2I, respectively, with minimal generation quality degradation. AI practitioners can use RAS to significantly improve the sampling speed of Diffusion Transformers, facilitating real-time applications that require high-quality image generation.  |
| Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model (Read more on [arXiv](https://arxiv.org/abs/2502.10248) or [HuggingFace](https://huggingface.co/papers/2502.10248))| Nan Duan, Liangyu Chen, Kun Yan, Haoyang Huang, Guoqing Ma | i) Step-Video-T2V, a 30B parameter text-to-video model, achieves state-of-the-art results via a novel architecture and training strategy. ii) The research objective is to develop a high-performance and high-quality text-to-video generation model surpassing existing open-source and commercial engines. iii) The methodology involves a deep compression Video-VAE, a DiT with 3D full attention trained using Flow Matching, and a video-based DPO for visual quality enhancement. iv) Evaluated on Step-Video-T2V-Eval, Step-Video-T2V demonstrates state-of-the-art performance with 16x16 spatial and 8x temporal compression ratios while generating videos up to 204 frames. v) AI practitioners can leverage Step-Video-T2V as a strong baseline for further innovations in video foundation models, particularly in improving motion dynamics, aesthetics, and content consistency.  |
| ZeroBench: An Impossible Visual Benchmark for Contemporary Large Multimodal Models (Read more on [arXiv](https://arxiv.org/abs/2502.09696) or [HuggingFace](https://huggingface.co/papers/2502.09696))| Samuel Roberts, Akash Gupta, Ansh Sharma, Mohammad Reza Taesiri, Jonathan Roberts | ZeroBench is a new visual reasoning benchmark of 100 questions designed to be impossible for current large multimodal models (LMMs). The main research objective is to create a lightweight yet challenging visual benchmark to evaluate and differentiate the capabilities of LMMs. The methodology involves manually curating and reviewing a set of diverse, multi-step visual reasoning questions, and then adversarially filtering them based on the performance of 20 contemporary LMMs. The primary result is that all evaluated LMMs scored 0.0% on the main questions of ZeroBench, although they achieved non-zero scores on the easier sub-questions, such as 24.30% pass@1 by Claude 3.5 Sonnet v2. The principle implication is that this benchmark highlights limitations to assist in the development of improved LMMs.  |
| Large Language Diffusion Models (Read more on [arXiv](https://arxiv.org/abs/2502.09992) or [HuggingFace](https://huggingface.co/papers/2502.09992))| Jingyang Ou, Xiaolu Zhang, Zebin You, Fengqi Zhu, Shen Nie | LLaDA, a diffusion model trained from scratch, achieves performance comparable to autoregressive LLMs like LLaMA3 8B.  The main research question is whether diffusion models can achieve the capabilities of large language models (LLMs) without relying on the autoregressive paradigm.  Key methodology used is a masked diffusion model (MDM) trained with a forward data masking process and a reverse process parameterized by a vanilla Transformer to predict masked tokens, optimizing a likelihood bound.  Primary result is that LLaDA 8B surpasses LLaMA2 7B on nearly all 15 standard zero/few-shot learning tasks and is on par with LLaMA3 8B, and it achieves a 70.7% accuracy on the GSM8K benchmark.  Principal implication is that AI practitioners can explore diffusion models as a viable alternative to autoregressive models for large-scale language modeling, potentially offering advantages in bidirectional context understanding and parallel token generation.  |
| MM-RLHF: The Next Step Forward in Multimodal LLM Alignment (Read more on [arXiv](https://arxiv.org/abs/2502.10391) or [HuggingFace](https://huggingface.co/papers/2502.10391))| Peiyan Li, Chaoyou Fu, Haochen Tian, Tao Yu, Yi-Fan Zhang | i) The paper introduces MM-RLHF, a new dataset and methodology for aligning multimodal large language models (MLLMs) with human preferences. ii) The research aims to enhance MLLM capabilities across multiple dimensions by aligning models with human preferences. iii) The methodology includes curating a 120k comparison pair dataset, developing a critique-based reward model, and employing dynamic reward scaling within DPO. iv) Fine-tuning LLaVA-ov-7B with MM-RLHF and the proposed alignment algorithm achieves a 19.5% increase in conversational abilities and a 60% improvement in safety. v) AI practitioners can leverage the MM-RLHF dataset and associated techniques to improve MLLM alignment, leading to safer and more capable multimodal models; the critique based reward model can be used to provide more informative feedback for training.  |
| Precise Parameter Localization for Textual Generation in Diffusion Models (Read more on [arXiv](https://arxiv.org/abs/2502.09935) or [HuggingFace](https://huggingface.co/papers/2502.09935))| Adam Dziedzic, Kamil Deja, Franziska Boenisch, Bartosz Cywiński, Łukasz Staniszewski | This research localizes and utilizes the parameters in diffusion models responsible for generating and editing textual content within images. The main research objective is to identify the specific parameters within diffusion models that control the generation of textual content in images. The key methodology involves activation patching of cross and joint attention layers and fine-tuning using Low-Rank Adaptation (LoRA). The primary result is that less than 1% of diffusion models' parameters (0.61% of Stable Diffusion XL, 0.21% of DeepFloyd IF, and 0.23% of Stable Diffusion 3), specifically within attention layers, are responsible for textual content generation. This implies that AI practitioners can improve text generation in diffusion models, and enable precise text editing by fine-tuning or manipulating only this small subset of parameters, conserving computational resources and preserving overall image generation quality.  |
| Diverse Inference and Verification for Advanced Reasoning (Read more on [arXiv](https://arxiv.org/abs/2502.09955) or [HuggingFace](https://huggingface.co/papers/2502.09955))| Yuke Zhang, Seunghwan Hyun, Mao Mao, Gaston Longhitano, Iddo Drori | i) The paper presents a diverse inference approach to improve the performance of Reasoning LLMs on challenging tasks. ii) The research aims to enhance reasoning LLMs' accuracy on complex benchmarks like IMO combinatorics, ARC puzzles, and HLE questions. iii) Key methods include combining multiple models/methods at test time, verifying solutions automatically, test-time simulations, reinforcement learning, and meta-learning of agent graphs. iv) The approach increases IMO combinatorics accuracy from 33.3% to 77.8%, HLE accuracy from 8% to 37%, and solves 80% of ARC puzzles unsolvable by 948 humans. v) AI practitioners can leverage diverse inference and verification techniques to improve the robustness and accuracy of reasoning LLMs on advanced problem-solving tasks.  |
| We Can't Understand AI Using our Existing Vocabulary (Read more on [arXiv](https://arxiv.org/abs/2502.07586) or [HuggingFace](https://huggingface.co/papers/2502.07586))| Been Kim, Robert Geirhos, John Hewitt | This position paper argues that understanding and controlling AI requires developing new vocabulary (neologisms) to represent concepts unique to machines or humans.  The main research objective is to argue for developing neologisms to bridge the communication gap between humans and AI, stemming from their differing conceptualizations of the world.  The key methodology used is a conceptual argument supported by a proof-of-concept, "neologism embedding learning," which trains new word embeddings representing human or machine concepts to control model behavior.  The primary results demonstrated that using a "length neologism," responses that meet the length contraints went from near 0% with regular instructions, to a vast majority of generations, shown in figure 5. The authors presented a new "diversity neologism", increasing response variety in a number-guessing task.  Principal implication for AI practitioners is that creating and incorporating neologisms into prompts can improve control over language model behavior and potentially provide a more precise way to interact with and understand AI systems.  |
| AdaPTS: Adapting Univariate Foundation Models to Probabilistic Multivariate Time Series Forecasting (Read more on [arXiv](https://arxiv.org/abs/2502.10235) or [HuggingFace](https://huggingface.co/papers/2502.10235))| Maurizio Filippone, Albert Thomas, Giuseppe Paolo, Vasilii Feofanov, abenechehab | AdaPTS is a framework for adapting pre-trained univariate time series foundation models to probabilistic multivariate forecasting using trainable feature-space transformations. The main research objective is to develop a method for leveraging pre-trained univariate time series foundation models (FMs) for multivariate forecasting tasks while addressing challenges like inter-feature dependencies and uncertainty quantification. The key methodology involves introducing "adapters"—stochastic, invertible feature-space transformations—that project multivariate inputs into a latent space where a frozen, pre-trained univariate FM can be applied independently to each dimension, followed by an inverse transformation. Primary results show that AdaPTS improves the forecasting accuracy of the Moment model in 5 out of 8 considered tasks; for example on the Illness dataset (H=24), the VAE adapter achieved a 15% MSE improvement, reducing it from 2.902 to 2.461. AI practitioners can use AdaPTS as a modular and scalable solution for leveraging existing time series FMs in multivariate contexts, enhancing forecasting performance, and uncertainty quantification without requiring FM fine-tuning.  |
| FoNE: Precise Single-Token Number Embeddings via Fourier Features (Read more on [arXiv](https://arxiv.org/abs/2502.09741) or [HuggingFace](https://huggingface.co/papers/2502.09741))| Vatsal Sharan, Robin Jia, Mahdi Soltanolkotabi, Deqing Fu, Tianyi Zhou | FoNE introduces a novel method to represent numbers as single tokens in large language models using Fourier features. The main research objective is to develop a more precise and efficient number embedding method that overcomes the limitations of traditional subword and digit-wise tokenization in LLMs. FoNE maps numbers directly into the embedding space using their Fourier features, encoding each digit with two embedding dimensions. On 6-digit decimal addition, FoNE requires 64x less data to achieve 99% accuracy than subword and digit-wise embeddings and is the only method that yields 100% accuracy on over 100,000 test examples. The principal implication is that AI practitioners can leverage FoNE to improve LLM performance on number-related tasks, achieving higher accuracy with reduced computational overhead and training data.  |
| Jailbreaking to Jailbreak (Read more on [arXiv](https://arxiv.org/abs/2502.09638) or [HuggingFace](https://huggingface.co/papers/2502.09638))| Bijan Varjavand, Robert Vacareanu, Vaughn Robinson, Jeremy Kritz, ZifanScale | This paper introduces "Jailbreaking-to-Jailbreak" (J2), a novel approach where a refusal-trained Large Language Model (LLM) is jailbroken to assist in jailbreaking other LLMs. The main research objective is to evaluate the capability of jailbroken LLMs to act as effective red teamers and to compare their performance against existing automated and human-led red teaming methods. Key methodology involves creating J2 attackers by jailbreaking frontier LLMs through human-crafted prompts, then using these J2 attackers in an iterative, multi-turn red teaming workflow with in-context learning. Primary results show that J2 attackers (specifically Sonnet-3.5 and Gemini-1.5-pro) achieve 93.0% and 91.0% attack success rates (ASRs) respectively against GPT-40 on Harmbench, approaching human-level performance. Principal implication for AI practitioners is that LLM safeguards can be bypassed by leveraging a jailbroken version of an LLM, highlighting a new failure mode and emphasizing the need for enhanced safeguard mechanisms against LLM-assisted jailbreaking.  |
| STMA: A Spatio-Temporal Memory Agent for Long-Horizon Embodied Task Planning (Read more on [arXiv](https://arxiv.org/abs/2502.10177) or [HuggingFace](https://huggingface.co/papers/2502.10177))| Shuguang Cui, Zhixin Mai, Ge Wang, Yiming Zhao, Mingcong Lei | The paper introduces the Spatio-Temporal Memory Agent (STMA), a framework designed to enhance task planning and execution in dynamic environments for embodied AI. The main objective is to enable agents to perform long-horizon tasks by improving decision-making and adaptability through integrated spatio-temporal memory. The methodology involves a spatio-temporal memory module, a dynamic knowledge graph for spatial reasoning, and a planner-critic mechanism for iterative strategy refinement. Results from evaluations in the TextWorld environment show STMA achieved a 31.25% improvement in success rate and a 24.7% increase in average score compared to state-of-the-art models. For AI practitioners, STMA offers a new way to approach memory within AI Agents.  |
| MRS: A Fast Sampler for Mean Reverting Diffusion based on ODE and SDE Solvers (Read more on [arXiv](https://arxiv.org/abs/2502.07856) or [HuggingFace](https://huggingface.co/papers/2502.07856))| Ge Yang, Le Lu, Hongbo Zhao, Wei Fang, Ao Li | Mean Reverting Sampler (MRS) accelerates sampling for Mean Reverting (MR) Diffusion models. The main research objective is to reduce the sampling NFEs (number of function evaluations) of MR Diffusion, which currently requires hundreds of steps. The methodology involves solving the reverse-time SDE and probability flow ODE associated with MR Diffusion, deriving semi-analytical solutions consisting of an analytical function and a neural network parameterized integral. Primary results demonstrate that the MR Sampler maintains high sampling quality with a speedup of 10 to 20 times across ten different image restoration tasks. Principal implication for AI practitioners is that they can leverage MRS for faster and more efficient controllable generation using MR Diffusion models, making them more practical in applications.  |
| V2V-LLM: Vehicle-to-Vehicle Cooperative Autonomous Driving with Multi-Modal Large Language Models (Read more on [arXiv](https://arxiv.org/abs/2502.09980) or [HuggingFace](https://huggingface.co/papers/2502.09980))| Yu-Chiang Frank Wang, Stephen F. Smith, Chien-Yi Wang, Ryo Hachiuma, Hsu-kuang Chiu | i) This paper introduces V2V-LLM, a large language model for cooperative autonomous driving. ii) The research aims to explore the problem of integrating LLMs into cooperative autonomous driving systems to improve safety. iii) The methodology involves creating a new dataset, V2V-QA, and developing a baseline method, V2V-LLM, that fuses perception information from multiple connected autonomous vehicles using scene-level and object-level features. iv) The V2V-LLM outperforms other fusion methods on notable object identification and planning tasks in the V2V-QA dataset, achieving a collision rate of 3.00% compared to 4.57% for the "No Fusion" baseline. v) The primary implication for AI practitioners is the potential of V2V-LLM to serve as a foundation model for cooperative autonomous driving, particularly in scenarios with sensor occlusion.  |
| Agentic End-to-End De Novo Protein Design for Tailored Dynamics Using a Language Diffusion Model (Read more on [arXiv](https://arxiv.org/abs/2502.10173) or [HuggingFace](https://huggingface.co/papers/2502.10173))| Markus J. Buehler, Bo Ni | VibeGen is a generative AI framework for de novo protein design conditioned on normal mode vibrations. The main research objective is to develop a model that can generate novel protein sequences that exhibit specified dynamic properties, specifically low-frequency vibrational modes. The key methodology involves an agentic dual-model architecture, comprising a protein designer (PD) based on a protein language diffusion model that generates sequences and a protein predictor (PP) that evaluates their dynamic accuracy. Primary results showed that the generated proteins accurately reproduced prescribed normal mode amplitudes, with a median Pearson correlation coefficient of 0.53 between designed and target vibration profiles across a large test set. Principal implication for AI practitioners is the demonstration of a viable approach for integrating protein dynamics into generative protein design, enabling the creation of biomolecules with targeted motion-based functionalities.  |
